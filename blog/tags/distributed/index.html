<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-react-helmet="true">One post tagged with &quot;distributed&quot; | Recohut</title><meta data-react-helmet="true" property="og:title" content="One post tagged with &quot;distributed&quot; | Recohut"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://docs.recohut.com/blog/tags/distributed"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="blog_tags_posts"><link data-react-helmet="true" rel="icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://docs.recohut.com/blog/tags/distributed"><link data-react-helmet="true" rel="alternate" href="https://docs.recohut.com/blog/tags/distributed" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://docs.recohut.com/blog/tags/distributed" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.52d28afd.css">
<link rel="preload" href="/assets/js/runtime~main.c7814cfb.js" as="script">
<link rel="preload" href="/assets/js/main.c1286f86.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Recohut Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Recohut Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">Recohut</b></a><a class="navbar__item navbar__link" href="/docs/intro">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/recohut/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">üåú</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">üåû</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">Recent posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/bytedance&#x27;s-secret-sauce-of-recommendation">ByteDance&#x27;s secret sauce of recommendation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/clinical-decision-making">Clinical Decision Making</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/detectron-2">Detectron 2</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/distributed-training-of-recommender-systems">Distributed Training of Recommender Systems</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/document-recommendation">Document Recommendation</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;distributed&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_d4p0" itemprop="headline"><a itemprop="url" href="/blog/2021/10/01/distributed-training-of-recommender-systems">Distributed Training of Recommender Systems</a></h2><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2021-10-01T00:00:00.000Z" itemprop="datePublished">October 1, 2021</time> ¬∑ <!-- -->6 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/sparsh-ai" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://avatars.githubusercontent.com/u/62965911?v=4" alt="Sparsh Agarwal"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/sparsh-ai" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Sparsh Agarwal</span></a></div><small class="avatar__subtitle" itemprop="description">Principal Developer</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>The usage and importance of recommender systems are increasing at a fast pace. And deep learning is gaining traction as the preferred choice for model architecture. Giants like Google and Facebook are already using recommenders to earn billions of dollars.</p><p>Recently, Facebook shared its approach to maintain its 12 trillion parameter recommender. Building these large systems is challenging because it requires huge computation and memory resources. And we will soon enter into 100 trillion range. And SMEs will not be left behind due to open-source environment of software architectures and the decreasing cost of hardware, especially on the cloud infrastructure.</p><p>As per one estimate, a model with 100 trillion parameters would require at least 200TB just to store the model, even at 16-bit floating-point accuracy. So we need architectures that can support efficient and distributed training of recommendation models.</p><p><strong><em>Memory-intensive vs Computation-intensive</em></strong>: The increasing parameter comes mostly from the embedding layer which maps each entrance of an ID type feature (such as an user ID and a session ID) into a fixed length low-dimensional embedding vector. Consider the billion scale of entrances for the ID type features in a production recommender system and the wide utilization of feature crosses, the embedding layer usually domains the parameter space, which makes this component extremely <strong>memory-intensive</strong>. On the other hand, these low-dimensional embedding vectors are concatenated with diversified Non-ID type features (e.g., image, audio, video, social network, etc.) to feed a group of increasingly sophisticated neural networks (e.g., convolution, LSTM, multi-head attention) for prediction(s). Furthermore, in practice, multiple objectives can also be combined and optimized simultaneously for multiple tasks. These mechanisms make the rest neural network increasingly <strong>computation-intensive</strong>.</p><p><img alt="An example of a recommender models with 100+ trillions of parameter in the embedding layer and 50+ TFLOP computation in the neural network." src="/assets/images/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-76057748d7f785bcb03bc9fae4560fc3.png"></p><p>An example of a recommender models with 100+ trillions of parameter in the embedding layer and 50+ TFLOP computation in the neural network.</p><p><a href="https://github.com/alibaba/x-deeplearning" target="_blank" rel="noopener noreferrer">Alibaba&#x27;s XDL</a>, <a href="https://github.com/PaddlePaddle/PaddleRec" target="_blank" rel="noopener noreferrer">Baidu&#x27;s PaddleRec</a>, and <a href="https://github.com/persiaml/persia" target="_blank" rel="noopener noreferrer">Kwai&#x27;s Persia</a> are some open-source frameworks for this large-scale distributed training of recommender systems.</p><aside>üìå ***Synchronous vs Asynchronous Algorithms***: Synchronous algorithms always use the up-to-date gradient to update the model to ensure the model accuracy. However, the overhead of communications for synchronous algorithms starts to become too expensive to scale out the training procedure, causing inefficiency in running time. While asynchronous algorithm have better hardware efficiency, it often leads to a ‚Äúsignificant‚Äù loss in model accuracy at this scale‚Äîfor production recommender systems (e.g., Baidu‚Äôs search engine). Recall that even 0.1% drop of accuracy would lead to a noticeable loss in revenue.</aside><h3 class="anchor anchorWithStickyNavbar_y2LR" id="parameter-server-framework">Parameter Server Framework<a class="hash-link" href="#parameter-server-framework" title="Direct link to heading">‚Äã</a></h3><p>Existing distributed systems for deep learning based recommender models are usually built on top of the parameter server (PS) framework, where one can add elastic distributed storage to hold the increasingly large amount of parameters of the embedding layer. On the other hand, the computation workload does not scale linearly with the increasing parameter scale of the embedding layer‚Äîin fact, with an efficient implementation, a lookup operation over a larger embedding table would introduce almost no additional computations.</p><p><img alt="Left: deep learning based recommender model training workflow over a heterogeneous cluster. Right: Gantt charts to compare fully synchronous, fully asynchronous, raw hybrid and optimized hybrid modes of distributed training of the deep learning recommender model. [Source](https://arxiv.org/pdf/2111.05897v1.pdf)." src="/assets/images/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-1-64afd6c4cb479b89e18f624461bb9641.png"></p><p>Left: deep learning based recommender model training workflow over a heterogeneous cluster. Right: Gantt charts to compare fully synchronous, fully asynchronous, raw hybrid and optimized hybrid modes of distributed training of the deep learning recommender model. <a href="https://arxiv.org/pdf/2111.05897v1.pdf" target="_blank" rel="noopener noreferrer">Source</a>.</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="persia">PERSIA<a class="hash-link" href="#persia" title="Direct link to heading">‚Äã</a></h3><p><strong>PERSIA</strong>¬†(<strong>P</strong>arallel r<strong>E</strong>commendation t<strong>R</strong>aining¬†<strong>S</strong>ystem with hybr<strong>I</strong>d¬†<strong>A</strong>cceleration) is a PyTorch-based system for training deep learning recommendation models on commodity hardware. It supports models containing more than 100 trillion parameters.</p><p>It uses a hybrid training algorithm to tackle the embedding layer and dense neural network modules differently‚Äîthe embedding layer is trained in an asynchronous fashion to improve the throughput of training samples, while the rest neural network is trained in a synchronous fashion to preserve the statistical efficiency.</p><p>It also uses a distributed system to manage the hybrid computation resources (CPUs and GPUs) to optimize the co-existence of asynchronicity and synchronicity in the training algorithm.</p><p><img alt="Untitled" src="/assets/images/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-2-f8f92456dbc99598ab43bdb238450ac0.png"></p><p><img alt="Untitled" src="/assets/images/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-3-c4a1ad9cdcc4ab78213fff42a2bf2d18.png"></p><p>Persia includes a data loader module, a embedding PS (Parameter Server) module, a group of embedding workers over CPU nodes, and a group of NN workers over GPU instances. Each module can be dynamically scaled for different model scales and desired training throughput:</p><ul><li>A data loader that fetches training data from distributed storages such as Hadoop, Kafka, etc;</li><li>A embedding parameter server (embedding PS for short) manages the storage and update of the parameters in the embedding layer $\mathrm{w}^{emb}$;</li><li>A group of embedding workers that runs Algorithm 1 for getting the embedding parameters from the embedding PS; aggregating embedding vectors (potentially) and putting embedding gradients back to embedding PS;</li><li>A group of NN workers that runs the forward-/backward- propagation of the neural network $\mathrm{NN_{w^{nn}}(¬∑)}$.</li></ul><p><img alt="The architecture of Persia." src="/assets/images/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-4-717546b660d1b2fcaff856bf274d18e2.png"></p><p>The architecture of Persia.</p><p>Logically, the training procedure is conducted by Persia in a data dispatching based paradigm as below:</p><ol><li>The data loader will dispatch the ID type feature $\mathrm{x^{ID}}$ to an embedding worker‚Äîthe embedding worker will generate an unique sample ID ùúâ for this sample, buffer this sample ID with the ID type feature $\mathrm{x_\xi^{ID}}$ locally, and returns this ID ùúâ back the data loader; the data loader will associate this sample‚Äôs Non-ID type features and labels with this unique ID.</li><li>Next, the data loader will dispatch the Non-ID type feature and label(s) $\mathrm{(x<em>\xi^{NID},y</em>\xi)}$ to a NN worker.</li><li>Once a NN worker receives this incomplete training sample, it will issue a request to pull the ID type features‚Äô $\mathrm{(x<em>\xi^{ID})}$ embedding $\mathrm{w</em>\xi^{emb}}$ from some embedding worker according to the sample ID ùúâ‚Äîthis would trigger the forward propagation in Algorithm 1, where the embedding worker will use the buffered ID type feature $\mathrm{x<em>\xi^{ID}}$ to get the corresponding $\mathrm{w</em>\xi^{emb}}$ from the embedding PS.</li><li>Then the embedding worker performs some potential aggregation of original embedding vectors. When this computation finishes, the aggregated embedding vector $\mathrm{w_\xi^{emb}}$ will be transmitted to the NN worker that issues the pull request.</li><li>Once the NN worker gets a group of complete inputs for the dense module, it will create a mini-batch and conduct the training computation of the NN according to Algorithm 2. Note that the parameter of the NN always locates in the device RAM of the NN worker, where the NN workers synchronize the gradients by the AllReduce Paradigm.</li><li>When the iteration of Algorithm 2 is finished, the NN worker will send the gradients of the embedding ($\mathrm{F_\xi^{emb&#x27;}}$) back to the embedding worker (also along with the sample ID ùúâ).</li><li>The embedding worker will query the buffered ID type feature $\mathrm{x<em>\xi^{ID}}$ according to the sample ID ùúâ; compute gradients $\mathrm{F</em>\xi^{emb&#x27;}}$ of the embedding parameters and send the gradients to the embedding PS, so that the embedding PS can finally compute the updates according the embedding parameter‚Äôs gradients by its SGD optimizer and update the embedding parameters.</li></ol></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/distributed">distributed</a></li><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/recsys">recsys</a></li></ul></div><div class="col text--right col--3"><a aria-label="Read more about Distributed Training of Recommender Systems" href="/blog/2021/10/01/distributed-training-of-recommender-systems"><b>Read More</b></a></div></footer></article></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/concept-basics">Concepts</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tutorials">Tutorials</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/projects">Projects</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/recohut/docs" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://nb.recohut.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Jupyter Notebooks<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://step.recohut.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Interactive Stories<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2022 Recohut Docs, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.c7814cfb.js"></script>
<script src="/assets/js/main.c1286f86.js"></script>
</body>
</html>