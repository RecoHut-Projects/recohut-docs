<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.14">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Recohut RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Recohut Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><title data-react-helmet="true">Short-video Background Music Recommender | Recohut</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://docs.recohut.com/blog/2021/10/01/short-video-background-music-recommender"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" property="og:title" content="Short-video Background Music Recommender | Recohut"><meta data-react-helmet="true" name="description" content="Matching micro-videos with suitable background music can help uploaders better convey their contents and emotions, and increase the click-through rate of their uploaded videos. However, manually selecting the background music becomes a painstaking task due to the voluminous and ever-growing pool of candidate music. Therefore, automatically recommending background music to videos becomes an important task."><meta data-react-helmet="true" property="og:description" content="Matching micro-videos with suitable background music can help uploaders better convey their contents and emotions, and increase the click-through rate of their uploaded videos. However, manually selecting the background music becomes a painstaking task due to the voluminous and ever-growing pool of candidate music. Therefore, automatically recommending background music to videos becomes an important task."><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="article:published_time" content="2021-10-01T00:00:00.000Z"><meta data-react-helmet="true" property="article:author" content="https://github.com/sparsh-ai"><meta data-react-helmet="true" property="article:tag" content="recsys"><link data-react-helmet="true" rel="icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://docs.recohut.com/blog/2021/10/01/short-video-background-music-recommender"><link data-react-helmet="true" rel="alternate" href="https://docs.recohut.com/blog/2021/10/01/short-video-background-music-recommender" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://docs.recohut.com/blog/2021/10/01/short-video-background-music-recommender" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.87c99533.css">
<link rel="preload" href="/assets/js/runtime~main.c048513b.js" as="script">
<link rel="preload" href="/assets/js/main.ba5db000.js" as="script">
</head>
<body data-theme="light">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Recohut Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Recohut Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">Recohut</b></a><a class="navbar__item navbar__link" href="/docs/intro">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/recohut/docs" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">ðŸŒœ</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">ðŸŒž</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div><div class="dsla-search-wrapper"><div class="dsla-search-field" data-tags="default,docs-default-current"></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-post-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_q+wC thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_9G5K margin-bottom--md">Recent posts</div><ul class="sidebarItemList_6T4b"><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/bytedance&#x27;s-secret-sauce-of-recommendation">ByteDance&#x27;s secret sauce of recommendation</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/clinical-decision-making">Clinical Decision Making</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/detectron-2">Detectron 2</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/distributed-training-of-recommender-systems">Distributed Training of Recommender Systems</a></li><li class="sidebarItem_cjdF"><a class="sidebarItemLink_zyXk" href="/blog/2021/10/01/document-recommendation">Document Recommendation</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="blogPostTitle_d4p0" itemprop="headline">Short-video Background Music Recommender</h1><div class="blogPostData_-Im+ margin-vert--md"><time datetime="2021-10-01T00:00:00.000Z" itemprop="datePublished">October 1, 2021</time> Â· <!-- -->3 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_8c0z"><div class="avatar margin-bottom--sm"><a href="https://github.com/sparsh-ai" target="_blank" rel="noopener noreferrer" class="avatar__photo-link avatar__photo"><img class="image_9q7L" src="https://avatars.githubusercontent.com/u/62965911?v=4" alt="Sparsh Agarwal"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/sparsh-ai" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Sparsh Agarwal</span></a></div><small class="avatar__subtitle" itemprop="description">Principal Developer</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Matching micro-videos with suitable background music can help uploaders better convey their contents and emotions, and increase the click-through rate of their uploaded videos. However, manually selecting the background music becomes a painstaking task due to the voluminous and ever-growing pool of candidate music. Therefore, automatically recommending background music to videos becomes an important task.</p><p>In <a href="https://arxiv.org/pdf/2107.07268.pdf" target="_blank" rel="noopener noreferrer">this</a> paper, Zhu et. al. shared their approach to solve this task. They first collected ~3,000 background music from popular TikTok videos and also ~150,000 video clips that used some kind of background music. They named this dataset <code>TT-150K</code>.</p><p><img alt="An exemplar subset of videos and their matched background music in the established TT-150k dataset" src="/assets/images/content-blog-raw-blog-short-video-background-music-recommender-untitled-8e4334cad8c9ec206ebdba19b1163b61.png"></p><p>An exemplar subset of videos and their matched background music in the established TT-150k dataset</p><p>After building the dataset, they worked on modeling and proposed the following architecture:</p><p><img alt="Proposed CMVAE (Cross-modal Variational Auto-encoder) framework" src="/assets/images/content-blog-raw-blog-short-video-background-music-recommender-untitled-1-81086e3ba53f8bc9648682e6f1b367ed.png"></p><p>Proposed CMVAE (Cross-modal Variational Auto-encoder) framework</p><p>The goal is to represent videos (<code>users</code> in recsys terminology) and music (<code>items</code>) in a shared latent space. To achieve this, CMVAE use pre-trained models to extract features from unstructured data - <code>vggish</code> model for audio2vec, <code>resnet</code> for video2vec and <code>bert-multilingual</code> for text2vec.  Text and video vectors are then fused using product-of-expert approach. </p><p>It uses the reconstruction power of variational autoencoders to 1) reconstruct video from music latent vector and, 2) reconstruct music from video latent vector. In layman terms, we are training a neural network that will try to guess the video activity just by listening background music, and also try to guess the background music just by seeing the video activities. </p><p>The joint training objective is $\mathcal{L}<em>{(z_m,z_v)} = \beta \cdot\mathcal{L}</em>{cross<!-- -->_<!-- -->recon} - \mathcal{L}<em>{KL} + \gamma \cdot \mathcal{L}</em>{matching}$, where $\beta$ and $\gamma$ control the weight of the cross reconstruction loss and the matching loss, respectively.</p><p>After training the model, they compared the model&#x27;s performance with existing baselines and the results are as follows:</p><p><img alt="/img/content-blog-raw-blog-short-video-background-music-recommender-untitled-2.png" src="/assets/images/content-blog-raw-blog-short-video-background-music-recommender-untitled-2-0002224cfc03822d344479f3766cd1ec.png"></p><p><strong>Conclusion</strong>: I don&#x27;t make short videos myself but can easily imagine the difficulty in finding the right background music. If I have to do this task manually, I will try out 5-6 videos and select one that I like. But here, I will be assuming that my audience would also like this music. Moreover, feedback is not actionable because it will create kind of an implicit sub-conscious effect (because when I see a video, I mostly judge it at overall level and rarely notice that background music is the problem). So, this kind of recommender system will definitely help me in selecting a better background music. Excited to see this feature soon in TikTok, Youtube Shorts and other similar services.</p></div><footer class="row docusaurus-mt-lg blogPostDetailsFull_xD8n"><div class="col"><b>Tags:</b><ul class="tags_NBRY padding--none margin-left--sm"><li class="tag_F03v"><a class="tag_WK-t tagRegular_LXbV" href="/blog/tags/recsys">recsys</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/recohut/docs/blog/blog/2021-10-01-short-video-background-music-recommender.mdx" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_mS5F" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/2021/10/01/semantic-similarity"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Â« <!-- -->Semantic Similarity</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/2021/10/01/the-progression-of-analytics-in-enterprises"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">The progression of analytics in enterprises<!-- --> Â»</div></a></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Learn</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/concept-basics">Concepts</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tutorials">Tutorials</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/projects">Projects</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/recohut/docs" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://nb.recohut.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Jupyter Notebooks<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://step.recohut.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Interactive Stories<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 Recohut Docs, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.c048513b.js"></script>
<script src="/assets/js/main.ba5db000.js"></script>
</body>
</html>