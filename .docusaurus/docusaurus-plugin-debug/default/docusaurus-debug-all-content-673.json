{
  "docusaurus-plugin-content-docs": {
    "default": {
      "loadedVersions": [
        {
          "versionName": "current",
          "versionLabel": "Next",
          "versionPath": "/docs",
          "tagsPath": "/docs/tags",
          "versionEditUrl": "https://github.com/recohut/docs/docs/docs",
          "versionEditUrlLocalized": "https://github.com/recohut/docs/docs/i18n/en/docusaurus-plugin-content-docs/current",
          "versionBanner": null,
          "versionBadge": false,
          "versionClassName": "docs-version-current",
          "isLast": true,
          "routePriority": -1,
          "sidebarFilePath": "/content/docs/sidebars.js",
          "contentPath": "/content/docs/docs",
          "contentPathLocalized": "/content/docs/i18n/en/docusaurus-plugin-content-docs/current",
          "docs": [
            {
              "unversionedId": "concept-basics/challenges",
              "id": "concept-basics/challenges",
              "title": "Challenges",
              "description": "The construction of effective Recommender Systems (RS) is a complex process, mainly due to the nature of RSs which involves large scale software-systems and human interactions. Iterative development processes require deep understanding of a current baseline as well as the ability to estimate the impact of changes in multiple variables of interest. Simulations are well suited to address both challenges and potentially leading to a high velocity construction process, a fundamental requirement in commercial contexts. Recently, there has been significant interest in RS Simulation Platforms, which allow RS developers to easily craft simulated environments where their systems can be analyzed.",
              "source": "@site/docs/concept-basics/challenges.mdx",
              "sourceDirName": "concept-basics",
              "slug": "/concept-basics/challenges",
              "permalink": "/docs/concept-basics/challenges",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-basics/challenges.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Introduction",
                "permalink": "/docs/intro"
              },
              "next": {
                "title": "Evaluation",
                "permalink": "/docs/concept-basics/evaluation"
              }
            },
            {
              "unversionedId": "concept-basics/evaluation",
              "id": "concept-basics/evaluation",
              "title": "Evaluation",
              "description": "Online vs Offline Evaluation",
              "source": "@site/docs/concept-basics/evaluation.mdx",
              "sourceDirName": "concept-basics",
              "slug": "/concept-basics/evaluation",
              "permalink": "/docs/concept-basics/evaluation",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-basics/evaluation.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Challenges",
                "permalink": "/docs/concept-basics/challenges"
              },
              "next": {
                "title": "User Feedback",
                "permalink": "/docs/concept-basics/implicit-feedback"
              }
            },
            {
              "unversionedId": "concept-basics/implicit-feedback",
              "id": "concept-basics/implicit-feedback",
              "title": "User Feedback",
              "description": "Explicit vs. implicit users feedback",
              "source": "@site/docs/concept-basics/implicit-feedback.mdx",
              "sourceDirName": "concept-basics",
              "slug": "/concept-basics/implicit-feedback",
              "permalink": "/docs/concept-basics/implicit-feedback",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-basics/implicit-feedback.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Evaluation",
                "permalink": "/docs/concept-basics/evaluation"
              },
              "next": {
                "title": "Processes",
                "permalink": "/docs/concept-basics/processes"
              }
            },
            {
              "unversionedId": "concept-basics/processes",
              "id": "concept-basics/processes",
              "title": "Processes",
              "description": "Retrieval and Ranking",
              "source": "@site/docs/concept-basics/processes.mdx",
              "sourceDirName": "concept-basics",
              "slug": "/concept-basics/processes",
              "permalink": "/docs/concept-basics/processes",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-basics/processes.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "User Feedback",
                "permalink": "/docs/concept-basics/implicit-feedback"
              },
              "next": {
                "title": "Session-based Recommenders",
                "permalink": "/docs/concept-basics/session-based-recommenders"
              }
            },
            {
              "unversionedId": "concept-basics/session-based-recommenders",
              "id": "concept-basics/session-based-recommenders",
              "title": "Session-based Recommenders",
              "description": "Recommender systems help users find relevant items of interest, for example on e-commerce or media streaming sites. Most academic research is concerned with approaches that personalize the recommendations according to long-term user profiles. In many real-world applications, however, such long-term profiles often do not exist and recommendations, therefore, have to be made solely based on the observed behavior of a user during an ongoing session.",
              "source": "@site/docs/concept-basics/session-based-recommenders.md",
              "sourceDirName": "concept-basics",
              "slug": "/concept-basics/session-based-recommenders",
              "permalink": "/docs/concept-basics/session-based-recommenders",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-basics/session-based-recommenders.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Processes",
                "permalink": "/docs/concept-basics/processes"
              },
              "next": {
                "title": "Tasks",
                "permalink": "/docs/concept-basics/tasks"
              }
            },
            {
              "unversionedId": "concept-basics/tasks",
              "id": "concept-basics/tasks",
              "title": "Tasks",
              "description": "Top-K Recommendation",
              "source": "@site/docs/concept-basics/tasks.mdx",
              "sourceDirName": "concept-basics",
              "slug": "/concept-basics/tasks",
              "permalink": "/docs/concept-basics/tasks",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-basics/tasks.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Session-based Recommenders",
                "permalink": "/docs/concept-basics/session-based-recommenders"
              },
              "next": {
                "title": "Types of Recommender Systems",
                "permalink": "/docs/concept-basics/types-of-recommender-systems"
              }
            },
            {
              "unversionedId": "concept-basics/types-of-recommender-systems",
              "id": "concept-basics/types-of-recommender-systems",
              "title": "Types of Recommender Systems",
              "description": "Group Recommender System",
              "source": "@site/docs/concept-basics/types-of-recommender-systems.md",
              "sourceDirName": "concept-basics",
              "slug": "/concept-basics/types-of-recommender-systems",
              "permalink": "/docs/concept-basics/types-of-recommender-systems",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-basics/types-of-recommender-systems.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Tasks",
                "permalink": "/docs/concept-basics/tasks"
              },
              "next": {
                "title": "Amazon Personalize",
                "permalink": "/docs/concept-extras/amazon-personalize"
              }
            },
            {
              "unversionedId": "concept-extras/amazon-personalize",
              "id": "concept-extras/amazon-personalize",
              "title": "Amazon Personalize",
              "description": "This page is a random dump of my notes on Amazon Personalize. Proceed accordingly.",
              "source": "@site/docs/concept-extras/amazon-personalize.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/amazon-personalize",
              "permalink": "/docs/concept-extras/amazon-personalize",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/amazon-personalize.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Types of Recommender Systems",
                "permalink": "/docs/concept-basics/types-of-recommender-systems"
              },
              "next": {
                "title": "Bias & Fairness",
                "permalink": "/docs/concept-extras/bias-&-fairness"
              }
            },
            {
              "unversionedId": "concept-extras/bias-&-fairness",
              "id": "concept-extras/bias-&-fairness",
              "title": "Bias & Fairness",
              "description": "It can’t be denied that there is bias all around us. A bias is a prejudice against a person or group of people, including, but not limited to their gender, race, and beliefs. Many of these biases arise from emergent behavior in social interactions, events in history, and cultural and political views around the world. These biases affect the data that we collect. Because AI algorithms work with this data, it is an inherent problem that the machine will “learn” these biases. From a technical perspective, we can engineer the system perfectly, but at the end of the day, humans interact with these systems, and it’s our responsibility to minimize bias and prejudice as much as possible. The algorithms we use are only as good as the data provided to them. Understanding the data and the context in which it is being used is the first step in battling bias, and this understanding will help you build better solutions—because you will be well versed in the problem space. Providing balanced data with as little bias as possible should result in better solutions.",
              "source": "@site/docs/concept-extras/bias-&-fairness.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/bias-&-fairness",
              "permalink": "/docs/concept-extras/bias-&-fairness",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/bias-&-fairness.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Amazon Personalize",
                "permalink": "/docs/concept-extras/amazon-personalize"
              },
              "next": {
                "title": "Causal Inference",
                "permalink": "/docs/concept-extras/causal-inference"
              }
            },
            {
              "unversionedId": "concept-extras/causal-inference",
              "id": "concept-extras/causal-inference",
              "title": "Causal Inference",
              "description": "Typical recommender systems frame the recommendation task as either a distance learning problem between pairs of products, or between pairs of users and products, or as a next item prediction problem. However, a recommender system should not only attempt to model organic user behavior but influence it. This is where causal techniques help, potentially via simple modifications of standard matrix factorization methods.",
              "source": "@site/docs/concept-extras/causal-inference.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/causal-inference",
              "permalink": "/docs/concept-extras/causal-inference",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/causal-inference.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Bias & Fairness",
                "permalink": "/docs/concept-extras/bias-&-fairness"
              },
              "next": {
                "title": "Cold Start",
                "permalink": "/docs/concept-extras/cold-start"
              }
            },
            {
              "unversionedId": "concept-extras/cold-start",
              "id": "concept-extras/cold-start",
              "title": "Cold Start",
              "description": "One long-standing challenge for Collaborative Filtering (CF) based recommendation methods is the cold start problem, i.e., to provide recommendations for new users or items who have no historical interaction record. The cold start problem is common in real world applications. For example, 500 hours of new videos are uploaded to YouTube every minute, 500,000 new users register in Facebook every day, and web/mobile apps face the daily challenge of onboarding new users and subscribers. To provide recommendations for these new users and items, many content-based methods and heuristic methods have been deployed, e.g., recommending popular items or geographically near items. However, recent research efforts that tackle the cold start problem from the perspective of machine learning have made promising strides.",
              "source": "@site/docs/concept-extras/cold-start.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/cold-start",
              "permalink": "/docs/concept-extras/cold-start",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/cold-start.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Causal Inference",
                "permalink": "/docs/concept-extras/causal-inference"
              },
              "next": {
                "title": "Cross-domain",
                "permalink": "/docs/concept-extras/cross-domain"
              }
            },
            {
              "unversionedId": "concept-extras/cross-domain",
              "id": "concept-extras/cross-domain",
              "title": "Cross-domain",
              "description": "A common challenge for most current recommender systems is the cold-start problem. Due to the lack of user-item interactions, the fine-tuned recommender systems are unable to handle situations with new users or new items. Recently, some works introduce the meta-optimization idea into the recommendation scenarios, i.e. predicting the user preference by only a few of past interacted items. The core idea is learning a global sharing initialization parameter for all users and then learning the local parameters for each user separately. However, most meta-learning based recommendation approaches adopt model-agnostic meta-learning for parameter initialization, where the global sharing parameter may lead the model into local optima for some users.",
              "source": "@site/docs/concept-extras/cross-domain.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/cross-domain",
              "permalink": "/docs/concept-extras/cross-domain",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/cross-domain.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Cold Start",
                "permalink": "/docs/concept-extras/cold-start"
              },
              "next": {
                "title": "Data Science",
                "permalink": "/docs/concept-extras/data-science"
              }
            },
            {
              "unversionedId": "concept-extras/data-science",
              "id": "concept-extras/data-science",
              "title": "Data Science",
              "description": "Data science is used in a variety of ways. Some data scientists focus on the analytics side of things, pulling out hidden patterns and insights from data, then communicating these results with visualizations and statistics. Others work on creating predictive models in order to predict future events, such as predicting whether someone will put solar panels on their house. Yet others work on models for classification; for example, classifying the make and model of a car in an image. One thing ties all applications of data science together: the data. Anywhere you have enough data, you can use data science to accomplish things that seem like magic to the casual observer.",
              "source": "@site/docs/concept-extras/data-science.md",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/data-science",
              "permalink": "/docs/concept-extras/data-science",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/data-science.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Cross-domain",
                "permalink": "/docs/concept-extras/cross-domain"
              },
              "next": {
                "title": "Diversity",
                "permalink": "/docs/concept-extras/diversity"
              }
            },
            {
              "unversionedId": "concept-extras/diversity",
              "id": "concept-extras/diversity",
              "title": "Diversity",
              "description": "Individual-level diversity and System-level diversity",
              "source": "@site/docs/concept-extras/diversity.md",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/diversity",
              "permalink": "/docs/concept-extras/diversity",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/diversity.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Data Science",
                "permalink": "/docs/concept-extras/data-science"
              },
              "next": {
                "title": "Emerging Concepts in Recommender Systems",
                "permalink": "/docs/concept-extras/emerging-concepts-in-recommender-systems"
              }
            },
            {
              "unversionedId": "concept-extras/emerging-concepts-in-recommender-systems",
              "id": "concept-extras/emerging-concepts-in-recommender-systems",
              "title": "Emerging Concepts in Recommender Systems",
              "description": "Real-time Learning and Inference",
              "source": "@site/docs/concept-extras/emerging-concepts-in-recommender-systems.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/emerging-concepts-in-recommender-systems",
              "permalink": "/docs/concept-extras/emerging-concepts-in-recommender-systems",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/emerging-concepts-in-recommender-systems.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Diversity",
                "permalink": "/docs/concept-extras/diversity"
              },
              "next": {
                "title": "Graph Embeddings",
                "permalink": "/docs/concept-extras/graph-embeddings"
              }
            },
            {
              "unversionedId": "concept-extras/graph-embeddings",
              "id": "concept-extras/graph-embeddings",
              "title": "Graph Embeddings",
              "description": "Due to their nature, graphs can be analyzed at different levels of granularity: at the node, edge, and graph level (the whole graph), as depicted in the following figure. For each of those levels, different problems could be faced and, as a consequence, specific algorithms should be used.",
              "source": "@site/docs/concept-extras/graph-embeddings.md",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/graph-embeddings",
              "permalink": "/docs/concept-extras/graph-embeddings",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/graph-embeddings.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Emerging Concepts in Recommender Systems",
                "permalink": "/docs/concept-extras/emerging-concepts-in-recommender-systems"
              },
              "next": {
                "title": "Incremental Learning",
                "permalink": "/docs/concept-extras/incremental-learning"
              }
            },
            {
              "unversionedId": "concept-extras/incremental-learning",
              "id": "concept-extras/incremental-learning",
              "title": "Incremental Learning",
              "description": "Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference.",
              "source": "@site/docs/concept-extras/incremental-learning.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/incremental-learning",
              "permalink": "/docs/concept-extras/incremental-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/incremental-learning.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Graph Embeddings",
                "permalink": "/docs/concept-extras/graph-embeddings"
              },
              "next": {
                "title": "Jensen–Shannon divergence",
                "permalink": "/docs/concept-extras/jensen-shannon-divergence"
              }
            },
            {
              "unversionedId": "concept-extras/jensen-shannon-divergence",
              "id": "concept-extras/jensen-shannon-divergence",
              "title": "Jensen–Shannon divergence",
              "description": "In probability theory and statistics, the **Jensen)–Shannon divergence* is a method of measuring the similarity between two probability distributions. It is also known as *information radius* (IRad)[1] or *total divergence to the average**.[2] It is based on the Kullback–Leibler divergence, with some notable (and useful) differences, including that it is symmetric and it always has a finite value. The square root of the Jensen–Shannon divergence is a metric) often referred to as Jensen-Shannon distance.",
              "source": "@site/docs/concept-extras/jensen-shannon-divergence.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/jensen-shannon-divergence",
              "permalink": "/docs/concept-extras/jensen-shannon-divergence",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/jensen-shannon-divergence.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Incremental Learning",
                "permalink": "/docs/concept-extras/incremental-learning"
              },
              "next": {
                "title": "Meta Learning",
                "permalink": "/docs/concept-extras/meta-learning"
              }
            },
            {
              "unversionedId": "concept-extras/meta-learning",
              "id": "concept-extras/meta-learning",
              "title": "Meta Learning",
              "description": "Meta learning covers a wide range of topics and has contributed to a booming study trend. Few-shot learning is one of successful branches of meta learning. We retrospect some representative meta-learning models with strong connections to our work.",
              "source": "@site/docs/concept-extras/meta-learning.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/meta-learning",
              "permalink": "/docs/concept-extras/meta-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/meta-learning.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Jensen–Shannon divergence",
                "permalink": "/docs/concept-extras/jensen-shannon-divergence"
              },
              "next": {
                "title": "MLOps",
                "permalink": "/docs/concept-extras/mlops"
              }
            },
            {
              "unversionedId": "concept-extras/mlops",
              "id": "concept-extras/mlops",
              "title": "MLOps",
              "description": "The boom in AI has seen a rising demand for better AI infrastructure — both in the compute hardware layer and AI framework optimizations that make optimal use of accelerated compute. Unfortunately, organizations often overlook the critical importance of a middle tier: infrastructure software that standardizes the ML life cycle, adding a common platform for teams of data scientists and researchers to standardize their approach and eliminate distracting DevOps work. This process of building the ML life cycle is increasingly known as MLOps, with end-to-end platforms being built to automate and standardize repeatable manual processes. Although dozens of MLOps platforms exist, adopting one can be confusing and cumbersome. What should be considered when employing MLOps? What are the core pillars to MLOps, and which features are most critical?",
              "source": "@site/docs/concept-extras/mlops.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/mlops",
              "permalink": "/docs/concept-extras/mlops",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/mlops.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Meta Learning",
                "permalink": "/docs/concept-extras/meta-learning"
              },
              "next": {
                "title": "Model Deployment",
                "permalink": "/docs/concept-extras/model-deployment"
              }
            },
            {
              "unversionedId": "concept-extras/model-deployment",
              "id": "concept-extras/model-deployment",
              "title": "Model Deployment",
              "description": "modeldeployment",
              "source": "@site/docs/concept-extras/model-deployment.md",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/model-deployment",
              "permalink": "/docs/concept-extras/model-deployment",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/model-deployment.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MLOps",
                "permalink": "/docs/concept-extras/mlops"
              },
              "next": {
                "title": "Model Retraining",
                "permalink": "/docs/concept-extras/model-retraining"
              }
            },
            {
              "unversionedId": "concept-extras/model-retraining",
              "id": "concept-extras/model-retraining",
              "title": "Model Retraining",
              "description": "Concept Drift",
              "source": "@site/docs/concept-extras/model-retraining.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/model-retraining",
              "permalink": "/docs/concept-extras/model-retraining",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/model-retraining.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Model Deployment",
                "permalink": "/docs/concept-extras/model-deployment"
              },
              "next": {
                "title": "Multi-Objective Optimization",
                "permalink": "/docs/concept-extras/multi-objective-optimization"
              }
            },
            {
              "unversionedId": "concept-extras/multi-objective-optimization",
              "id": "concept-extras/multi-objective-optimization",
              "title": "Multi-Objective Optimization",
              "description": "Recommender systems have been widely applied to several domains and applications. Traditional recommender systems usually deal with a single objective, such as minimizing the prediction errors or maximizing the ranking of the recommendation list. There is an emerging demand for multi-objective optimization so that the development of recommendation models can take multiple objectives into consideration, especially in the area of multi-stakeholder and multi-task recommender systems.",
              "source": "@site/docs/concept-extras/multi-objective-optimization.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/multi-objective-optimization",
              "permalink": "/docs/concept-extras/multi-objective-optimization",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/multi-objective-optimization.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Model Retraining",
                "permalink": "/docs/concept-extras/model-retraining"
              },
              "next": {
                "title": "Multi-Task Learning",
                "permalink": "/docs/concept-extras/multi-task-learning"
              }
            },
            {
              "unversionedId": "concept-extras/multi-task-learning",
              "id": "concept-extras/multi-task-learning",
              "title": "Multi-Task Learning",
              "description": "",
              "source": "@site/docs/concept-extras/multi-task-learning.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/multi-task-learning",
              "permalink": "/docs/concept-extras/multi-task-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/multi-task-learning.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Multi-Objective Optimization",
                "permalink": "/docs/concept-extras/multi-objective-optimization"
              },
              "next": {
                "title": "Multi-task Learning",
                "permalink": "/docs/concept-extras/multitask-learning"
              }
            },
            {
              "unversionedId": "concept-extras/multitask-learning",
              "id": "concept-extras/multitask-learning",
              "title": "Multi-task Learning",
              "description": "Generally, as soon as you find yourself optimizing more than one loss function, you are effectively doing multi-task learning (in contrast to single-task learning). In those scenarios, it helps to think about what you are trying to do explicitly in terms of MTL and to draw insights from it.",
              "source": "@site/docs/concept-extras/multitask-learning.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/multitask-learning",
              "permalink": "/docs/concept-extras/multitask-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/multitask-learning.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Multi-Task Learning",
                "permalink": "/docs/concept-extras/multi-task-learning"
              },
              "next": {
                "title": "off-policy-learning",
                "permalink": "/docs/concept-extras/off-policy-learning"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/chatbot",
              "id": "concept-extras/nlp/chatbot",
              "title": "Chatbot",
              "description": "/img/content-concepts-raw-nlp-chatbot-img.png",
              "source": "@site/docs/concept-extras/nlp/chatbot.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/chatbot",
              "permalink": "/docs/concept-extras/nlp/chatbot",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/chatbot.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Scalarization",
                "permalink": "/docs/concept-extras/scalarization"
              },
              "next": {
                "title": "Language Modeling",
                "permalink": "/docs/concept-extras/nlp/language-modeling"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/language-modeling",
              "id": "concept-extras/nlp/language-modeling",
              "title": "Language Modeling",
              "description": "Language Models (LMs) estimate the probability of different linguistic units: symbols, tokens, token sequences.",
              "source": "@site/docs/concept-extras/nlp/language-modeling.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/language-modeling",
              "permalink": "/docs/concept-extras/nlp/language-modeling",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/language-modeling.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Chatbot",
                "permalink": "/docs/concept-extras/nlp/chatbot"
              },
              "next": {
                "title": "Named Entity Recognition",
                "permalink": "/docs/concept-extras/nlp/named-entity-recognition"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/named-entity-recognition",
              "id": "concept-extras/nlp/named-entity-recognition",
              "title": "Named Entity Recognition",
              "description": "/img/content-concepts-raw-nlp-named-entity-recognition-img.png",
              "source": "@site/docs/concept-extras/nlp/named-entity-recognition.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/named-entity-recognition",
              "permalink": "/docs/concept-extras/nlp/named-entity-recognition",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/named-entity-recognition.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Language Modeling",
                "permalink": "/docs/concept-extras/nlp/language-modeling"
              },
              "next": {
                "title": "Text Analysis",
                "permalink": "/docs/concept-extras/nlp/text-analysis"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/text-analysis",
              "id": "concept-extras/nlp/text-analysis",
              "title": "Text Analysis",
              "description": "Rapid text analysis can save lives. Let’s consider a real-world incident when US soldiers stormed a terrorist compound. In the compound, they discovered a computer containing terabytes of archived data. The data included documents, text messages, and emails pertaining to terrorist activities. The documents were too numerous to be read by any single human being. Fortunately, the soldiers were equipped with special software that could perform very fast text analysis. The software allowed the soldiers to process all of the text data without even having to leave the compound. The onsite analysis immediately revealed an active terrorist plot in a nearby neighborhood. The soldiers instantly responded to the plot and prevented a terrorist attack.",
              "source": "@site/docs/concept-extras/nlp/text-analysis.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/text-analysis",
              "permalink": "/docs/concept-extras/nlp/text-analysis",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/text-analysis.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Named Entity Recognition",
                "permalink": "/docs/concept-extras/nlp/named-entity-recognition"
              },
              "next": {
                "title": "Text Classification",
                "permalink": "/docs/concept-extras/nlp/text-classification"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/text-classification",
              "id": "concept-extras/nlp/text-classification",
              "title": "Text Classification",
              "description": "/img/content-concepts-raw-text-classification-img.png",
              "source": "@site/docs/concept-extras/nlp/text-classification.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/text-classification",
              "permalink": "/docs/concept-extras/nlp/text-classification",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/text-classification.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Text Analysis",
                "permalink": "/docs/concept-extras/nlp/text-analysis"
              },
              "next": {
                "title": "Text Generation",
                "permalink": "/docs/concept-extras/nlp/text-generation"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/text-generation",
              "id": "concept-extras/nlp/text-generation",
              "title": "Text Generation",
              "description": "Natural language generation (NLG) can actually tell a story – exactly like that of a human analyst – by writing the sentences and paragraphs for you. It can also summarize reports.",
              "source": "@site/docs/concept-extras/nlp/text-generation.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/text-generation",
              "permalink": "/docs/concept-extras/nlp/text-generation",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/text-generation.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Text Classification",
                "permalink": "/docs/concept-extras/nlp/text-classification"
              },
              "next": {
                "title": "Text Similarity",
                "permalink": "/docs/concept-extras/nlp/text-similarity"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/text-similarity",
              "id": "concept-extras/nlp/text-similarity",
              "title": "Text Similarity",
              "description": "/img/content-concepts-raw-nlp-text-similarity-img.png",
              "source": "@site/docs/concept-extras/nlp/text-similarity.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/text-similarity",
              "permalink": "/docs/concept-extras/nlp/text-similarity",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/text-similarity.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Text Generation",
                "permalink": "/docs/concept-extras/nlp/text-generation"
              },
              "next": {
                "title": "Text Style Transfer",
                "permalink": "/docs/concept-extras/nlp/text-style-transfer"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/text-style-transfer",
              "id": "concept-extras/nlp/text-style-transfer",
              "title": "Text Style Transfer",
              "description": "How to adapt the text to different situations, audiences and purposes by making some changes? The style of the text usually includes many aspects such as morphology, grammar, emotion, complexity, fluency, tense, tone and so on.",
              "source": "@site/docs/concept-extras/nlp/text-style-transfer.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/text-style-transfer",
              "permalink": "/docs/concept-extras/nlp/text-style-transfer",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/text-style-transfer.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Text Similarity",
                "permalink": "/docs/concept-extras/nlp/text-similarity"
              },
              "next": {
                "title": "Text Summarization",
                "permalink": "/docs/concept-extras/nlp/text-summarization"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/text-summarization",
              "id": "concept-extras/nlp/text-summarization",
              "title": "Text Summarization",
              "description": "/img/content-concepts-raw-nlp-text-summarization-untitled.png",
              "source": "@site/docs/concept-extras/nlp/text-summarization.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/text-summarization",
              "permalink": "/docs/concept-extras/nlp/text-summarization",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/text-summarization.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Text Style Transfer",
                "permalink": "/docs/concept-extras/nlp/text-style-transfer"
              },
              "next": {
                "title": "Topic Modeling",
                "permalink": "/docs/concept-extras/nlp/topic-modeling"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/topic-modeling",
              "id": "concept-extras/nlp/topic-modeling",
              "title": "Topic Modeling",
              "description": "/img/content-concepts-raw-nlp-topic-modeling-img.png",
              "source": "@site/docs/concept-extras/nlp/topic-modeling.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/topic-modeling",
              "permalink": "/docs/concept-extras/nlp/topic-modeling",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/topic-modeling.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Text Summarization",
                "permalink": "/docs/concept-extras/nlp/text-summarization"
              },
              "next": {
                "title": "Transformers",
                "permalink": "/docs/concept-extras/nlp/transformers"
              }
            },
            {
              "unversionedId": "concept-extras/nlp/transformers",
              "id": "concept-extras/nlp/transformers",
              "title": "Transformers",
              "description": "The old, obsolete, 1980 architecture of Recurrent Neural Networks(RNNs) including the LSTMs were simply not producing good results anymore. In less than two years, transformer models wiped RNNs off the map and even outperformed human baselines for many tasks.",
              "source": "@site/docs/concept-extras/nlp/transformers.mdx",
              "sourceDirName": "concept-extras/nlp",
              "slug": "/concept-extras/nlp/transformers",
              "permalink": "/docs/concept-extras/nlp/transformers",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/nlp/transformers.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Topic Modeling",
                "permalink": "/docs/concept-extras/nlp/topic-modeling"
              },
              "next": {
                "title": "1mg Prod2vec",
                "permalink": "/docs/concept-extras/success-stories/1mg-prod2vec"
              }
            },
            {
              "unversionedId": "concept-extras/off-policy-learning",
              "id": "concept-extras/off-policy-learning",
              "title": "off-policy-learning",
              "description": "",
              "source": "@site/docs/concept-extras/off-policy-learning.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/off-policy-learning",
              "permalink": "/docs/concept-extras/off-policy-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/off-policy-learning.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Multi-task Learning",
                "permalink": "/docs/concept-extras/multitask-learning"
              },
              "next": {
                "title": "Off-Policy Learning",
                "permalink": "/docs/concept-extras/offline-learning"
              }
            },
            {
              "unversionedId": "concept-extras/offline-learning",
              "id": "concept-extras/offline-learning",
              "title": "Off-Policy Learning",
              "description": "Offline Reinforcement Learning",
              "source": "@site/docs/concept-extras/offline-learning.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/offline-learning",
              "permalink": "/docs/concept-extras/offline-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/offline-learning.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "off-policy-learning",
                "permalink": "/docs/concept-extras/off-policy-learning"
              },
              "next": {
                "title": "Scalarization",
                "permalink": "/docs/concept-extras/scalarization"
              }
            },
            {
              "unversionedId": "concept-extras/scalarization",
              "id": "concept-extras/scalarization",
              "title": "Scalarization",
              "description": "| Method | Idea | Scalarization | Characteristic |",
              "source": "@site/docs/concept-extras/scalarization.mdx",
              "sourceDirName": "concept-extras",
              "slug": "/concept-extras/scalarization",
              "permalink": "/docs/concept-extras/scalarization",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/scalarization.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Off-Policy Learning",
                "permalink": "/docs/concept-extras/offline-learning"
              },
              "next": {
                "title": "Chatbot",
                "permalink": "/docs/concept-extras/nlp/chatbot"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/1mg-prod2vec",
              "id": "concept-extras/success-stories/1mg-prod2vec",
              "title": "1mg Prod2vec",
              "description": "Gurgaon (India) based 1mg is an online pharmacy and healthcare platform that offers medicines, lab tests, and doctor consultations. Launched in 2013 as Healthkartplus, 1mg initially focussed on the alternative medicine space with AYUSH products. Over the years, it rebranded itself as 1mg which is an online pharmacy and healthcare platform that offers medicines, lab tests, and doctor consultations. Today, 1mg provides a wide range of healthcare services. 1mg also provides information on medicines. It facilitates lab tests at home. At present, the platform has about 2,000 tests and 120 verified labs listed and users can consult a doctor across 20 specialties. The company earns from its services like diagnostics, sale of medicines, preventive healthcare, and online consultations, as well as through native ads on its platform.",
              "source": "@site/docs/concept-extras/success-stories/1mg-prod2vec.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/1mg-prod2vec",
              "permalink": "/docs/concept-extras/success-stories/1mg-prod2vec",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/1mg-prod2vec.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Transformers",
                "permalink": "/docs/concept-extras/nlp/transformers"
              },
              "next": {
                "title": "Airbnb Experiences",
                "permalink": "/docs/concept-extras/success-stories/airbnb-experiences"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/airbnb-experiences",
              "id": "concept-extras/success-stories/airbnb-experiences",
              "title": "Airbnb Experiences",
              "description": "Machine Learning-Powered Search Ranking of Airbnb Experiences",
              "source": "@site/docs/concept-extras/success-stories/airbnb-experiences.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/airbnb-experiences",
              "permalink": "/docs/concept-extras/success-stories/airbnb-experiences",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/airbnb-experiences.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "1mg Prod2vec",
                "permalink": "/docs/concept-extras/success-stories/1mg-prod2vec"
              },
              "next": {
                "title": "Alipay CTR",
                "permalink": "/docs/concept-extras/success-stories/alipay-ctr"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/alipay-ctr",
              "id": "concept-extras/success-stories/alipay-ctr",
              "title": "Alipay CTR",
              "description": "An online A/B testing was conducted in the production environment of Alipay for 10 days. The candidate items recommended to users include cash reward, coupons, prizes and member credits. The goal is to increase the CTR of the candidate items while constraining the total cost due to limited budget. The recommendation system serves at the scale of tens of millions of users in real traffic, hence the traffic is very expensive in the business view.",
              "source": "@site/docs/concept-extras/success-stories/alipay-ctr.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/alipay-ctr",
              "permalink": "/docs/concept-extras/success-stories/alipay-ctr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/alipay-ctr.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Airbnb Experiences",
                "permalink": "/docs/concept-extras/success-stories/airbnb-experiences"
              },
              "next": {
                "title": "Doordash Contextual Bandit",
                "permalink": "/docs/concept-extras/success-stories/doordash-contextual-bandit"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/doordash-contextual-bandit",
              "id": "concept-extras/success-stories/doordash-contextual-bandit",
              "title": "Doordash Contextual Bandit",
              "description": "Read here on Doordash's blog",
              "source": "@site/docs/concept-extras/success-stories/doordash-contextual-bandit.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/doordash-contextual-bandit",
              "permalink": "/docs/concept-extras/success-stories/doordash-contextual-bandit",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/doordash-contextual-bandit.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Alipay CTR",
                "permalink": "/docs/concept-extras/success-stories/alipay-ctr"
              },
              "next": {
                "title": "Etsy Personalization",
                "permalink": "/docs/concept-extras/success-stories/etsy-personalization"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/etsy-personalization",
              "id": "concept-extras/success-stories/etsy-personalization",
              "title": "Etsy Personalization",
              "description": "Two-sided marketplaces such as eBay, Etsy and Taobao have two distinct groups of customers: buyers who use the platform to seek the most relevant and interesting item to purchase and sellers who view the same platform as a tool to reach out to their audience and grow their business. Additionally, platforms have their own objectives ranging from growing both buyer and seller user bases to revenue maximization. It is not difficult to see that it would be challenging to obtain a globally favorable outcome for all parties. Taking the search experience as an example, any interventions are likely to impact either buyers or sellers unfairly to course correct for a greater perceived need.",
              "source": "@site/docs/concept-extras/success-stories/etsy-personalization.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/etsy-personalization",
              "permalink": "/docs/concept-extras/success-stories/etsy-personalization",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/etsy-personalization.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Doordash Contextual Bandit",
                "permalink": "/docs/concept-extras/success-stories/doordash-contextual-bandit"
              },
              "next": {
                "title": "Huawei AppGallery",
                "permalink": "/docs/concept-extras/success-stories/huawei-appgallery"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/huawei-appgallery",
              "id": "concept-extras/success-stories/huawei-appgallery",
              "title": "Huawei AppGallery",
              "description": "Untitled",
              "source": "@site/docs/concept-extras/success-stories/huawei-appgallery.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/huawei-appgallery",
              "permalink": "/docs/concept-extras/success-stories/huawei-appgallery",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/huawei-appgallery.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Etsy Personalization",
                "permalink": "/docs/concept-extras/success-stories/etsy-personalization"
              },
              "next": {
                "title": "LinkedIn GLMix",
                "permalink": "/docs/concept-extras/success-stories/linkedin-glmix"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/linkedin-glmix",
              "id": "concept-extras/success-stories/linkedin-glmix",
              "title": "LinkedIn GLMix",
              "description": "A snapshot of the LinkedIn jobs homepage.",
              "source": "@site/docs/concept-extras/success-stories/linkedin-glmix.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/linkedin-glmix",
              "permalink": "/docs/concept-extras/success-stories/linkedin-glmix",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/linkedin-glmix.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Huawei AppGallery",
                "permalink": "/docs/concept-extras/success-stories/huawei-appgallery"
              },
              "next": {
                "title": "MarketCloud Real-time",
                "permalink": "/docs/concept-extras/success-stories/marketcloud-real-time"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/marketcloud-real-time",
              "id": "concept-extras/success-stories/marketcloud-real-time",
              "title": "MarketCloud Real-time",
              "description": "Model Training and Deployment",
              "source": "@site/docs/concept-extras/success-stories/marketcloud-real-time.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/marketcloud-real-time",
              "permalink": "/docs/concept-extras/success-stories/marketcloud-real-time",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/marketcloud-real-time.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "LinkedIn GLMix",
                "permalink": "/docs/concept-extras/success-stories/linkedin-glmix"
              },
              "next": {
                "title": "Netflix Personalize Images",
                "permalink": "/docs/concept-extras/success-stories/netflix-personalize-images"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/netflix-personalize-images",
              "id": "concept-extras/success-stories/netflix-personalize-images",
              "title": "Netflix Personalize Images",
              "description": "Read here on Netflix's blog",
              "source": "@site/docs/concept-extras/success-stories/netflix-personalize-images.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/netflix-personalize-images",
              "permalink": "/docs/concept-extras/success-stories/netflix-personalize-images",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/netflix-personalize-images.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MarketCloud Real-time",
                "permalink": "/docs/concept-extras/success-stories/marketcloud-real-time"
              },
              "next": {
                "title": "Pinterest Multi-task Learning",
                "permalink": "/docs/concept-extras/success-stories/pinterest-multi-task-learning"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/pinterest-multi-task-learning",
              "id": "concept-extras/success-stories/pinterest-multi-task-learning",
              "title": "Pinterest Multi-task Learning",
              "description": "Multi-task Learning for Related Products Recommendations at Pinterest",
              "source": "@site/docs/concept-extras/success-stories/pinterest-multi-task-learning.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/pinterest-multi-task-learning",
              "permalink": "/docs/concept-extras/success-stories/pinterest-multi-task-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/pinterest-multi-task-learning.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Netflix Personalize Images",
                "permalink": "/docs/concept-extras/success-stories/netflix-personalize-images"
              },
              "next": {
                "title": "Santander Banking Products",
                "permalink": "/docs/concept-extras/success-stories/santander-banking-products"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/santander-banking-products",
              "id": "concept-extras/success-stories/santander-banking-products",
              "title": "Santander Banking Products",
              "description": "The goal of the bank is to predict which new products customers will purchase. The data starts on 2015–01–28, and has monthly records of the products each customer has, such as a credit card, savings account, etc. In addition, the dataset also records user personal data such as average income, age, gender, and so on. The monthly statistics are provided until 2015–05–28. Finally, the model predicts which additional products a customer will start using from the following month, 2016–06–28. Thus, the dataset spans 17 months from 2015–01–28 to 2016–05–28, and the output set contains only the timestamp corresponding to 2016–06–28. Models are therefore trained on sequences of 16 months to predict products acquired on their respective last month.",
              "source": "@site/docs/concept-extras/success-stories/santander-banking-products.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/santander-banking-products",
              "permalink": "/docs/concept-extras/success-stories/santander-banking-products",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/santander-banking-products.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Pinterest Multi-task Learning",
                "permalink": "/docs/concept-extras/success-stories/pinterest-multi-task-learning"
              },
              "next": {
                "title": "Scribd Real-time",
                "permalink": "/docs/concept-extras/success-stories/scribd-real-time"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/scribd-real-time",
              "id": "concept-extras/success-stories/scribd-real-time",
              "title": "Scribd Real-time",
              "description": "Transformer based model architecture can be applied to recommendation applications as well but recommendation problems are a bit more complex than NLP domain so it needs to be adapted according to the business needs. Therefore, instead of predicting next word based on the past sequence of words, at Scribd, we are interested in predicting what user would like to read next based on rich user interaction history with multiple types of documents and multiple types of interactions, where position in sequence & relative time are both important factors.",
              "source": "@site/docs/concept-extras/success-stories/scribd-real-time.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/scribd-real-time",
              "permalink": "/docs/concept-extras/success-stories/scribd-real-time",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/scribd-real-time.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Santander Banking Products",
                "permalink": "/docs/concept-extras/success-stories/santander-banking-products"
              },
              "next": {
                "title": "Spotify Contextual Bandits",
                "permalink": "/docs/concept-extras/success-stories/spotify-contextual-bandits"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/spotify-contextual-bandits",
              "id": "concept-extras/success-stories/spotify-contextual-bandits",
              "title": "Spotify Contextual Bandits",
              "description": "Read more in this paper",
              "source": "@site/docs/concept-extras/success-stories/spotify-contextual-bandits.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/spotify-contextual-bandits",
              "permalink": "/docs/concept-extras/success-stories/spotify-contextual-bandits",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/spotify-contextual-bandits.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Scribd Real-time",
                "permalink": "/docs/concept-extras/success-stories/scribd-real-time"
              },
              "next": {
                "title": "Spotify RL",
                "permalink": "/docs/concept-extras/success-stories/spotify-rl"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/spotify-rl",
              "id": "concept-extras/success-stories/spotify-rl",
              "title": "Spotify RL",
              "description": "https://towardsdatascience.com/recommendation-system-with-reinforcement-learning-3362cb4422c8",
              "source": "@site/docs/concept-extras/success-stories/spotify-rl.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/spotify-rl",
              "permalink": "/docs/concept-extras/success-stories/spotify-rl",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/spotify-rl.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Spotify Contextual Bandits",
                "permalink": "/docs/concept-extras/success-stories/spotify-contextual-bandits"
              },
              "next": {
                "title": "StitchFix Multi-armed Bandit",
                "permalink": "/docs/concept-extras/success-stories/stitchfix-multi-armed-bandit"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/stitchfix-multi-armed-bandit",
              "id": "concept-extras/success-stories/stitchfix-multi-armed-bandit",
              "title": "StitchFix Multi-armed Bandit",
              "description": "Read more on official blog",
              "source": "@site/docs/concept-extras/success-stories/stitchfix-multi-armed-bandit.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/stitchfix-multi-armed-bandit",
              "permalink": "/docs/concept-extras/success-stories/stitchfix-multi-armed-bandit",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/stitchfix-multi-armed-bandit.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Spotify RL",
                "permalink": "/docs/concept-extras/success-stories/spotify-rl"
              },
              "next": {
                "title": "Taobao BST",
                "permalink": "/docs/concept-extras/success-stories/taobao-bst"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/taobao-bst",
              "id": "concept-extras/success-stories/taobao-bst",
              "title": "Taobao BST",
              "description": "The BST has been deployed in rank stage for Taobao recommendation, which provides recommending service for hundreds of millions of consumers everyday. In this paper, Alibaba described its usage and technical details in Taobao platform.",
              "source": "@site/docs/concept-extras/success-stories/taobao-bst.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/taobao-bst",
              "permalink": "/docs/concept-extras/success-stories/taobao-bst",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/taobao-bst.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "StitchFix Multi-armed Bandit",
                "permalink": "/docs/concept-extras/success-stories/stitchfix-multi-armed-bandit"
              },
              "next": {
                "title": "The Long Tail",
                "permalink": "/docs/concept-extras/success-stories/the-long-tail"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/the-long-tail",
              "id": "concept-extras/success-stories/the-long-tail",
              "title": "The Long Tail",
              "description": "Here is an excerpt from the book The Long Tail by Chris Anderson: \"In 1988, a British mountain climber named Joe Simpson wrote a book called Touching the Void, a harrowing account of near-death in the Peruvian Andes. It got good reviews but, only a modest success, it was soon forgotten. Then, a decade later, a strange thing happened. Jon Krakauer wrote Into Thin Air, another book about a mountain-cämbing tragedy, which became a publishing sensation. Suddenly Touching the Void started to sell again\".",
              "source": "@site/docs/concept-extras/success-stories/the-long-tail.mdx",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/the-long-tail",
              "permalink": "/docs/concept-extras/success-stories/the-long-tail",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/the-long-tail.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Taobao BST",
                "permalink": "/docs/concept-extras/success-stories/taobao-bst"
              },
              "next": {
                "title": "UberEats Personalization",
                "permalink": "/docs/concept-extras/success-stories/ubereats-personalization"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/ubereats-personalization",
              "id": "concept-extras/success-stories/ubereats-personalization",
              "title": "UberEats Personalization",
              "description": "Food Discovery with Uber Eats: Recommending for the Marketplace",
              "source": "@site/docs/concept-extras/success-stories/ubereats-personalization.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/ubereats-personalization",
              "permalink": "/docs/concept-extras/success-stories/ubereats-personalization",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/ubereats-personalization.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Long Tail",
                "permalink": "/docs/concept-extras/success-stories/the-long-tail"
              },
              "next": {
                "title": "Walmart Model Selection",
                "permalink": "/docs/concept-extras/success-stories/walmart-model-selection"
              }
            },
            {
              "unversionedId": "concept-extras/success-stories/walmart-model-selection",
              "id": "concept-extras/success-stories/walmart-model-selection",
              "title": "Walmart Model Selection",
              "description": "In this paper, Walmart researchers briefly discussed their approach and experiment details.",
              "source": "@site/docs/concept-extras/success-stories/walmart-model-selection.md",
              "sourceDirName": "concept-extras/success-stories",
              "slug": "/concept-extras/success-stories/walmart-model-selection",
              "permalink": "/docs/concept-extras/success-stories/walmart-model-selection",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/success-stories/walmart-model-selection.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "UberEats Personalization",
                "permalink": "/docs/concept-extras/success-stories/ubereats-personalization"
              },
              "next": {
                "title": "Facial Analytics",
                "permalink": "/docs/concept-extras/vision/facial-analytics"
              }
            },
            {
              "unversionedId": "concept-extras/vision/facial-analytics",
              "id": "concept-extras/vision/facial-analytics",
              "title": "Facial Analytics",
              "description": "/img/content-concepts-raw-computer-vision-facial-analytics-img.png",
              "source": "@site/docs/concept-extras/vision/facial-analytics.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/facial-analytics",
              "permalink": "/docs/concept-extras/vision/facial-analytics",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/facial-analytics.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Walmart Model Selection",
                "permalink": "/docs/concept-extras/success-stories/walmart-model-selection"
              },
              "next": {
                "title": "Image Segmentation",
                "permalink": "/docs/concept-extras/vision/image-segmentation"
              }
            },
            {
              "unversionedId": "concept-extras/vision/image-segmentation",
              "id": "concept-extras/vision/image-segmentation",
              "title": "Image Segmentation",
              "description": "/img/content-concepts-raw-computer-vision-image-segmentation-slide46.png",
              "source": "@site/docs/concept-extras/vision/image-segmentation.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/image-segmentation",
              "permalink": "/docs/concept-extras/vision/image-segmentation",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/image-segmentation.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Facial Analytics",
                "permalink": "/docs/concept-extras/vision/facial-analytics"
              },
              "next": {
                "title": "Image Similarity",
                "permalink": "/docs/concept-extras/vision/image-similarity"
              }
            },
            {
              "unversionedId": "concept-extras/vision/image-similarity",
              "id": "concept-extras/vision/image-similarity",
              "title": "Image Similarity",
              "description": "/img/content-concepts-raw-computer-vision-image-similarity-slide19.png",
              "source": "@site/docs/concept-extras/vision/image-similarity.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/image-similarity",
              "permalink": "/docs/concept-extras/vision/image-similarity",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/image-similarity.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Image Segmentation",
                "permalink": "/docs/concept-extras/vision/image-segmentation"
              },
              "next": {
                "title": "Object Detection",
                "permalink": "/docs/concept-extras/vision/object-detection"
              }
            },
            {
              "unversionedId": "concept-extras/vision/object-detection",
              "id": "concept-extras/vision/object-detection",
              "title": "Object Detection",
              "description": "/img/content-concepts-raw-computer-vision-object-detection-slide29.png",
              "source": "@site/docs/concept-extras/vision/object-detection.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/object-detection",
              "permalink": "/docs/concept-extras/vision/object-detection",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/object-detection.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Image Similarity",
                "permalink": "/docs/concept-extras/vision/image-similarity"
              },
              "next": {
                "title": "Object Tracking",
                "permalink": "/docs/concept-extras/vision/object-tracking"
              }
            },
            {
              "unversionedId": "concept-extras/vision/object-tracking",
              "id": "concept-extras/vision/object-tracking",
              "title": "Object Tracking",
              "description": "/img/content-concepts-raw-computer-vision-object-tracking-img.png",
              "source": "@site/docs/concept-extras/vision/object-tracking.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/object-tracking",
              "permalink": "/docs/concept-extras/vision/object-tracking",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/object-tracking.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Object Detection",
                "permalink": "/docs/concept-extras/vision/object-detection"
              },
              "next": {
                "title": "Pose Estimation",
                "permalink": "/docs/concept-extras/vision/pose-estimation"
              }
            },
            {
              "unversionedId": "concept-extras/vision/pose-estimation",
              "id": "concept-extras/vision/pose-estimation",
              "title": "Pose Estimation",
              "description": "/img/content-concepts-raw-computer-vision-pose-estimation-slide52.png",
              "source": "@site/docs/concept-extras/vision/pose-estimation.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/pose-estimation",
              "permalink": "/docs/concept-extras/vision/pose-estimation",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/pose-estimation.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Object Tracking",
                "permalink": "/docs/concept-extras/vision/object-tracking"
              },
              "next": {
                "title": "Scene Text Recognition",
                "permalink": "/docs/concept-extras/vision/scene-text-recognition"
              }
            },
            {
              "unversionedId": "concept-extras/vision/scene-text-recognition",
              "id": "concept-extras/vision/scene-text-recognition",
              "title": "Scene Text Recognition",
              "description": "/img/content-concepts-raw-computer-vision-scene-text-recognition-img.png",
              "source": "@site/docs/concept-extras/vision/scene-text-recognition.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/scene-text-recognition",
              "permalink": "/docs/concept-extras/vision/scene-text-recognition",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/scene-text-recognition.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Pose Estimation",
                "permalink": "/docs/concept-extras/vision/pose-estimation"
              },
              "next": {
                "title": "Video Action Recognition",
                "permalink": "/docs/concept-extras/vision/video-action-recognition"
              }
            },
            {
              "unversionedId": "concept-extras/vision/video-action-recognition",
              "id": "concept-extras/vision/video-action-recognition",
              "title": "Video Action Recognition",
              "description": "/img/content-concepts-raw-computer-vision-video-action-recognition-img.png",
              "source": "@site/docs/concept-extras/vision/video-action-recognition.mdx",
              "sourceDirName": "concept-extras/vision",
              "slug": "/concept-extras/vision/video-action-recognition",
              "permalink": "/docs/concept-extras/vision/video-action-recognition",
              "editUrl": "https://github.com/recohut/docs/docs/docs/concept-extras/vision/video-action-recognition.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Scene Text Recognition",
                "permalink": "/docs/concept-extras/vision/scene-text-recognition"
              },
              "next": {
                "title": "Models",
                "permalink": "/docs/models/"
              }
            },
            {
              "unversionedId": "datasets",
              "id": "datasets",
              "title": "Datasets",
              "description": "| Title | Link | Description |",
              "source": "@site/docs/datasets.mdx",
              "sourceDirName": ".",
              "slug": "/datasets",
              "permalink": "/docs/datasets",
              "editUrl": "https://github.com/recohut/docs/docs/docs/datasets.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "River",
                "permalink": "/docs/tools/river"
              },
              "next": {
                "title": "Projects",
                "permalink": "/docs/projects"
              }
            },
            {
              "unversionedId": "intro",
              "id": "intro",
              "title": "Introduction",
              "description": "It is evident that the pace that technology advances have been increased over the last decades. Scientific discoveries and technological growth introduced to people a huge variety of options and possibilities. One of the most important advantages that technology offers is the direct and easy access to information. Nowadays access to vast networks of information is easy and people can be informed about almost anything they desire. Even though ease of access provided people with the ability to acquire the needed information, they are now facing a new obstacle: this of easily finding what they need. On one hand, information abundance covers the majority of needs but on the other hinders accessibility to information truly valuable to the user. The term that describes this phenomenon is “Information Overload”. Often users are presented with seemingly similar information to their inquiry but irrelevant to their actual needs, rendering this way the discovery of the desired knowledge a difficult task. Continuous expanding of information overload necessitated the development of systems that aim to alleviate such problems. Such systems were introduced in order to filter or retrieve the desired information. Recommendation systems is an example. Recommenders aim to filter out all the unnecessary and irrelevant information and present those that fit the user’s needs. This way the user is relieved of the burden of discovering what he needs making this way information truly accessible.",
              "source": "@site/docs/intro.mdx",
              "sourceDirName": ".",
              "slug": "/intro",
              "permalink": "/docs/intro",
              "editUrl": "https://github.com/recohut/docs/docs/docs/intro.mdx",
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1
              },
              "sidebar": "tutorialSidebar",
              "next": {
                "title": "Challenges",
                "permalink": "/docs/concept-basics/challenges"
              }
            },
            {
              "unversionedId": "models/a3c",
              "id": "models/a3c",
              "title": "A3C",
              "description": "A3C stands for Asynchronous Advantage Actor-Critic. The A3C algorithm builds upon the Actor-Critic class of algorithms by using a neural network to approximate the actor (and critic). The actor learns the policy function using a deep neural network, while the critic estimates the value function. The asynchronous nature of the algorithm allows the agent to learn from different parts of the state space, allowing parallel learning and faster convergence. Unlike DQN agents, which use an experience replay memory, the A3C agent uses multiple workers to gather more samples for learning.",
              "source": "@site/docs/models/a3c.md",
              "sourceDirName": "models",
              "slug": "/models/a3c",
              "permalink": "/docs/models/a3c",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/a3c.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Models",
                "permalink": "/docs/models/"
              },
              "next": {
                "title": "AFM",
                "permalink": "/docs/models/afm"
              }
            },
            {
              "unversionedId": "models/afm",
              "id": "models/afm",
              "title": "AFM",
              "description": "AFM stands for Attentional Factorization Machines. It Improves FM by discriminating the importance of different feature interactions, and learns the importance of each feature interaction from data via a neural attention network. Empirically, it is shown on regression task that AFM performs betters than FM with a 8.6% relative improvement, and consistently outperforms the state-of-the-art deep learning methods Wide&Deep and DeepCross with a much simpler structure and fewer model parameters.",
              "source": "@site/docs/models/afm.md",
              "sourceDirName": "models",
              "slug": "/models/afm",
              "permalink": "/docs/models/afm",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/afm.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "A3C",
                "permalink": "/docs/models/a3c"
              },
              "next": {
                "title": "AFN",
                "permalink": "/docs/models/afn"
              }
            },
            {
              "unversionedId": "models/afn",
              "id": "models/afn",
              "title": "AFN",
              "description": "AFN stands for Adaptive Factorization Network.",
              "source": "@site/docs/models/afn.md",
              "sourceDirName": "models",
              "slug": "/models/afn",
              "permalink": "/docs/models/afn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/afn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "AFM",
                "permalink": "/docs/models/afm"
              },
              "next": {
                "title": "AR",
                "permalink": "/docs/models/ar"
              }
            },
            {
              "unversionedId": "models/ar",
              "id": "models/ar",
              "title": "AR",
              "description": "Simple Association Rules (AR) are a simplified version of the association rule mining technique [Agrawal et al. 1993] with a maximum rule size of two. The method is designed to capture the frequency of two co-occurring events, e.g., “Customers who bought . . . also bought”.",
              "source": "@site/docs/models/ar.md",
              "sourceDirName": "models",
              "slug": "/models/ar",
              "permalink": "/docs/models/ar",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/ar.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "AFN",
                "permalink": "/docs/models/afn"
              },
              "next": {
                "title": "ASMG",
                "permalink": "/docs/models/asmg"
              }
            },
            {
              "unversionedId": "models/asmg",
              "id": "models/asmg",
              "title": "ASMG",
              "description": "ASMG stands for Adaptive Sequential Model Generation.",
              "source": "@site/docs/models/asmg.md",
              "sourceDirName": "models",
              "slug": "/models/asmg",
              "permalink": "/docs/models/asmg",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/asmg.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "AR",
                "permalink": "/docs/models/ar"
              },
              "next": {
                "title": "AttRec",
                "permalink": "/docs/models/attrec"
              }
            },
            {
              "unversionedId": "models/attrec",
              "id": "models/attrec",
              "title": "AttRec",
              "description": "AttRec stands for Self-Attentive Sequential Recommendation.",
              "source": "@site/docs/models/attrec.md",
              "sourceDirName": "models",
              "slug": "/models/attrec",
              "permalink": "/docs/models/attrec",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/attrec.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "ASMG",
                "permalink": "/docs/models/asmg"
              },
              "next": {
                "title": "AUSH",
                "permalink": "/docs/models/aush"
              }
            },
            {
              "unversionedId": "models/aush",
              "id": "models/aush",
              "title": "AUSH",
              "description": "Attacking Recommender Systems with Augmented User Profiles",
              "source": "@site/docs/models/aush.mdx",
              "sourceDirName": "models",
              "slug": "/models/aush",
              "permalink": "/docs/models/aush",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/aush.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "AttRec",
                "permalink": "/docs/models/attrec"
              },
              "next": {
                "title": "AutoInt",
                "permalink": "/docs/models/autoint"
              }
            },
            {
              "unversionedId": "models/autoint",
              "id": "models/autoint",
              "title": "AutoInt",
              "description": "Song et. al., “Automatic Feature Interaction Learning via Self-Attentive Neural Networks”. CIKM, 2018.",
              "source": "@site/docs/models/autoint.md",
              "sourceDirName": "models",
              "slug": "/models/autoint",
              "permalink": "/docs/models/autoint",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/autoint.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "AUSH",
                "permalink": "/docs/models/aush"
              },
              "next": {
                "title": "BASR",
                "permalink": "/docs/models/basr"
              }
            },
            {
              "unversionedId": "models/basr",
              "id": "models/basr",
              "title": "BASR",
              "description": "Black-Box Attacks on Sequential Recommenders via Data-Free Model Extraction",
              "source": "@site/docs/models/basr.mdx",
              "sourceDirName": "models",
              "slug": "/models/basr",
              "permalink": "/docs/models/basr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/basr.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "AutoInt",
                "permalink": "/docs/models/autoint"
              },
              "next": {
                "title": "BCQ",
                "permalink": "/docs/models/bcq"
              }
            },
            {
              "unversionedId": "models/bcq",
              "id": "models/bcq",
              "title": "BCQ",
              "description": "Current off-policy deep reinforcement learning algorithms fail to address extrapolation error by selecting actions with respect to a learned value estimate, without consideration of the accuracy of the estimate. As a result, certain outof-distribution actions can be erroneously extrapolated to higher values. However, the value of an off-policy agent can be accurately evaluated in regions where data is available.",
              "source": "@site/docs/models/bcq.md",
              "sourceDirName": "models",
              "slug": "/models/bcq",
              "permalink": "/docs/models/bcq",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/bcq.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "BASR",
                "permalink": "/docs/models/basr"
              },
              "next": {
                "title": "Behavior Propensity Modeling",
                "permalink": "/docs/models/beh-prop"
              }
            },
            {
              "unversionedId": "models/beh-prop",
              "id": "models/beh-prop",
              "title": "Behavior Propensity Modeling",
              "description": "behavior-propensity-modeling",
              "source": "@site/docs/models/beh-prop.mdx",
              "sourceDirName": "models",
              "slug": "/models/beh-prop",
              "permalink": "/docs/models/beh-prop",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/beh-prop.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "BCQ",
                "permalink": "/docs/models/bcq"
              },
              "next": {
                "title": "BiasOnly",
                "permalink": "/docs/models/biasonly"
              }
            },
            {
              "unversionedId": "models/biasonly",
              "id": "models/biasonly",
              "title": "BiasOnly",
              "description": "BiasOnly is a simple baseline that assumes no interactions between users and items. Formally, it learns: (1) a global bias 𝛼; (2) scalar biases $\\betau$ for each user 𝑢 ∈ U; and (3) scalar biases $\\betai$ for each item 𝑖 ∈ I. Ultimately, the rating/relevance for user 𝑢 and item 𝑖 is modeled as $\\hati^u = \\alpha + \\betau + \\beta_i$.",
              "source": "@site/docs/models/biasonly.md",
              "sourceDirName": "models",
              "slug": "/models/biasonly",
              "permalink": "/docs/models/biasonly",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/biasonly.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Behavior Propensity Modeling",
                "permalink": "/docs/models/beh-prop"
              },
              "next": {
                "title": "BigGraph",
                "permalink": "/docs/models/biggraph"
              }
            },
            {
              "unversionedId": "models/biggraph",
              "id": "models/biggraph",
              "title": "BigGraph",
              "description": "PyTorch-BigGraph: A Large-scale Graph Embedding System",
              "source": "@site/docs/models/biggraph.mdx",
              "sourceDirName": "models",
              "slug": "/models/biggraph",
              "permalink": "/docs/models/biggraph",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/biggraph.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "BiasOnly",
                "permalink": "/docs/models/biasonly"
              },
              "next": {
                "title": "BPR",
                "permalink": "/docs/models/bpr"
              }
            },
            {
              "unversionedId": "models/bpr",
              "id": "models/bpr",
              "title": "BPR",
              "description": "BPR stands for Bayesian Personalized Ranking. In matrix factorization (MF), to compute the prediction we have to multiply the user factors to the item factors:",
              "source": "@site/docs/models/bpr.md",
              "sourceDirName": "models",
              "slug": "/models/bpr",
              "permalink": "/docs/models/bpr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/bpr.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "BigGraph",
                "permalink": "/docs/models/biggraph"
              },
              "next": {
                "title": "BST",
                "permalink": "/docs/models/bst"
              }
            },
            {
              "unversionedId": "models/bst",
              "id": "models/bst",
              "title": "BST",
              "description": "It stands for Behavior Sequence Transformer.",
              "source": "@site/docs/models/bst.mdx",
              "sourceDirName": "models",
              "slug": "/models/bst",
              "permalink": "/docs/models/bst",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/bst.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "BPR",
                "permalink": "/docs/models/bpr"
              },
              "next": {
                "title": "CASER",
                "permalink": "/docs/models/caser"
              }
            },
            {
              "unversionedId": "models/caser",
              "id": "models/caser",
              "title": "CASER",
              "description": "CASER stands for Convolutional Sequence Embedding Recommendation. Top-N sequential recommendation models each user as a sequence of items interacted in the past and aims to predict top-N ranked items that a user will likely interact in a 'near future'. The order of interaction implies that sequential patterns play an important role where more recent items in a sequence have a larger impact on the next item. Convolutional Sequence Embedding Recommendation Model (Caser) address this requirement by embedding a sequence of recent items into an image' in the time and latent spaces and learn sequential patterns as local features of the image using convolutional filters. This approach provides a unified and flexible network structure for capturing both general preferences and sequential patterns. In other words, Caser adopts convolutional neural networks capture the dynamic pattern influences of users’ recent activities.",
              "source": "@site/docs/models/caser.md",
              "sourceDirName": "models",
              "slug": "/models/caser",
              "permalink": "/docs/models/caser",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/caser.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "BST",
                "permalink": "/docs/models/bst"
              },
              "next": {
                "title": "CIGC",
                "permalink": "/docs/models/cigc"
              }
            },
            {
              "unversionedId": "models/cigc",
              "id": "models/cigc",
              "title": "CIGC",
              "description": "To pursue high efficiency, we set the target as using only new data for model updating, meanwhile not sacrificing the recommendation accuracy compared with full model retraining. This is non-trivial to achieve, since the interaction data participates in both the graph structure for model construction and the loss function for model learning, whereas the old graph structure is not allowed to use in model updating. Causal Incremental Graph Convolution (CIGC) estimates the output of full graph convolution. Incremental Graph Convolution (IGC) ingeniously combine the old representations and the incremental graph and effectively fuse the long-term and short-term preference signals. Colliding Effect Distillation (CED) aims to avoid the out-of-date issue of inactive nodes that are not in the incremental graph, which connects the new data with inactive nodes through causal inference. In particular, CED estimates the causal effect of new data on the representation of inactive nodes through the control of their collider.",
              "source": "@site/docs/models/cigc.mdx",
              "sourceDirName": "models",
              "slug": "/models/cigc",
              "permalink": "/docs/models/cigc",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/cigc.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "CASER",
                "permalink": "/docs/models/caser"
              },
              "next": {
                "title": "CoKE",
                "permalink": "/docs/models/coke"
              }
            },
            {
              "unversionedId": "models/coke",
              "id": "models/coke",
              "title": "CoKE",
              "description": "Contextualized Knowledge Graph Embedding",
              "source": "@site/docs/models/coke.mdx",
              "sourceDirName": "models",
              "slug": "/models/coke",
              "permalink": "/docs/models/coke",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/coke.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "CIGC",
                "permalink": "/docs/models/cigc"
              },
              "next": {
                "title": "DCN",
                "permalink": "/docs/models/dcn"
              }
            },
            {
              "unversionedId": "models/dcn",
              "id": "models/dcn",
              "title": "DCN",
              "description": "DCN stands for Deep and Cross Network. Manual explicit feature crossing process is very laborious and inefficient. On the other hand, automatic implicit feature crossing methods like MLPs cannot efficiently approximate even 2nd or 3rd-order feature crosses. Deep-cross networks provides a solution to this problem. DCN was designed to learn explicit and bounded-degree cross features more effectively. It starts with an input layer (typically an embedding layer), followed by a cross network containing multiple cross layers that models explicit feature interactions, and then combines with a deep network that models implicit feature interactions.",
              "source": "@site/docs/models/dcn.md",
              "sourceDirName": "models",
              "slug": "/models/dcn",
              "permalink": "/docs/models/dcn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dcn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "CoKE",
                "permalink": "/docs/models/coke"
              },
              "next": {
                "title": "DDPG",
                "permalink": "/docs/models/ddpg"
              }
            },
            {
              "unversionedId": "models/ddpg",
              "id": "models/ddpg",
              "title": "DDPG",
              "description": "Deterministic Policy Gradient (DPG) is a type of Actor-Critic RL algorithm that uses two neural networks: one for estimating the action value function, and the other for estimating the optimal target policy. The Deep Deterministic Policy Gradient (DDPG) agent builds upon the idea of DPG and is quite efficient compared to vanilla Actor-Critic agents due to the use of deterministic action policies.",
              "source": "@site/docs/models/ddpg.md",
              "sourceDirName": "models",
              "slug": "/models/ddpg",
              "permalink": "/docs/models/ddpg",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/ddpg.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DCN",
                "permalink": "/docs/models/dcn"
              },
              "next": {
                "title": "DeepCross",
                "permalink": "/docs/models/deepcross"
              }
            },
            {
              "unversionedId": "models/deepcross",
              "id": "models/deepcross",
              "title": "DeepCross",
              "description": "Shan, Y., Hoens, T., Jiao, J., Wang, H., Yu, D. and Mao, J., 2016. Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features. [online] Kdd.org.",
              "source": "@site/docs/models/deepcross.md",
              "sourceDirName": "models",
              "slug": "/models/deepcross",
              "permalink": "/docs/models/deepcross",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/deepcross.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DDPG",
                "permalink": "/docs/models/ddpg"
              },
              "next": {
                "title": "DeepFM",
                "permalink": "/docs/models/deepfm"
              }
            },
            {
              "unversionedId": "models/deepfm",
              "id": "models/deepfm",
              "title": "DeepFM",
              "description": "DeepFM stands for Deep Factorization Machines. It consists of an FM component and a deep component which are integrated in a parallel structure. The FM component is the same as the 2-way factorization machines which is used to model the low-order feature interactions. The deep component is a multi-layered perceptron that is used to capture high-order feature interactions and nonlinearities. These two components share the same inputs/embeddings and their outputs are summed up as the final prediction.",
              "source": "@site/docs/models/deepfm.md",
              "sourceDirName": "models",
              "slug": "/models/deepfm",
              "permalink": "/docs/models/deepfm",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/deepfm.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DeepCross",
                "permalink": "/docs/models/deepcross"
              },
              "next": {
                "title": "DeepWalk",
                "permalink": "/docs/models/deepwalk"
              }
            },
            {
              "unversionedId": "models/deepwalk",
              "id": "models/deepwalk",
              "title": "DeepWalk",
              "description": "DeepWalk learns representations of online social networks graphs. By performing random walks to generate sequences, the paper demonstrated that it was able to learn vector representations of nodes (e.g., profiles, content) in the graph.",
              "source": "@site/docs/models/deepwalk.mdx",
              "sourceDirName": "models",
              "slug": "/models/deepwalk",
              "permalink": "/docs/models/deepwalk",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/deepwalk.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DeepFM",
                "permalink": "/docs/models/deepfm"
              },
              "next": {
                "title": "DGTN",
                "permalink": "/docs/models/dgtn"
              }
            },
            {
              "unversionedId": "models/dgtn",
              "id": "models/dgtn",
              "title": "DGTN",
              "description": "DGTN stands for Dual-channel Graph Transition Network.",
              "source": "@site/docs/models/dgtn.md",
              "sourceDirName": "models",
              "slug": "/models/dgtn",
              "permalink": "/docs/models/dgtn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dgtn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DeepWalk",
                "permalink": "/docs/models/deepwalk"
              },
              "next": {
                "title": "DM",
                "permalink": "/docs/models/dm"
              }
            },
            {
              "unversionedId": "models/dm",
              "id": "models/dm",
              "title": "DM",
              "description": "The direct method (DM) involves training a model on the historical data to predict the reward for each context-action instance. In this model, the reward is the target variable, while the context and action are the input features. Using this model, we can predict the rewards for each context-action instance associated with the target policy. This is illustrated below.",
              "source": "@site/docs/models/dm.mdx",
              "sourceDirName": "models",
              "slug": "/models/dm",
              "permalink": "/docs/models/dm",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dm.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DGTN",
                "permalink": "/docs/models/dgtn"
              },
              "next": {
                "title": "DMT",
                "permalink": "/docs/models/dmt"
              }
            },
            {
              "unversionedId": "models/dmt",
              "id": "models/dmt",
              "title": "DMT",
              "description": "Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems.",
              "source": "@site/docs/models/dmt.mdx",
              "sourceDirName": "models",
              "slug": "/models/dmt",
              "permalink": "/docs/models/dmt",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dmt.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DM",
                "permalink": "/docs/models/dm"
              },
              "next": {
                "title": "DPADL",
                "permalink": "/docs/models/dpadl"
              }
            },
            {
              "unversionedId": "models/dpadl",
              "id": "models/dpadl",
              "title": "DPADL",
              "description": "Data Poisoning Attacks to Deep Learning Based Recommender Systems",
              "source": "@site/docs/models/dpadl.mdx",
              "sourceDirName": "models",
              "slug": "/models/dpadl",
              "permalink": "/docs/models/dpadl",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dpadl.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DMT",
                "permalink": "/docs/models/dmt"
              },
              "next": {
                "title": "DQN",
                "permalink": "/docs/models/dqn"
              }
            },
            {
              "unversionedId": "models/dqn",
              "id": "models/dqn",
              "title": "DQN",
              "description": "The Q-learning component of DQN was invented in 1989 by Christopher Watkins in his PhD thesis titled “Learning from Delayed Rewards”. Experience replay quickly followed, invented by Long-Ji Lin in 1992. This played a major role in improving the efficiency of Q-learning. In the years that followed, however, there were no major success stories involving deep Q-learning. This is perhaps not surprising given the combination of limited computational power in the 1990s and early 2000s, data-hungry deep learning architectures, and the sparse, noisy, and delayed feedback signals experienced in RL. Progress had to wait for the emergence of general-purpose GPU programming, for example with the launch of CUDA in 2006, and the reignition of interest in deep learning within the machine learning community that began in the mid-2000s and rapidly accelerated after 2012.",
              "source": "@site/docs/models/dqn.md",
              "sourceDirName": "models",
              "slug": "/models/dqn",
              "permalink": "/docs/models/dqn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dqn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DPADL",
                "permalink": "/docs/models/dpadl"
              },
              "next": {
                "title": "Doubly Robust",
                "permalink": "/docs/models/dr"
              }
            },
            {
              "unversionedId": "models/dr",
              "id": "models/dr",
              "title": "Doubly Robust",
              "description": "The doubly robust technique combines the direct method with inverse propensity scores. An intuitive way to think about it is to consider that it uses the predicted rewards from the direct method, and if there is additional information (i.e. exploration and target policy actions match) then the inverse propensity score correction is applied. This is illustrated below.",
              "source": "@site/docs/models/dr.mdx",
              "sourceDirName": "models",
              "slug": "/models/dr",
              "permalink": "/docs/models/dr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dr.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DQN",
                "permalink": "/docs/models/dqn"
              },
              "next": {
                "title": "DRQN",
                "permalink": "/docs/models/drqn"
              }
            },
            {
              "unversionedId": "models/drqn",
              "id": "models/drqn",
              "title": "DRQN",
              "description": "DRQN stands for Deep Recurrent Q-Learning. It is a combination of a recurrent neural network (RNN) and a deep Q-network (DQN). The idea being that the RNN will be able to retain information from states further back in time and incorporate that into predicting better Q values and thus performing better on games that require long term planning.",
              "source": "@site/docs/models/drqn.md",
              "sourceDirName": "models",
              "slug": "/models/drqn",
              "permalink": "/docs/models/drqn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/drqn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Doubly Robust",
                "permalink": "/docs/models/dr"
              },
              "next": {
                "title": "DRR",
                "permalink": "/docs/models/drr"
              }
            },
            {
              "unversionedId": "models/drr",
              "id": "models/drr",
              "title": "DRR",
              "description": "DRR Framework",
              "source": "@site/docs/models/drr.md",
              "sourceDirName": "models",
              "slug": "/models/drr",
              "permalink": "/docs/models/drr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/drr.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DRQN",
                "permalink": "/docs/models/drqn"
              },
              "next": {
                "title": "Dueling DQN",
                "permalink": "/docs/models/dueling-dqn"
              }
            },
            {
              "unversionedId": "models/dueling-dqn",
              "id": "models/dueling-dqn",
              "title": "Dueling DQN",
              "description": "A Dueling DQN agent explicitly estimates two quantities through a modified network architecture:",
              "source": "@site/docs/models/dueling-dqn.md",
              "sourceDirName": "models",
              "slug": "/models/dueling-dqn",
              "permalink": "/docs/models/dueling-dqn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/dueling-dqn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "DRR",
                "permalink": "/docs/models/drr"
              },
              "next": {
                "title": "FFM",
                "permalink": "/docs/models/ffm"
              }
            },
            {
              "unversionedId": "models/ffm",
              "id": "models/ffm",
              "title": "FFM",
              "description": "FFM stands for Field-aware Factorization Machines. In the official FFM paper, it is empirically proven that for large, sparse datasets with many categorical features, FFM performs better. Conversely, for small and dense datasets or numerical datasets, FFM may not be as effective as FM. FFM is also prone to overfitting on the training dataset, hence one should use a standalone validation set and use early stopping when the loss increases.",
              "source": "@site/docs/models/ffm.md",
              "sourceDirName": "models",
              "slug": "/models/ffm",
              "permalink": "/docs/models/ffm",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/ffm.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Dueling DQN",
                "permalink": "/docs/models/dueling-dqn"
              },
              "next": {
                "title": "FGNN",
                "permalink": "/docs/models/fgnn"
              }
            },
            {
              "unversionedId": "models/fgnn",
              "id": "models/fgnn",
              "title": "FGNN",
              "description": "Ruihong Qiu, Jingjing Li, Zi Huang and Hongzhi Yin, “Rethinking the Item Order in Session-based Recommendation with Graph Neural Networks”. CIKM, 2019.",
              "source": "@site/docs/models/fgnn.md",
              "sourceDirName": "models",
              "slug": "/models/fgnn",
              "permalink": "/docs/models/fgnn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/fgnn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "FFM",
                "permalink": "/docs/models/ffm"
              },
              "next": {
                "title": "FM",
                "permalink": "/docs/models/fm"
              }
            },
            {
              "unversionedId": "models/fm",
              "id": "models/fm",
              "title": "FM",
              "description": "Factorization Machines (FMs) are a supervised learning approach that enhances the linear regression model by incorporating the second-order feature interactions. Factorization Machine type algorithms are a combination of linear regression and matrix factorization, the cool idea behind this type of algorithm is it aims model interactions between features (a.k.a attributes, explanatory variables) using factorized parameters. By doing so it has the ability to estimate all interactions between features even with extremely sparse data.",
              "source": "@site/docs/models/fm.md",
              "sourceDirName": "models",
              "slug": "/models/fm",
              "permalink": "/docs/models/fm",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/fm.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "FGNN",
                "permalink": "/docs/models/fgnn"
              },
              "next": {
                "title": "GAT",
                "permalink": "/docs/models/gat"
              }
            },
            {
              "unversionedId": "models/gat",
              "id": "models/gat",
              "title": "GAT",
              "description": "GAT stands for Graph Attention Networks. This is a special GNN model that addresses several key challenges of spectral models, such as poor ability of generalization from a specific graph structure to another and sophisticated computation of matrix inverse. GAT utilizes attention mechanisms to aggregate neighborhood features (embeddings) by specifying different weights to different nodes.",
              "source": "@site/docs/models/gat.mdx",
              "sourceDirName": "models",
              "slug": "/models/gat",
              "permalink": "/docs/models/gat",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/gat.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "FM",
                "permalink": "/docs/models/fm"
              },
              "next": {
                "title": "GC-SAN",
                "permalink": "/docs/models/gc-san"
              }
            },
            {
              "unversionedId": "models/gc-san",
              "id": "models/gc-san",
              "title": "GC-SAN",
              "description": "GC-SAN stands for Graph contextualized self-attention.",
              "source": "@site/docs/models/gc-san.md",
              "sourceDirName": "models",
              "slug": "/models/gc-san",
              "permalink": "/docs/models/gc-san",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/gc-san.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "GAT",
                "permalink": "/docs/models/gat"
              },
              "next": {
                "title": "GCE-GNN",
                "permalink": "/docs/models/gce-gnn"
              }
            },
            {
              "unversionedId": "models/gce-gnn",
              "id": "models/gce-gnn",
              "title": "GCE-GNN",
              "description": "GCE-GNN stands for Global Context Enhanced Graph Neural Networks. It exploit item transitions over all sessions in a more subtle manner for better inferring the user preference of the current session.",
              "source": "@site/docs/models/gce-gnn.md",
              "sourceDirName": "models",
              "slug": "/models/gce-gnn",
              "permalink": "/docs/models/gce-gnn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/gce-gnn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "GC-SAN",
                "permalink": "/docs/models/gc-san"
              },
              "next": {
                "title": "GLMix",
                "permalink": "/docs/models/glmix"
              }
            },
            {
              "unversionedId": "models/glmix",
              "id": "models/glmix",
              "title": "GLMix",
              "description": "Generalized Linear Mixed Effects model (GLMix) decomposes a personalized recommender system into 2 submodels we first train the fixed effects model, and then train random effects models on the residuals after scoring the fixed effects model, and go back to fixed effects model training again until convergence (Zhang et al., 2016).",
              "source": "@site/docs/models/glmix.mdx",
              "sourceDirName": "models",
              "slug": "/models/glmix",
              "permalink": "/docs/models/glmix",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/glmix.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "GCE-GNN",
                "permalink": "/docs/models/gce-gnn"
              },
              "next": {
                "title": "GRU4Rec",
                "permalink": "/docs/models/gru4rec"
              }
            },
            {
              "unversionedId": "models/gru4rec",
              "id": "models/gru4rec",
              "title": "GRU4Rec",
              "description": "It uses session-parallel mini-batch approach where we first create an order for the sessions and then, we use the first event of the first X sessions to form the input of the first mini-batch (the desired output is the second events of our active sessions). The second mini-batch is formed from the second events and so on. If any of the sessions end, the next available session is put in its place. Sessions are assumed to be independent, thus we reset the appropriate hidden state when this switch occurs.",
              "source": "@site/docs/models/gru4rec.md",
              "sourceDirName": "models",
              "slug": "/models/gru4rec",
              "permalink": "/docs/models/gru4rec",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/gru4rec.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "GLMix",
                "permalink": "/docs/models/glmix"
              },
              "next": {
                "title": "HMLET",
                "permalink": "/docs/models/hmlet"
              }
            },
            {
              "unversionedId": "models/hmlet",
              "id": "models/hmlet",
              "title": "HMLET",
              "description": "HMLET stands for Hybrid Method of Linear and nonlinEar collaborative filTering (HMLET, pronounced as Hamlet). It is a GCN-based CF method.",
              "source": "@site/docs/models/hmlet.mdx",
              "sourceDirName": "models",
              "slug": "/models/hmlet",
              "permalink": "/docs/models/hmlet",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/hmlet.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "GRU4Rec",
                "permalink": "/docs/models/gru4rec"
              },
              "next": {
                "title": "IncCTR",
                "permalink": "/docs/models/incctr"
              }
            },
            {
              "unversionedId": "models/incctr",
              "id": "models/incctr",
              "title": "IncCTR",
              "description": "Recently, various deep CTR models are proposed, such as DeepFM, Wide & Deep, PIN, DIN, and DIEN. Generally, deep CTR models include three parts: embedding layer, interaction layer, and prediction layer.",
              "source": "@site/docs/models/incctr.mdx",
              "sourceDirName": "models",
              "slug": "/models/incctr",
              "permalink": "/docs/models/incctr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/incctr.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "HMLET",
                "permalink": "/docs/models/hmlet"
              },
              "next": {
                "title": "IPW",
                "permalink": "/docs/models/ipw"
              }
            },
            {
              "unversionedId": "models/ipw",
              "id": "models/ipw",
              "title": "IPW",
              "description": "Inverse Propensity Weighting",
              "source": "@site/docs/models/ipw.mdx",
              "sourceDirName": "models",
              "slug": "/models/ipw",
              "permalink": "/docs/models/ipw",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/ipw.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "IncCTR",
                "permalink": "/docs/models/incctr"
              },
              "next": {
                "title": "ItemPop",
                "permalink": "/docs/models/itempop"
              }
            },
            {
              "unversionedId": "models/itempop",
              "id": "models/itempop",
              "title": "ItemPop",
              "description": "Itempop is a naïve baseline that simply ranks items according to overall train-set popularity. Note that this method is unaffected by the user for which items are being recommended, and has the same global ranking of all items",
              "source": "@site/docs/models/itempop.md",
              "sourceDirName": "models",
              "slug": "/models/itempop",
              "permalink": "/docs/models/itempop",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/itempop.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "IPW",
                "permalink": "/docs/models/ipw"
              },
              "next": {
                "title": "KHGT",
                "permalink": "/docs/models/khgt"
              }
            },
            {
              "unversionedId": "models/khgt",
              "id": "models/khgt",
              "title": "KHGT",
              "description": "Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation",
              "source": "@site/docs/models/khgt.mdx",
              "sourceDirName": "models",
              "slug": "/models/khgt",
              "permalink": "/docs/models/khgt",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/khgt.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "ItemPop",
                "permalink": "/docs/models/itempop"
              },
              "next": {
                "title": "LESSR",
                "permalink": "/docs/models/lessr"
              }
            },
            {
              "unversionedId": "models/lessr",
              "id": "models/lessr",
              "title": "LESSR",
              "description": "Tianwen Chen and Raymond Chi-Wing Wong, “LESSR: Handling Information Loss of Graph Neural Networks for Session-based Recommendation”. KDD, 2020.",
              "source": "@site/docs/models/lessr.md",
              "sourceDirName": "models",
              "slug": "/models/lessr",
              "permalink": "/docs/models/lessr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/lessr.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "KHGT",
                "permalink": "/docs/models/khgt"
              },
              "next": {
                "title": "LightFM WARP",
                "permalink": "/docs/models/lightfm-warp"
              }
            },
            {
              "unversionedId": "models/lightfm-warp",
              "id": "models/lightfm-warp",
              "title": "LightFM WARP",
              "description": "LightFM is probably the only recommender package implementing the WARP (Weighted Approximate-Rank Pairwise) loss for implicit feedback learning-to-rank. Generally, it performs better than the more popular BPR (Bayesian Personalised Ranking) loss --- often by a large margin.",
              "source": "@site/docs/models/lightfm-warp.md",
              "sourceDirName": "models",
              "slug": "/models/lightfm-warp",
              "permalink": "/docs/models/lightfm-warp",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/lightfm-warp.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "LESSR",
                "permalink": "/docs/models/lessr"
              },
              "next": {
                "title": "LightGCN",
                "permalink": "/docs/models/lightgcn"
              }
            },
            {
              "unversionedId": "models/lightgcn",
              "id": "models/lightgcn",
              "title": "LightGCN",
              "description": "GCN is a representative model of graph neural networks that applies message passing to aggregate neighborhood information. The message passing layer with self-loops is defined as follows:",
              "source": "@site/docs/models/lightgcn.md",
              "sourceDirName": "models",
              "slug": "/models/lightgcn",
              "permalink": "/docs/models/lightgcn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/lightgcn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "LightFM WARP",
                "permalink": "/docs/models/lightfm-warp"
              },
              "next": {
                "title": "LINE",
                "permalink": "/docs/models/line"
              }
            },
            {
              "unversionedId": "models/line",
              "id": "models/line",
              "title": "LINE",
              "description": "Large-scale Information Network Embedding",
              "source": "@site/docs/models/line.md",
              "sourceDirName": "models",
              "slug": "/models/line",
              "permalink": "/docs/models/line",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/line.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "LightGCN",
                "permalink": "/docs/models/lightgcn"
              },
              "next": {
                "title": "LIRD",
                "permalink": "/docs/models/lird"
              }
            },
            {
              "unversionedId": "models/lird",
              "id": "models/lird",
              "title": "LIRD",
              "description": "Existing reinforcement learning recommender methods also could recommend a list of items. E.g. DQN can calculate Q-values of all recalled items separately, and recommend a list of items with highest Q-values. But these recommendations are similar in Euclidean space and we want to find similarity in associative space. For instance, for a bread 🍞, I want egg 🥚, milk 🥛 in my recommendation list instead of white bread 🍞, brown bread 🥪, bun 🫓 etc.",
              "source": "@site/docs/models/lird.md",
              "sourceDirName": "models",
              "slug": "/models/lird",
              "permalink": "/docs/models/lird",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/lird.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "LINE",
                "permalink": "/docs/models/line"
              },
              "next": {
                "title": "Markov Chains",
                "permalink": "/docs/models/markov-chains"
              }
            },
            {
              "unversionedId": "models/markov-chains",
              "id": "models/markov-chains",
              "title": "Markov Chains",
              "description": "Markov chains, named after Andrey Markov, are mathematical systems that hop from one \"state\" (a situation or set of values) to another. For example, if you made a Markov chain model of a baby's behavior, you might include \"playing,\" \"eating\", \"sleeping,\" and \"crying\" as states, which together with other behaviors could form a 'state space': a list of all possible states. In addition, on top of the state space, a Markov chain tells you the probability of hopping, or \"transitioning,\" from one state to any other state---e.g., the chance that a baby currently playing will fall asleep in the next five minutes without crying first.",
              "source": "@site/docs/models/markov-chains.md",
              "sourceDirName": "models",
              "slug": "/models/markov-chains",
              "permalink": "/docs/models/markov-chains",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/markov-chains.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "LIRD",
                "permalink": "/docs/models/lird"
              },
              "next": {
                "title": "MATN",
                "permalink": "/docs/models/matn"
              }
            },
            {
              "unversionedId": "models/matn",
              "id": "models/matn",
              "title": "MATN",
              "description": "Multiplex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network.",
              "source": "@site/docs/models/matn.mdx",
              "sourceDirName": "models",
              "slug": "/models/matn",
              "permalink": "/docs/models/matn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/matn.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Markov Chains",
                "permalink": "/docs/models/markov-chains"
              },
              "next": {
                "title": "MB-GMN",
                "permalink": "/docs/models/mb-gmn"
              }
            },
            {
              "unversionedId": "models/mb-gmn",
              "id": "models/mb-gmn",
              "title": "MB-GMN",
              "description": "MB-GMN stands for Multi-behavior pattern modeling with meta-knowledge learner.",
              "source": "@site/docs/models/mb-gmn.md",
              "sourceDirName": "models",
              "slug": "/models/mb-gmn",
              "permalink": "/docs/models/mb-gmn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/mb-gmn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MATN",
                "permalink": "/docs/models/matn"
              },
              "next": {
                "title": "MDP",
                "permalink": "/docs/models/mdp"
              }
            },
            {
              "unversionedId": "models/mdp",
              "id": "models/mdp",
              "title": "MDP",
              "description": "The Markov decision process (MDP), a reinforcement learning (RL) algorithm, perfectly illustrates how machines have become intelligent in their own unique way. Humans build their decision process on experience. MDPs are memoryless. Humans use logic and reasoning to think problems through. MDPs apply random decisions 100% of the time. Humans think in words, labeling everything they perceive. MDPs have an unsupervised approach that uses no labels or training data. MDPs boost the machine thought process of self-driving cars (SDCs), translation tools, scheduling software, and more. This memoryless, random, and unlabeled machine thought process marks a historical change in the way a former human problem was solved.",
              "source": "@site/docs/models/mdp.mdx",
              "sourceDirName": "models",
              "slug": "/models/mdp",
              "permalink": "/docs/models/mdp",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/mdp.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MB-GMN",
                "permalink": "/docs/models/mb-gmn"
              },
              "next": {
                "title": "MF",
                "permalink": "/docs/models/mf"
              }
            },
            {
              "unversionedId": "models/mf",
              "id": "models/mf",
              "title": "MF",
              "description": "Matrix Factorization is an iterative approach of SVD called Regularized SVD. It uses the gradient-descent method to estimate the resulting matrices. The obtained model will not be a true SVD of the rating-matrix, as the component matrices are no longer orthogonal, but tends to be more accurate at predicting unseen preferences than the standard SVD [Ekstrand et al. 2011].",
              "source": "@site/docs/models/mf.md",
              "sourceDirName": "models",
              "slug": "/models/mf",
              "permalink": "/docs/models/mf",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/mf.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MDP",
                "permalink": "/docs/models/mdp"
              },
              "next": {
                "title": "MIAN",
                "permalink": "/docs/models/mian"
              }
            },
            {
              "unversionedId": "models/mian",
              "id": "models/mian",
              "title": "MIAN",
              "description": "MIAN stands for Multi-Interactive Attention Network. It aggregate multiple information, and gain latent representations through interactions between candidate items and other fine-grained features.",
              "source": "@site/docs/models/mian.md",
              "sourceDirName": "models",
              "slug": "/models/mian",
              "permalink": "/docs/models/mian",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/mian.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MF",
                "permalink": "/docs/models/mf"
              },
              "next": {
                "title": "MMoE",
                "permalink": "/docs/models/mmoe"
              }
            },
            {
              "unversionedId": "models/mmoe",
              "id": "models/mmoe",
              "title": "MMoE",
              "description": "MMoE stands for Multi-gate Mixture-of-Experts.",
              "source": "@site/docs/models/mmoe.mdx",
              "sourceDirName": "models",
              "slug": "/models/mmoe",
              "permalink": "/docs/models/mmoe",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/mmoe.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MIAN",
                "permalink": "/docs/models/mian"
              },
              "next": {
                "title": "MPNN",
                "permalink": "/docs/models/mpnn"
              }
            },
            {
              "unversionedId": "models/models",
              "id": "models/models",
              "title": "Models",
              "description": "CTR Prediction Models",
              "source": "@site/docs/models/models.md",
              "sourceDirName": "models",
              "slug": "/models/",
              "permalink": "/docs/models/",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/models.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Video Action Recognition",
                "permalink": "/docs/concept-extras/vision/video-action-recognition"
              },
              "next": {
                "title": "A3C",
                "permalink": "/docs/models/a3c"
              }
            },
            {
              "unversionedId": "models/mpnn",
              "id": "models/mpnn",
              "title": "MPNN",
              "description": "Message Passing Neural Networks",
              "source": "@site/docs/models/mpnn.mdx",
              "sourceDirName": "models",
              "slug": "/models/mpnn",
              "permalink": "/docs/models/mpnn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/mpnn.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MMoE",
                "permalink": "/docs/models/mmoe"
              },
              "next": {
                "title": "NeuMF",
                "permalink": "/docs/models/neumf"
              }
            },
            {
              "unversionedId": "models/neumf",
              "id": "models/neumf",
              "title": "NeuMF",
              "description": "NMF Leverages the representation power of deep neural-networks to capture nonlinear correlations between user and item embeddings. Formally, the rating/relevance for user 𝑢 and item 𝑖 is modeled as $\\hati^u = \\alpha + \\betau + \\betai + f(\\gammau || \\gammai || \\gammau \\cdot \\gammai)$ where $\\gammau , \\gamma_i \\in \\mathbb{R}^d$, ‘||’ represents the concatenation operation, and $f: \\mathbb{R}^{3d} \\rightarrow \\mathbb{R}$ represents an arbitrarily complex neural network.",
              "source": "@site/docs/models/neumf.md",
              "sourceDirName": "models",
              "slug": "/models/neumf",
              "permalink": "/docs/models/neumf",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/neumf.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "MPNN",
                "permalink": "/docs/models/mpnn"
              },
              "next": {
                "title": "NFM",
                "permalink": "/docs/models/nfm"
              }
            },
            {
              "unversionedId": "models/nfm",
              "id": "models/nfm",
              "title": "NFM",
              "description": "NFM stands for Neural Factorization Machine.",
              "source": "@site/docs/models/nfm.md",
              "sourceDirName": "models",
              "slug": "/models/nfm",
              "permalink": "/docs/models/nfm",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/nfm.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "NeuMF",
                "permalink": "/docs/models/neumf"
              },
              "next": {
                "title": "NGCF",
                "permalink": "/docs/models/ngcf"
              }
            },
            {
              "unversionedId": "models/ngcf",
              "id": "models/ngcf",
              "title": "NGCF",
              "description": "NGCF stands for Neural Graph Collaborative Filtering. This GNN-based approach follows basic operations inherited from the standard GCN to explore the high-order connectivity information. More specifically, NGCF stacks embedding layers and concatenates embeddings obtained in all layers to constitute the final embeddings.",
              "source": "@site/docs/models/ngcf.md",
              "sourceDirName": "models",
              "slug": "/models/ngcf",
              "permalink": "/docs/models/ngcf",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/ngcf.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "NFM",
                "permalink": "/docs/models/nfm"
              },
              "next": {
                "title": "NMRN",
                "permalink": "/docs/models/nmrn"
              }
            },
            {
              "unversionedId": "models/nmrn",
              "id": "models/nmrn",
              "title": "NMRN",
              "description": "NMRN is a streaming recommender model based on neural memory networks with external memories to capture and store both long-term stable interests and short-term dynamic interests in a unified way. An adaptive negative sampling framework based on Generative Adversarial Nets (GAN) is developed to optimize our proposed streaming recommender model, which effectively overcomes the limitations of classical negative sampling approaches and improves the effectiveness of the model parameter inference.",
              "source": "@site/docs/models/nmrn.mdx",
              "sourceDirName": "models",
              "slug": "/models/nmrn",
              "permalink": "/docs/models/nmrn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/nmrn.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "NGCF",
                "permalink": "/docs/models/ngcf"
              },
              "next": {
                "title": "Node2vec",
                "permalink": "/docs/models/node2vec"
              }
            },
            {
              "unversionedId": "models/node2vec",
              "id": "models/node2vec",
              "title": "Node2vec",
              "description": "Nodes in networks could be organized based on communities they belong to (i.e., homophily); in other cases, the organization could be based on the structural roles of nodes in the network (i.e., structural equivalence). For instance, in the below figure, we observe nodes $u$ and $s1$ belonging to the same tightly knit community of nodes, while the nodes $u$ and $s6$ in the two distinct communities share the same structural role of a hub node. Real-world networks commonly exhibit a mixture of such equivalences.",
              "source": "@site/docs/models/node2vec.mdx",
              "sourceDirName": "models",
              "slug": "/models/node2vec",
              "permalink": "/docs/models/node2vec",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/node2vec.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "NMRN",
                "permalink": "/docs/models/nmrn"
              },
              "next": {
                "title": "PNN",
                "permalink": "/docs/models/pnn"
              }
            },
            {
              "unversionedId": "models/pnn",
              "id": "models/pnn",
              "title": "PNN",
              "description": "PNN stands for Product-based Neural Network.",
              "source": "@site/docs/models/pnn.md",
              "sourceDirName": "models",
              "slug": "/models/pnn",
              "permalink": "/docs/models/pnn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/pnn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Node2vec",
                "permalink": "/docs/models/node2vec"
              },
              "next": {
                "title": "PPO",
                "permalink": "/docs/models/ppo"
              }
            },
            {
              "unversionedId": "models/ppo",
              "id": "models/ppo",
              "title": "PPO",
              "description": "The PPO (Proximal Policy Optimization) algorithm was introduced by the OpenAI team in 2017 and quickly became one of the most popular Reinforcement Learning method that pushed all other RL methods at that moment aside. PPO involves collecting a small batch of experiences interacting with the environment and using that batch to update its decision-making policy. Once the policy is updated with that batch, the experiences are thrown away and a newer batch is collected with the newly updated policy. This is the reason why it is an “on-policy learning” approach where the experience samples collected are only useful for updating the current policy.",
              "source": "@site/docs/models/ppo.md",
              "sourceDirName": "models",
              "slug": "/models/ppo",
              "permalink": "/docs/models/ppo",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/ppo.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "PNN",
                "permalink": "/docs/models/pnn"
              },
              "next": {
                "title": "Q-learning",
                "permalink": "/docs/models/q-learning"
              }
            },
            {
              "unversionedId": "models/q-learning",
              "id": "models/q-learning",
              "title": "Q-learning",
              "description": "Q-learning can be applied to model-free RL problems. It supports off-policy learning and therefore provides a practical solution to problems where available experiences were/are collected using some other policy or by some other agent (even humans).",
              "source": "@site/docs/models/q-learning.md",
              "sourceDirName": "models",
              "slug": "/models/q-learning",
              "permalink": "/docs/models/q-learning",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/q-learning.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "PPO",
                "permalink": "/docs/models/ppo"
              },
              "next": {
                "title": "Random Walk",
                "permalink": "/docs/models/random_walk"
              }
            },
            {
              "unversionedId": "models/random_walk",
              "id": "models/random_walk",
              "title": "Random Walk",
              "description": "The term \"random walk\" was first mentioned by Karl Pearson in 1905 in a letter to Nature magazine titled The Problem of the Random Walk. Study of random walks date back even further to the Gambler’s ruin problem, where it could be used to show that a gambler would eventually go bankrupt against an opponent with infinite wealth. It’s only in the last couple of decades, however, that researchers have studied them with respect to networks.",
              "source": "@site/docs/models/random_walk.mdx",
              "sourceDirName": "models",
              "slug": "/models/random_walk",
              "permalink": "/docs/models/random_walk",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/random_walk.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Q-learning",
                "permalink": "/docs/models/q-learning"
              },
              "next": {
                "title": "RKMF",
                "permalink": "/docs/models/rkmf"
              }
            },
            {
              "unversionedId": "models/rkmf",
              "id": "models/rkmf",
              "title": "RKMF",
              "description": "A kernel function allows to transform the product of the factor matrices. Kernels like the s-shaped logistic function allow to impose bounds on the prediction (e.g. one to five stars) while still being differentiable.",
              "source": "@site/docs/models/rkmf.mdx",
              "sourceDirName": "models",
              "slug": "/models/rkmf",
              "permalink": "/docs/models/rkmf",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/rkmf.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Random Walk",
                "permalink": "/docs/models/random_walk"
              },
              "next": {
                "title": "SAC",
                "permalink": "/docs/models/sac"
              }
            },
            {
              "unversionedId": "models/sac",
              "id": "models/sac",
              "title": "SAC",
              "description": "SAS stands for Soft Actor-Critic. It not only boasts of being more sample efficient than traditional RL algorithms but also promises to be robust to brittleness in convergence.",
              "source": "@site/docs/models/sac.md",
              "sourceDirName": "models",
              "slug": "/models/sac",
              "permalink": "/docs/models/sac",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sac.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "RKMF",
                "permalink": "/docs/models/rkmf"
              },
              "next": {
                "title": "SARSA",
                "permalink": "/docs/models/sarsa"
              }
            },
            {
              "unversionedId": "models/sarsa",
              "id": "models/sarsa",
              "title": "SARSA",
              "description": "The SARSA algorithm can be applied to model-free control problems and allows us to optimize the value function of an unknown MDP. SARSA is an on-policy temporal difference learning-based control algorithm. The SARSA algorithm can be summarized as follows:",
              "source": "@site/docs/models/sarsa.md",
              "sourceDirName": "models",
              "slug": "/models/sarsa",
              "permalink": "/docs/models/sarsa",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sarsa.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SAC",
                "permalink": "/docs/models/sac"
              },
              "next": {
                "title": "SASRec",
                "permalink": "/docs/models/sasrec"
              }
            },
            {
              "unversionedId": "models/sasrec",
              "id": "models/sasrec",
              "title": "SASRec",
              "description": "SASRec stands for Self-Attentive Sequential Recommendation. It relies on the sequence modeling capabilities of self-attentive neural networks to predict the occurence of the next item in a user’s consumption sequence. To be precise, given a user 𝑢 and their time-ordered consumption history $S^𝑢 = (S1^u, S2^u, \\dots, S_{|S^u|}^𝑢),$ SASRec first applies self-attention on $S^𝑢$ followed by a series of non-linear feed-forward layers to finally obtain the next item likelihood.",
              "source": "@site/docs/models/sasrec.md",
              "sourceDirName": "models",
              "slug": "/models/sasrec",
              "permalink": "/docs/models/sasrec",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sasrec.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SARSA",
                "permalink": "/docs/models/sarsa"
              },
              "next": {
                "title": "SDNE",
                "permalink": "/docs/models/sdne"
              }
            },
            {
              "unversionedId": "models/sdne",
              "id": "models/sdne",
              "title": "SDNE",
              "description": "Structural Deep Network Embedding",
              "source": "@site/docs/models/sdne.mdx",
              "sourceDirName": "models",
              "slug": "/models/sdne",
              "permalink": "/docs/models/sdne",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sdne.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SASRec",
                "permalink": "/docs/models/sasrec"
              },
              "next": {
                "title": "SGL",
                "permalink": "/docs/models/sgl"
              }
            },
            {
              "unversionedId": "models/sgl",
              "id": "models/sgl",
              "title": "SGL",
              "description": "SGL is the latest baseline for top-k recommendations. It introduces self-supervised learning into the recommendation system based on the contrastive learning framework. It is implemented on LightGCN and uses a multitask approach that unites the contrastive loss and the BPR loss function. SGL mainly benefits from graph contrastive learning to reinforce user and item representations.",
              "source": "@site/docs/models/sgl.md",
              "sourceDirName": "models",
              "slug": "/models/sgl",
              "permalink": "/docs/models/sgl",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sgl.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SDNE",
                "permalink": "/docs/models/sdne"
              },
              "next": {
                "title": "Shared Bottom",
                "permalink": "/docs/models/shared-bottom"
              }
            },
            {
              "unversionedId": "models/shared-bottom",
              "id": "models/shared-bottom",
              "title": "Shared Bottom",
              "description": "The shared-bottom model is the simplest and most common multi-task learning architecture. The model has a single base (the shared bottom) from which all of the task-specific subnetworks begin from. This means that this single representation is used for all tasks, and there is no way for individual tasks to adjust what information they get out of the shared bottom compared to other tasks.",
              "source": "@site/docs/models/shared-bottom.mdx",
              "sourceDirName": "models",
              "slug": "/models/shared-bottom",
              "permalink": "/docs/models/shared-bottom",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/shared-bottom.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SGL",
                "permalink": "/docs/models/sgl"
              },
              "next": {
                "title": "SiReN",
                "permalink": "/docs/models/siren"
              }
            },
            {
              "unversionedId": "models/siren",
              "id": "models/siren",
              "title": "SiReN",
              "description": "Existing literature often ignores the negative feedback e.g. dislikes on YouTube videos, and only capture the homophily (or assortativity) patterns by positive feedback. This is a missed opportunity situation. Performance of GNN-based Recommender Systems can be improved by including negative feedbacks. Disassortivity patterns can be learned by negative feedback. LightGCN can capture the assortativity patterns. and the MLP network can capture the disassortivity patterns.",
              "source": "@site/docs/models/siren.md",
              "sourceDirName": "models",
              "slug": "/models/siren",
              "permalink": "/docs/models/siren",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/siren.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Shared Bottom",
                "permalink": "/docs/models/shared-bottom"
              },
              "next": {
                "title": "SLIST",
                "permalink": "/docs/models/slist"
              }
            },
            {
              "unversionedId": "models/slist",
              "id": "models/slist",
              "title": "SLIST",
              "description": "SLIST stands for Session-aware Linear Similarity/Transition. It is built by unifying two linear models - SLIS and SLIT.",
              "source": "@site/docs/models/slist.md",
              "sourceDirName": "models",
              "slug": "/models/slist",
              "permalink": "/docs/models/slist",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/slist.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SiReN",
                "permalink": "/docs/models/siren"
              },
              "next": {
                "title": "SML",
                "permalink": "/docs/models/sml"
              }
            },
            {
              "unversionedId": "models/sml",
              "id": "models/sml",
              "title": "SML",
              "description": "Problem formulation",
              "source": "@site/docs/models/sml.mdx",
              "sourceDirName": "models",
              "slug": "/models/sml",
              "permalink": "/docs/models/sml",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sml.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SLIST",
                "permalink": "/docs/models/slist"
              },
              "next": {
                "title": "SPop",
                "permalink": "/docs/models/spop"
              }
            },
            {
              "unversionedId": "models/spop",
              "id": "models/spop",
              "title": "SPop",
              "description": "SPop stands for Session-based Popularity. It is a session popularity predictor that gives higher scores to items with higher number of occurrences in the session. Ties are broken up by adding the popularity score of the item.",
              "source": "@site/docs/models/spop.md",
              "sourceDirName": "models",
              "slug": "/models/spop",
              "permalink": "/docs/models/spop",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/spop.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SML",
                "permalink": "/docs/models/sml"
              },
              "next": {
                "title": "SR-GNN",
                "permalink": "/docs/models/sr-gnn"
              }
            },
            {
              "unversionedId": "models/sr",
              "id": "models/sr",
              "title": "SR",
              "description": "SR stands for Sequential Rules. The SR method is a variation of MC and AR. It also takes the order of actions into account, but in a less restrictive manner. In contrast to the MC method, we create a rule when an item q appeared after an item p in a session even when other events happened between p and q. When assigning weights to the rules, we consider the number of elements appearing between p and q in the session.",
              "source": "@site/docs/models/sr.md",
              "sourceDirName": "models",
              "slug": "/models/sr",
              "permalink": "/docs/models/sr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sr.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SR-SAN",
                "permalink": "/docs/models/sr-san"
              },
              "next": {
                "title": "SSE-PT",
                "permalink": "/docs/models/sse-pt"
              }
            },
            {
              "unversionedId": "models/sr-gnn",
              "id": "models/sr-gnn",
              "title": "SR-GNN",
              "description": "SR-GNN stands for Session-based Recommendation with Graph Neural Networks.",
              "source": "@site/docs/models/sr-gnn.md",
              "sourceDirName": "models",
              "slug": "/models/sr-gnn",
              "permalink": "/docs/models/sr-gnn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sr-gnn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SPop",
                "permalink": "/docs/models/spop"
              },
              "next": {
                "title": "SR-SAN",
                "permalink": "/docs/models/sr-san"
              }
            },
            {
              "unversionedId": "models/sr-san",
              "id": "models/sr-san",
              "title": "SR-SAN",
              "description": "SR-SAN stands for Session-based Recommendation with Self-Attention Networks.",
              "source": "@site/docs/models/sr-san.md",
              "sourceDirName": "models",
              "slug": "/models/sr-san",
              "permalink": "/docs/models/sr-san",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sr-san.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SR-GNN",
                "permalink": "/docs/models/sr-gnn"
              },
              "next": {
                "title": "SR",
                "permalink": "/docs/models/sr"
              }
            },
            {
              "unversionedId": "models/sse-pt",
              "id": "models/sse-pt",
              "title": "SSE-PT",
              "description": "Temporal information is crucial for recommendation problems because user preferences are naturally dynamic in the real world. Recent advances in deep learning, especially the discovery of various attention mechanisms and newer architectures in addition to widely used RNN and CNN in natural language processing, have allowed for better use of the temporal ordering of items that each user has engaged with. In particular, the SASRec model, inspired by the popular Transformer model in natural languages processing, has achieved state-of-the-art results. However, SASRec, just like the original Transformer model, is inherently an un-personalized model and does not include personalized user embeddings. SSE-PT overcomes this limitation by employing a Personalized Transformer.",
              "source": "@site/docs/models/sse-pt.mdx",
              "sourceDirName": "models",
              "slug": "/models/sse-pt",
              "permalink": "/docs/models/sse-pt",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/sse-pt.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SR",
                "permalink": "/docs/models/sr"
              },
              "next": {
                "title": "STAMP",
                "permalink": "/docs/models/stamp"
              }
            },
            {
              "unversionedId": "models/stamp",
              "id": "models/stamp",
              "title": "STAMP",
              "description": "/img/content-models-raw-mp2-stamp-untitled.png",
              "source": "@site/docs/models/stamp.md",
              "sourceDirName": "models",
              "slug": "/models/stamp",
              "permalink": "/docs/models/stamp",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/stamp.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SSE-PT",
                "permalink": "/docs/models/sse-pt"
              },
              "next": {
                "title": "Struc2Vec",
                "permalink": "/docs/models/struc2vec"
              }
            },
            {
              "unversionedId": "models/struc2vec",
              "id": "models/struc2vec",
              "title": "Struc2Vec",
              "description": "Learning Node Representations from Structural Identity",
              "source": "@site/docs/models/struc2vec.mdx",
              "sourceDirName": "models",
              "slug": "/models/struc2vec",
              "permalink": "/docs/models/struc2vec",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/struc2vec.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "STAMP",
                "permalink": "/docs/models/stamp"
              },
              "next": {
                "title": "SVAE",
                "permalink": "/docs/models/svae"
              }
            },
            {
              "unversionedId": "models/svae",
              "id": "models/svae",
              "title": "SVAE",
              "description": "SVAE stands for Sequential Variational Autoencoder.",
              "source": "@site/docs/models/svae.md",
              "sourceDirName": "models",
              "slug": "/models/svae",
              "permalink": "/docs/models/svae",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/svae.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Struc2Vec",
                "permalink": "/docs/models/struc2vec"
              },
              "next": {
                "title": "TAaMR",
                "permalink": "/docs/models/taamr"
              }
            },
            {
              "unversionedId": "models/taamr",
              "id": "models/taamr",
              "title": "TAaMR",
              "description": "Targeted Adversarial Attack against Multimedia Recommender Systems",
              "source": "@site/docs/models/taamr.mdx",
              "sourceDirName": "models",
              "slug": "/models/taamr",
              "permalink": "/docs/models/taamr",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/taamr.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "SVAE",
                "permalink": "/docs/models/svae"
              },
              "next": {
                "title": "TAGNN-PP",
                "permalink": "/docs/models/tagnn-pp"
              }
            },
            {
              "unversionedId": "models/tagnn",
              "id": "models/tagnn",
              "title": "TAGNN",
              "description": "TAGNN stands for Target Attentive Graph Neural Network. Session-based recommendations are challenging due to limited user-item interactions. Typical sequential models are not able to capture complex patterns from all previous interactions. SessionGraph (a graph representation of sessions) can capture the complex patterns from all previous interactions.",
              "source": "@site/docs/models/tagnn.md",
              "sourceDirName": "models",
              "slug": "/models/tagnn",
              "permalink": "/docs/models/tagnn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/tagnn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "TAGNN-PP",
                "permalink": "/docs/models/tagnn-pp"
              },
              "next": {
                "title": "VNCF",
                "permalink": "/docs/models/vncf"
              }
            },
            {
              "unversionedId": "models/tagnn-pp",
              "id": "models/tagnn-pp",
              "title": "TAGNN-PP",
              "description": "TAGNN-PP models item interactions with GNN, and both local and global user interactions with  a Transformer.",
              "source": "@site/docs/models/tagnn-pp.md",
              "sourceDirName": "models",
              "slug": "/models/tagnn-pp",
              "permalink": "/docs/models/tagnn-pp",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/tagnn-pp.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "TAaMR",
                "permalink": "/docs/models/taamr"
              },
              "next": {
                "title": "TAGNN",
                "permalink": "/docs/models/tagnn"
              }
            },
            {
              "unversionedId": "models/vncf",
              "id": "models/vncf",
              "title": "VNCF",
              "description": "VNCF stands for Variational Neural Collaborative Filtering.",
              "source": "@site/docs/models/vncf.md",
              "sourceDirName": "models",
              "slug": "/models/vncf",
              "permalink": "/docs/models/vncf",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/vncf.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "TAGNN",
                "permalink": "/docs/models/tagnn"
              },
              "next": {
                "title": "VSKNN",
                "permalink": "/docs/models/vsknn"
              }
            },
            {
              "unversionedId": "models/vsknn",
              "id": "models/vsknn",
              "title": "VSKNN",
              "description": "VSKNN stands for Vector Multiplication Session-Based kNN. The idea of this variant is to put more emphasis on the more recent events of a session when computing the similarities. Instead of encoding a session as a binary vector, we use real-valued vectors to encode the current session. Only the very last element of the session obtains a value of “1”; the weights of the other elements are determined using a linear decay function that depends on the position of the element within the session, where elements appearing earlier in the session obtain a lower weight. As a result, when using the dot product as a similarity function between the current weight-encoded session and a binary-encoded past session, more emphasis is given to elements that appear later in the sessions.",
              "source": "@site/docs/models/vsknn.md",
              "sourceDirName": "models",
              "slug": "/models/vsknn",
              "permalink": "/docs/models/vsknn",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/vsknn.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "VNCF",
                "permalink": "/docs/models/vncf"
              },
              "next": {
                "title": "Wide and Deep",
                "permalink": "/docs/models/wide-and-deep"
              }
            },
            {
              "unversionedId": "models/wide-and-deep",
              "id": "models/wide-and-deep",
              "title": "Wide and Deep",
              "description": "Wide and Deep Learning Model, proposed by Google, 2016, is a DNN-Linear mixed model, which combines the strength of memorization and generalization. It's useful for generic large-scale regression and classification problems with sparse input features (e.g., categorical features with a large number of possible feature values). It has been used for Google App Store for their app recommendation.",
              "source": "@site/docs/models/wide-and-deep.md",
              "sourceDirName": "models",
              "slug": "/models/wide-and-deep",
              "permalink": "/docs/models/wide-and-deep",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/wide-and-deep.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "VSKNN",
                "permalink": "/docs/models/vsknn"
              },
              "next": {
                "title": "Word2vec",
                "permalink": "/docs/models/word2vec"
              }
            },
            {
              "unversionedId": "models/word2vec",
              "id": "models/word2vec",
              "title": "Word2vec",
              "description": "/img/content-models-raw-mp2-word2vec-untitled.png",
              "source": "@site/docs/models/word2vec.md",
              "sourceDirName": "models",
              "slug": "/models/word2vec",
              "permalink": "/docs/models/word2vec",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/word2vec.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Wide and Deep",
                "permalink": "/docs/models/wide-and-deep"
              },
              "next": {
                "title": "xDeepFM",
                "permalink": "/docs/models/xdeepfm"
              }
            },
            {
              "unversionedId": "models/xdeepfm",
              "id": "models/xdeepfm",
              "title": "xDeepFM",
              "description": "xDeepFM stands for Extreme Deep Factorization Machines.",
              "source": "@site/docs/models/xdeepfm.md",
              "sourceDirName": "models",
              "slug": "/models/xdeepfm",
              "permalink": "/docs/models/xdeepfm",
              "editUrl": "https://github.com/recohut/docs/docs/docs/models/xdeepfm.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Word2vec",
                "permalink": "/docs/models/word2vec"
              },
              "next": {
                "title": "Tutorials",
                "permalink": "/docs/tutorials/"
              }
            },
            {
              "unversionedId": "projects",
              "id": "projects",
              "title": "Projects",
              "description": "| Project Id | Title | Links |",
              "source": "@site/docs/projects.mdx",
              "sourceDirName": ".",
              "slug": "/projects",
              "permalink": "/docs/projects",
              "editUrl": "https://github.com/recohut/docs/docs/docs/projects.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Datasets",
                "permalink": "/docs/datasets"
              }
            },
            {
              "unversionedId": "tools/obp",
              "id": "tools/obp",
              "title": "OBP",
              "description": "Process flow",
              "source": "@site/docs/tools/obp.mdx",
              "sourceDirName": "tools",
              "slug": "/tools/obp",
              "permalink": "/docs/tools/obp",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tools/obp.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "TensorFlow 2 Reinforcement Learning Cookbook",
                "permalink": "/docs/tutorials/tensorflow-2-reinforcement-learning-cookbook"
              },
              "next": {
                "title": "River",
                "permalink": "/docs/tools/river"
              }
            },
            {
              "unversionedId": "tools/river",
              "id": "tools/river",
              "title": "River",
              "description": "River is a Python library for online machine learning. It is the result of a merger between creme and scikit-multiflow. River's ambition is to be the go-to library for doing machine learning on streaming data.",
              "source": "@site/docs/tools/river.mdx",
              "sourceDirName": "tools",
              "slug": "/tools/river",
              "permalink": "/docs/tools/river",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tools/river.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "OBP",
                "permalink": "/docs/tools/obp"
              },
              "next": {
                "title": "Datasets",
                "permalink": "/docs/datasets"
              }
            },
            {
              "unversionedId": "tutorials/data-science-bookcamp",
              "id": "tutorials/data-science-bookcamp",
              "title": "Data Science Bookcamp",
              "description": "Key points",
              "source": "@site/docs/tutorials/data-science-bookcamp.md",
              "sourceDirName": "tutorials",
              "slug": "/tutorials/data-science-bookcamp",
              "permalink": "/docs/tutorials/data-science-bookcamp",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tutorials/data-science-bookcamp.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Tutorials",
                "permalink": "/docs/tutorials/"
              },
              "next": {
                "title": "Matching and Ranking models in Tensorflow",
                "permalink": "/docs/tutorials/matching-and-ranking-models-in-tensorflow"
              }
            },
            {
              "unversionedId": "tutorials/matching-and-ranking-models-in-tensorflow",
              "id": "tutorials/matching-and-ranking-models-in-tensorflow",
              "title": "Matching and Ranking models in Tensorflow",
              "description": "Matching models on ML-1m and ranking models on Criteo (sample) dataset in TF v2.5",
              "source": "@site/docs/tutorials/matching-and-ranking-models-in-tensorflow.mdx",
              "sourceDirName": "tutorials",
              "slug": "/tutorials/matching-and-ranking-models-in-tensorflow",
              "permalink": "/docs/tutorials/matching-and-ranking-models-in-tensorflow",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tutorials/matching-and-ranking-models-in-tensorflow.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Data Science Bookcamp",
                "permalink": "/docs/tutorials/data-science-bookcamp"
              },
              "next": {
                "title": "Real-time event capturing with Kafka and MongoDB",
                "permalink": "/docs/tutorials/real-time-event-capturing-with-kafka-and-mongodb"
              }
            },
            {
              "unversionedId": "tutorials/real-time-event-capturing-with-kafka-and-mongodb",
              "id": "tutorials/real-time-event-capturing-with-kafka-and-mongodb",
              "title": "Real-time event capturing with Kafka and MongoDB",
              "description": "| | |",
              "source": "@site/docs/tutorials/real-time-event-capturing-with-kafka-and-mongodb.md",
              "sourceDirName": "tutorials",
              "slug": "/tutorials/real-time-event-capturing-with-kafka-and-mongodb",
              "permalink": "/docs/tutorials/real-time-event-capturing-with-kafka-and-mongodb",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tutorials/real-time-event-capturing-with-kafka-and-mongodb.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Matching and Ranking models in Tensorflow",
                "permalink": "/docs/tutorials/matching-and-ranking-models-in-tensorflow"
              },
              "next": {
                "title": "Session-based Recommendation with Graph Neural Networks",
                "permalink": "/docs/tutorials/session-based-recommendation-with-graph-neural-net"
              }
            },
            {
              "unversionedId": "tutorials/session-based-recommendation-with-graph-neural-net",
              "id": "tutorials/session-based-recommendation-with-graph-neural-net",
              "title": "Session-based Recommendation with Graph Neural Networks",
              "description": "Session-based recommendation tasks are performed based on the user's anonymous historical behavior sequence and implicit feedback data, such as clicks, browsing, purchasing, etc., rather than rating or comment data. The primary aim is to predict the next behavior based on a sequence of the historical sequence of the session. Session-based recommendation aims to predict which item a user will click next, solely based on the user’s current sequential session data without access to the long-term preference profile.",
              "source": "@site/docs/tutorials/session-based-recommendation-with-graph-neural-net.mdx",
              "sourceDirName": "tutorials",
              "slug": "/tutorials/session-based-recommendation-with-graph-neural-net",
              "permalink": "/docs/tutorials/session-based-recommendation-with-graph-neural-net",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tutorials/session-based-recommendation-with-graph-neural-net.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Real-time event capturing with Kafka and MongoDB",
                "permalink": "/docs/tutorials/real-time-event-capturing-with-kafka-and-mongodb"
              },
              "next": {
                "title": "TensorFlow 2 Reinforcement Learning Cookbook",
                "permalink": "/docs/tutorials/tensorflow-2-reinforcement-learning-cookbook"
              }
            },
            {
              "unversionedId": "tutorials/tensorflow-2-reinforcement-learning-cookbook",
              "id": "tutorials/tensorflow-2-reinforcement-learning-cookbook",
              "title": "TensorFlow 2 Reinforcement Learning Cookbook",
              "description": "Process flow",
              "source": "@site/docs/tutorials/tensorflow-2-reinforcement-learning-cookbook.mdx",
              "sourceDirName": "tutorials",
              "slug": "/tutorials/tensorflow-2-reinforcement-learning-cookbook",
              "permalink": "/docs/tutorials/tensorflow-2-reinforcement-learning-cookbook",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tutorials/tensorflow-2-reinforcement-learning-cookbook.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Session-based Recommendation with Graph Neural Networks",
                "permalink": "/docs/tutorials/session-based-recommendation-with-graph-neural-net"
              },
              "next": {
                "title": "OBP",
                "permalink": "/docs/tools/obp"
              }
            },
            {
              "unversionedId": "tutorials/tutorials",
              "id": "tutorials/tutorials",
              "title": "Tutorials",
              "description": "Data pipeline",
              "source": "@site/docs/tutorials/tutorials.mdx",
              "sourceDirName": "tutorials",
              "slug": "/tutorials/",
              "permalink": "/docs/tutorials/",
              "editUrl": "https://github.com/recohut/docs/docs/docs/tutorials/tutorials.mdx",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "xDeepFM",
                "permalink": "/docs/models/xdeepfm"
              },
              "next": {
                "title": "Data Science Bookcamp",
                "permalink": "/docs/tutorials/data-science-bookcamp"
              }
            }
          ],
          "sidebars": {
            "tutorialSidebar": [
              {
                "type": "doc",
                "id": "intro"
              },
              {
                "type": "category",
                "label": "Concept - Basics",
                "collapsible": true,
                "collapsed": true,
                "items": [
                  {
                    "type": "doc",
                    "id": "concept-basics/challenges"
                  },
                  {
                    "type": "doc",
                    "id": "concept-basics/evaluation"
                  },
                  {
                    "type": "doc",
                    "id": "concept-basics/implicit-feedback"
                  },
                  {
                    "type": "doc",
                    "id": "concept-basics/processes"
                  },
                  {
                    "type": "doc",
                    "id": "concept-basics/session-based-recommenders"
                  },
                  {
                    "type": "doc",
                    "id": "concept-basics/tasks"
                  },
                  {
                    "type": "doc",
                    "id": "concept-basics/types-of-recommender-systems"
                  }
                ]
              },
              {
                "type": "category",
                "label": "Concept - Extras",
                "collapsible": true,
                "collapsed": true,
                "items": [
                  {
                    "type": "doc",
                    "id": "concept-extras/amazon-personalize"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/bias-&-fairness"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/causal-inference"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/cold-start"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/cross-domain"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/data-science"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/diversity"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/emerging-concepts-in-recommender-systems"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/graph-embeddings"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/incremental-learning"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/jensen-shannon-divergence"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/meta-learning"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/mlops"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/model-deployment"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/model-retraining"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/multi-objective-optimization"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/multi-task-learning"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/multitask-learning"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/off-policy-learning"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/offline-learning"
                  },
                  {
                    "type": "doc",
                    "id": "concept-extras/scalarization"
                  },
                  {
                    "type": "category",
                    "label": "NLP",
                    "collapsible": true,
                    "collapsed": true,
                    "items": [
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/chatbot"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/language-modeling"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/named-entity-recognition"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/text-analysis"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/text-classification"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/text-generation"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/text-similarity"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/text-style-transfer"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/text-summarization"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/topic-modeling"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/nlp/transformers"
                      }
                    ]
                  },
                  {
                    "type": "category",
                    "label": "Success Stories",
                    "collapsible": true,
                    "collapsed": true,
                    "items": [
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/1mg-prod2vec"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/airbnb-experiences"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/alipay-ctr"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/doordash-contextual-bandit"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/etsy-personalization"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/huawei-appgallery"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/linkedin-glmix"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/marketcloud-real-time"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/netflix-personalize-images"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/pinterest-multi-task-learning"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/santander-banking-products"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/scribd-real-time"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/spotify-contextual-bandits"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/spotify-rl"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/stitchfix-multi-armed-bandit"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/taobao-bst"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/the-long-tail"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/ubereats-personalization"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/success-stories/walmart-model-selection"
                      }
                    ]
                  },
                  {
                    "type": "category",
                    "label": "Computer Vision",
                    "collapsible": true,
                    "collapsed": true,
                    "items": [
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/facial-analytics"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/image-segmentation"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/image-similarity"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/object-detection"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/object-tracking"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/pose-estimation"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/scene-text-recognition"
                      },
                      {
                        "type": "doc",
                        "id": "concept-extras/vision/video-action-recognition"
                      }
                    ]
                  }
                ]
              },
              {
                "type": "category",
                "label": "Models",
                "collapsible": true,
                "collapsed": true,
                "items": [
                  {
                    "type": "doc",
                    "id": "models/a3c"
                  },
                  {
                    "type": "doc",
                    "id": "models/afm"
                  },
                  {
                    "type": "doc",
                    "id": "models/afn"
                  },
                  {
                    "type": "doc",
                    "id": "models/ar"
                  },
                  {
                    "type": "doc",
                    "id": "models/asmg"
                  },
                  {
                    "type": "doc",
                    "id": "models/attrec"
                  },
                  {
                    "type": "doc",
                    "id": "models/aush"
                  },
                  {
                    "type": "doc",
                    "id": "models/autoint"
                  },
                  {
                    "type": "doc",
                    "id": "models/basr"
                  },
                  {
                    "type": "doc",
                    "id": "models/bcq"
                  },
                  {
                    "type": "doc",
                    "id": "models/beh-prop"
                  },
                  {
                    "type": "doc",
                    "id": "models/biasonly"
                  },
                  {
                    "type": "doc",
                    "id": "models/biggraph"
                  },
                  {
                    "type": "doc",
                    "id": "models/bpr"
                  },
                  {
                    "type": "doc",
                    "id": "models/bst"
                  },
                  {
                    "type": "doc",
                    "id": "models/caser"
                  },
                  {
                    "type": "doc",
                    "id": "models/cigc"
                  },
                  {
                    "type": "doc",
                    "id": "models/coke"
                  },
                  {
                    "type": "doc",
                    "id": "models/dcn"
                  },
                  {
                    "type": "doc",
                    "id": "models/ddpg"
                  },
                  {
                    "type": "doc",
                    "id": "models/deepcross"
                  },
                  {
                    "type": "doc",
                    "id": "models/deepfm"
                  },
                  {
                    "type": "doc",
                    "id": "models/deepwalk"
                  },
                  {
                    "type": "doc",
                    "id": "models/dgtn"
                  },
                  {
                    "type": "doc",
                    "id": "models/dm"
                  },
                  {
                    "type": "doc",
                    "id": "models/dmt"
                  },
                  {
                    "type": "doc",
                    "id": "models/dpadl"
                  },
                  {
                    "type": "doc",
                    "id": "models/dqn"
                  },
                  {
                    "type": "doc",
                    "id": "models/dr"
                  },
                  {
                    "type": "doc",
                    "id": "models/drqn"
                  },
                  {
                    "type": "doc",
                    "id": "models/drr"
                  },
                  {
                    "type": "doc",
                    "id": "models/dueling-dqn"
                  },
                  {
                    "type": "doc",
                    "id": "models/ffm"
                  },
                  {
                    "type": "doc",
                    "id": "models/fgnn"
                  },
                  {
                    "type": "doc",
                    "id": "models/fm"
                  },
                  {
                    "type": "doc",
                    "id": "models/gat"
                  },
                  {
                    "type": "doc",
                    "id": "models/gc-san"
                  },
                  {
                    "type": "doc",
                    "id": "models/gce-gnn"
                  },
                  {
                    "type": "doc",
                    "id": "models/glmix"
                  },
                  {
                    "type": "doc",
                    "id": "models/gru4rec"
                  },
                  {
                    "type": "doc",
                    "id": "models/hmlet"
                  },
                  {
                    "type": "doc",
                    "id": "models/incctr"
                  },
                  {
                    "type": "doc",
                    "id": "models/ipw"
                  },
                  {
                    "type": "doc",
                    "id": "models/itempop"
                  },
                  {
                    "type": "doc",
                    "id": "models/khgt"
                  },
                  {
                    "type": "doc",
                    "id": "models/lessr"
                  },
                  {
                    "type": "doc",
                    "id": "models/lightfm-warp"
                  },
                  {
                    "type": "doc",
                    "id": "models/lightgcn"
                  },
                  {
                    "type": "doc",
                    "id": "models/line"
                  },
                  {
                    "type": "doc",
                    "id": "models/lird"
                  },
                  {
                    "type": "doc",
                    "id": "models/markov-chains"
                  },
                  {
                    "type": "doc",
                    "id": "models/matn"
                  },
                  {
                    "type": "doc",
                    "id": "models/mb-gmn"
                  },
                  {
                    "type": "doc",
                    "id": "models/mdp"
                  },
                  {
                    "type": "doc",
                    "id": "models/mf"
                  },
                  {
                    "type": "doc",
                    "id": "models/mian"
                  },
                  {
                    "type": "doc",
                    "id": "models/mmoe"
                  },
                  {
                    "type": "doc",
                    "id": "models/mpnn"
                  },
                  {
                    "type": "doc",
                    "id": "models/neumf"
                  },
                  {
                    "type": "doc",
                    "id": "models/nfm"
                  },
                  {
                    "type": "doc",
                    "id": "models/ngcf"
                  },
                  {
                    "type": "doc",
                    "id": "models/nmrn"
                  },
                  {
                    "type": "doc",
                    "id": "models/node2vec"
                  },
                  {
                    "type": "doc",
                    "id": "models/pnn"
                  },
                  {
                    "type": "doc",
                    "id": "models/ppo"
                  },
                  {
                    "type": "doc",
                    "id": "models/q-learning"
                  },
                  {
                    "type": "doc",
                    "id": "models/random_walk"
                  },
                  {
                    "type": "doc",
                    "id": "models/rkmf"
                  },
                  {
                    "type": "doc",
                    "id": "models/sac"
                  },
                  {
                    "type": "doc",
                    "id": "models/sarsa"
                  },
                  {
                    "type": "doc",
                    "id": "models/sasrec"
                  },
                  {
                    "type": "doc",
                    "id": "models/sdne"
                  },
                  {
                    "type": "doc",
                    "id": "models/sgl"
                  },
                  {
                    "type": "doc",
                    "id": "models/shared-bottom"
                  },
                  {
                    "type": "doc",
                    "id": "models/siren"
                  },
                  {
                    "type": "doc",
                    "id": "models/slist"
                  },
                  {
                    "type": "doc",
                    "id": "models/sml"
                  },
                  {
                    "type": "doc",
                    "id": "models/spop"
                  },
                  {
                    "type": "doc",
                    "id": "models/sr-gnn"
                  },
                  {
                    "type": "doc",
                    "id": "models/sr-san"
                  },
                  {
                    "type": "doc",
                    "id": "models/sr"
                  },
                  {
                    "type": "doc",
                    "id": "models/sse-pt"
                  },
                  {
                    "type": "doc",
                    "id": "models/stamp"
                  },
                  {
                    "type": "doc",
                    "id": "models/struc2vec"
                  },
                  {
                    "type": "doc",
                    "id": "models/svae"
                  },
                  {
                    "type": "doc",
                    "id": "models/taamr"
                  },
                  {
                    "type": "doc",
                    "id": "models/tagnn-pp"
                  },
                  {
                    "type": "doc",
                    "id": "models/tagnn"
                  },
                  {
                    "type": "doc",
                    "id": "models/vncf"
                  },
                  {
                    "type": "doc",
                    "id": "models/vsknn"
                  },
                  {
                    "type": "doc",
                    "id": "models/wide-and-deep"
                  },
                  {
                    "type": "doc",
                    "id": "models/word2vec"
                  },
                  {
                    "type": "doc",
                    "id": "models/xdeepfm"
                  }
                ],
                "link": {
                  "type": "doc",
                  "id": "models/models"
                }
              },
              {
                "type": "category",
                "label": "Tutorials",
                "collapsible": true,
                "collapsed": true,
                "items": [
                  {
                    "type": "doc",
                    "id": "tutorials/data-science-bookcamp"
                  },
                  {
                    "type": "doc",
                    "id": "tutorials/matching-and-ranking-models-in-tensorflow"
                  },
                  {
                    "type": "doc",
                    "id": "tutorials/real-time-event-capturing-with-kafka-and-mongodb"
                  },
                  {
                    "type": "doc",
                    "id": "tutorials/session-based-recommendation-with-graph-neural-net"
                  },
                  {
                    "type": "doc",
                    "id": "tutorials/tensorflow-2-reinforcement-learning-cookbook"
                  }
                ],
                "link": {
                  "type": "doc",
                  "id": "tutorials/tutorials"
                }
              },
              {
                "type": "category",
                "label": "Tools",
                "collapsible": true,
                "collapsed": true,
                "items": [
                  {
                    "type": "doc",
                    "id": "tools/obp"
                  },
                  {
                    "type": "doc",
                    "id": "tools/river"
                  }
                ]
              },
              {
                "type": "doc",
                "id": "datasets"
              },
              {
                "type": "doc",
                "id": "projects"
              }
            ]
          },
          "mainDocId": "intro",
          "categoryGeneratedIndices": []
        }
      ]
    }
  },
  "docusaurus-plugin-content-blog": {
    "default": {
      "blogSidebarTitle": "Recent posts",
      "blogPosts": [
        {
          "id": "/2021/10/01/bytedance's-secret-sauce-of-recommendation",
          "metadata": {
            "permalink": "/blog/2021/10/01/bytedance's-secret-sauce-of-recommendation",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-bytedance's-secret-sauce-of-recommendation.mdx",
            "source": "@site/blog/2021-10-01-bytedance's-secret-sauce-of-recommendation.mdx",
            "title": "ByteDance's secret sauce of recommendation",
            "description": "For those who have been envious of ByteDance’s immense success across its various consumer products, and more specifically, the recommendation algorithms powering those products, there is finally good news.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "recsys",
                "permalink": "/blog/tags/recsys"
              },
              {
                "label": "tool",
                "permalink": "/blog/tags/tool"
              }
            ],
            "readingTime": 3.565,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "nextItem": {
              "title": "Clinical Decision Making",
              "permalink": "/blog/2021/10/01/clinical-decision-making"
            }
          },
          "content": "For those who have been envious of [ByteDance’s](https://en.pingwest.com/search/bytedance) immense success across its various consumer products, and more specifically, the recommendation algorithms powering those products, there is finally good news.\n\n**With a new brand called [Volcano Engine,](https://www.volcengine.com/) ByteDance is now making the technologies that drove the success of TikTok, Douyin, Toutiao, etc., available as a commercialized service to enterprise clients for the first time.**\n\nVolcano Engine is a suite of services that purportedly assembles the “tools, technologies, and methodology” of ByteDance’s growth legend, covering its recommendation algorithms, audio-visual technologies, data insight services, cloud computing solutions, and more. It is quite literally a copy of the ByteDance's growth hacking “secret sauce”.\n\nThe intelligent recommendation service relies on the advanced large-scale machine learning and personalized recommendation technology of Volcano Engine. It has the ability to accumulate in information and information, live video, social networking, e-commerce and other fields, and provides customized recommendation algorithm services for partners. Improve core business indicators and create value through algorithmic capabilities\n\n![/img/content-blog-raw-blog-bytedance's-secret-sauce-of-recommendation-untitled.png](/img/content-blog-raw-blog-bytedance's-secret-sauce-of-recommendation-untitled.png)\n\nVolcano Engine-Intelligent Recommendation Service has been applied in many industries. Through in-depth mining and intelligent analysis of user behavior data, personalized content distribution and recommended product. Intelligent recommendation service has helped partners achieve a 150% increase in CTR in specific scenarios, 180% increase in advertising revenue in cooperation scenarios, helping partners understand users better\n\n![/img/content-blog-raw-blog-bytedance's-secret-sauce-of-recommendation-untitled-1.png](/img/content-blog-raw-blog-bytedance's-secret-sauce-of-recommendation-untitled-1.png)\n\n### **Data description**\n\nFor customers in the e-commerce industry, 3 data sheets are required to access the smart recommendation service. For specific field requirements, please refer to the following \"Data Field Description\":\n\n1. Product table (product): synchronize all product information of the access scene;\n2. User table (user): To synchronize all user information, the uniqueness of the user needs to be guaranteed, and the user id information is carried when requesting the service;\n3. User behavior table (behavior): Synchronize historical and incremental user behavior data. It is recommended to provide 6-12 months of historical behavior data. The longer the synchronization time, the better the effect;\n\n### **Data synchronization method**\n\nData synchronization includes offline data and incremental data. It supports synchronization through API interface, SDK or public cloud object storage. Among them:\n\n- Offline data: need to provide product data, user data and historical user behavior data;\n\n**Remarks:** Commodity data and user data are recommended to send day-level data snapshots. If there is no snapshot, then the latest data will be sent; Behavior data is synchronized at the day level; Commodity data, user data and behavior data are synchronized in json format. Each row of the data is json, corresponding to a record;\n\n- Incremental data: Incremental product data, user data, and user behavior data need to be provided;\n\n**Remarks:** ① Real-time incremental synchronization of behavioral data and product data is strongly recommended; ② User attribute data can be synchronized in increments of days;\n\n### **Data field description**\n\nThe following are the specific field requirements of the user, product, and user behavior table. Whether it is mandatory to include three types: \"Yes\", \"Suggestion\" and \"No\". It is recommended to upload as much as possible. The more fields available for the algorithm model, the better the effect of the model.\n\n### **Data synchronization**\n\nData synchronization supports synchronization through [API interface](https://www.volcengine.com/docs/4462/38312/) , [SDK](https://www.volcengine.com/docs/4462/39599/) or public cloud object storage.\n\n- If the amount of offline data is large, support customers to dump the data to public cloud object storage, and we will pull it through the public network\n- The offline data synchronization solution of the privatization deployment plan is more flexible and supports the direct pull of HDFS directories\n- The data to be synchronized includes offline data and incremental data. The synchronization method is described as follows:\n- Offline data: need to provide product data, user data and historical user behavior data\n- Commodity data and user data are recommended to send day-level data snapshots. If there is no snapshot, then the latest data will be sent\n- Behavior data is synchronized at the day level\n- Commodity data, user data, and behavioral data are synchronized in JSON format. Each row of the data is JSON, corresponding to a record\n- Incremental data: Incremental product data, user data, and user behavior data need to be provided;\n- Real-time incremental synchronization of behavioral data and product data is strongly recommended\n- User attribute data can be synchronized in increments of days\n\n### References\n\n1. [https://www.volcengine.com/](https://www.volcengine.com/)"
        },
        {
          "id": "/2021/10/01/clinical-decision-making",
          "metadata": {
            "permalink": "/blog/2021/10/01/clinical-decision-making",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-clinical-decision-making.mdx",
            "source": "@site/blog/2021-10-01-clinical-decision-making.mdx",
            "title": "Clinical Decision Making",
            "description": "Health insurance can be complicated—especially when it comes to prior authorization (also referred to as pre-approval, pre-authorization, and pre-certification). The manual labor involved in obtaining prior authorizations (PAs) is a well-recognized burden among providers. Up to 46% of PA requests are still submitted by fax, and 60% require a telephone call, according to America’s Health Insurance Plans (AHIP). A 2018 survey by the American Medical Association (AMA) found that doctors and their staff spend an average of 2 days a week completing PAs. In addition to eating up time that physicians could spend with patients, PAs also contribute to burnout.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "classification",
                "permalink": "/blog/tags/classification"
              },
              {
                "label": "healthcare",
                "permalink": "/blog/tags/healthcare"
              }
            ],
            "readingTime": 1.46,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "ByteDance's secret sauce of recommendation",
              "permalink": "/blog/2021/10/01/bytedance's-secret-sauce-of-recommendation"
            },
            "nextItem": {
              "title": "Detectron 2",
              "permalink": "/blog/2021/10/01/detectron-2"
            }
          },
          "content": "Health insurance can be complicated—especially when it comes to prior authorization (also referred to as pre-approval, pre-authorization, and pre-certification). The manual labor involved in obtaining prior authorizations (PAs) is a well-recognized burden among providers. Up to 46% of PA requests are still submitted by fax, and 60% require a telephone call, according to America’s Health Insurance Plans (AHIP). A 2018 survey by the American Medical Association (AMA) found that doctors and their staff spend an average of 2 days a week completing PAs. In addition to eating up time that physicians could spend with patients, PAs also contribute to burnout.\n\nThe objective was to identify the patterns from data to create clinical decision making in Pre-Auth and improve the accuracy in a clinical decision based on historical data analysis. \n\nTwo use cases were identified. Use Case 1 - *Supervised Learning Model - to aid clinicians in UM decision making. Tasks -* Ingest Pre-authorization data from Mongo DB into the analytical environment, Exploratory Data Analysis and Feature Engineering, Train supervised analytical models, model validation and model selection, Create a web service to be plugged into the case processing flow to call the model, and Display the recommendation from the model on UI on the authorization review screen. Use Case 2 - *Unsupervised Learning Model - to generate insights from the pre-authorization data. Tasks -* Ingest Pre-authorization data from Mongo DB into the analytical environment, Cluster analysis, univariate and multivariate analysis, and Generate insights and display insights on the dashboard.\n\nFinal Deliverables - Model re-training (batch mode), validation and deployment code (python scripts) with Unix command line support, Documentation - PPT, Recorded video, Technical document, Flask API backend system, HTML/PHP Web App frontend UI integration, and Plotly Dash Supervised/Unsupervised learning and insights generation dashboard."
        },
        {
          "id": "/2021/10/01/detectron-2",
          "metadata": {
            "permalink": "/blog/2021/10/01/detectron-2",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-detectron-2.mdx",
            "source": "@site/blog/2021-10-01-detectron-2.mdx",
            "title": "Detectron 2",
            "description": "/img/content-blog-raw-blog-detectron-2-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "tool",
                "permalink": "/blog/tags/tool"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 6.13,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Clinical Decision Making",
              "permalink": "/blog/2021/10/01/clinical-decision-making"
            },
            "nextItem": {
              "title": "Distributed Training of Recommender Systems",
              "permalink": "/blog/2021/10/01/distributed-training-of-recommender-systems"
            }
          },
          "content": "![/img/content-blog-raw-blog-detectron-2-untitled.png](/img/content-blog-raw-blog-detectron-2-untitled.png)\n\n# Introduction\n\nDetectron 2 is a next-generation open-source object detection system from Facebook AI Research. With the repo you can use and train the various state-of-the-art models for detection tasks such as bounding-box detection, instance and semantic segmentation, and person keypoint detection.\n\nThe following is the directory tree of detectron 2:\n\n```\ndetectron2\n├─checkpoint  <- checkpointer and model catalog handlers\n├─config      <- default configs and handlers\n├─data        <- dataset handlers and data loaders\n├─engine      <- predictor and trainer engines\n├─evaluation  <- evaluator for each dataset\n├─export      <- converter of detectron2 models to caffe2 (ONNX)\n├─layers      <- custom layers e.g. deformable conv.\n├─model_zoo   <- pre-trained model links and handler\n├─modeling   \n│  ├─meta_arch <- meta architecture e.g. R-CNN, RetinaNet\n│  ├─backbone  <- backbone network e.g. ResNet, FPN\n│  ├─proposal_generator <- region proposal network\n│  └─roi_heads <- head networks for pooled ROIs e.g. box, mask heads\n├─solver       <- optimizer and scheduler builders\n├─structures   <- structure classes e.g. Boxes, Instances, etc\n└─utils        <- utility modules e.g. visualizer, logger, etc\n```\n\n# Installation\n\n```python\n%%time\n!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html;\n!pip install cython pyyaml==5.1;\n!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI';\n!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html;\n\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\n```\n\n# Inference on pre-trained models\n\n![Original image](/img/content-blog-raw-blog-detectron-2-untitled-1.png)\n\nOriginal image\n\n![Object detection with Faster-RCNN-101](/img/content-blog-raw-blog-detectron-2-untitled-2.png)\n\nObject detection with Faster-RCNN-101\n\n![Instance segmentation with Mask-RCNN-50](/img/content-blog-raw-blog-detectron-2-untitled-3.png)\n\nInstance segmentation with Mask-RCNN-50\n\n![Keypoint estimation with Keypoint-RCNN-50](/img/content-blog-raw-blog-detectron-2-untitled-4.png)\n\nKeypoint estimation with Keypoint-RCNN-50\n\n![Panoptic segmentation with Panoptic-FPN-101](/img/content-blog-raw-blog-detectron-2-untitled-5.png)\n\nPanoptic segmentation with Panoptic-FPN-101\n\n![Default Mask R-CNN (top) vs. Mask R-CNN with PointRend (bottom) comparison](/img/content-blog-raw-blog-detectron-2-untitled-6.png)\n\nDefault Mask R-CNN (top) vs. Mask R-CNN with PointRend (bottom) comparison\n\n# Fine-tuning Balloons Dataset\n\n### Load the data\n\n```\n# download, decompress the data\n!wget https://github.com/matterport/Mask_RCNN/releases/download/v2.1/balloon_dataset.zip\n!unzip balloon_dataset.zip > /dev/null\n```\n\n### Convert dataset into Detectron2's standard format\n\n```\nfrom detectron2.structures import BoxMode\n# write a function that loads the dataset into detectron2's standard format\ndef get_balloon_dicts(img_dir):\n    json_file = os.path.join(img_dir, \"via_region_data.json\")\n    with open(json_file) as f:\n        imgs_anns = json.load(f)\n\n    dataset_dicts = []\n    for _, v in imgs_anns.items():\n        record = {}\n        \n        filename = os.path.join(img_dir, v[\"filename\"])\n        height, width = cv2.imread(filename).shape[:2]\n        \n        record[\"file_name\"] = filename\n        record[\"height\"] = height\n        record[\"width\"] = width\n      \n        annos = v[\"regions\"]\n        objs = []\n        for _, anno in annos.items():\n            assert not anno[\"region_attributes\"]\n            anno = anno[\"shape_attributes\"]\n            px = anno[\"all_points_x\"]\n            py = anno[\"all_points_y\"]\n            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n            poly = list(itertools.chain.from_iterable(poly))\n\n            obj = {\n                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n                \"bbox_mode\": BoxMode.XYXY_ABS,\n                \"segmentation\": [poly],\n                \"category_id\": 0,\n                \"iscrowd\": 0\n            }\n            objs.append(obj)\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts\n\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfor d in [\"train\", \"val\"]:\n    DatasetCatalog.register(\"balloon/\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n    MetadataCatalog.get(\"balloon/\" + d).set(thing_classes=[\"balloon\"])\nballoon_metadata = MetadataCatalog.get(\"balloon/train\")\n```\n\n### Model configuration and training\n\n```\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.config import get_cfg\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"balloon/train\",)\ncfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.BASE_LR = 0.00025\ncfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()\n```\n\n### Inference and Visualization\n\n```\nfrom detectron2.utils.visualizer import ColorMode\n\n# load weights\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n# Set training data-set path\ncfg.DATASETS.TEST = (\"balloon/val\", )\n# Create predictor (model for inference)\npredictor = DefaultPredictor(cfg)\n\ndataset_dicts = get_balloon_dicts(\"balloon/val\")\nfor d in random.sample(dataset_dicts, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1],\n                   metadata=balloon_metadata, \n                   scale=0.8, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n    )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    cv2_imshow(v.get_image()[:, :, ::-1])\n```\n\n![/img/content-blog-raw-blog-detectron-2-untitled-7.png](/img/content-blog-raw-blog-detectron-2-untitled-7.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-8.png](/img/content-blog-raw-blog-detectron-2-untitled-8.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-9.png](/img/content-blog-raw-blog-detectron-2-untitled-9.png)\n\n# Fine-tuning Chip Dataset\n\n### Load the data\n\n```\n#get the dataset\n!pip install -q kaggle\n!pip install -q kaggle-cli\nos.environ['KAGGLE_USERNAME'] = \"sparshag\" \nos.environ['KAGGLE_KEY'] = \"1b1f894d1fa6febe9676681b44ad807b\"\n!kaggle datasets download -d tannergi/microcontroller-detection\n!unzip microcontroller-detection.zip\n```\n\n### Convert dataset into Detectron2's standard format\n\n```\n# Registering the dataset\nfrom detectron2.structures import BoxMode\ndef get_microcontroller_dicts(csv_file, img_dir):\n    df = pd.read_csv(csv_file)\n    df['filename'] = df['filename'].map(lambda x: img_dir+x)\n\n    classes = ['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora']\n\n    df['class_int'] = df['class'].map(lambda x: classes.index(x))\n\n    dataset_dicts = []\n    for filename in df['filename'].unique().tolist():\n        record = {}\n        \n        height, width = cv2.imread(filename).shape[:2]\n        \n        record[\"file_name\"] = filename\n        record[\"height\"] = height\n        record[\"width\"] = width\n\n        objs = []\n        for index, row in df[(df['filename']==filename)].iterrows():\n          obj= {\n              'bbox': [row['xmin'], row['ymin'], row['xmax'], row['ymax']],\n              'bbox_mode': BoxMode.XYXY_ABS,\n              'category_id': row['class_int'],\n              \"iscrowd\": 0\n          }\n          objs.append(obj)\n        record[\"annotations\"] = objs\n        dataset_dicts.append(record)\n    return dataset_dicts\n\nclasses = ['Raspberry_Pi_3', 'Arduino_Nano', 'ESP8266', 'Heltec_ESP32_Lora']\nfor d in [\"train\", \"test\"]:\n  DatasetCatalog.register('microcontroller/' + d, lambda d=d: get_microcontroller_dicts('Microcontroller Detection/' + d + '_labels.csv', 'Microcontroller Detection/' + d+'/'))\n  MetadataCatalog.get('microcontroller/' + d).set(thing_classes=classes)\nmicrocontroller_metadata = MetadataCatalog.get('microcontroller/train')\n```\n\n### Model configuration and training\n\n```\n# Train the model\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = ('microcontroller/train',)\ncfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.MAX_ITER = 1000\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()\n```\n\n![/img/content-blog-raw-blog-detectron-2-untitled-10.png](/img/content-blog-raw-blog-detectron-2-untitled-10.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-11.png](/img/content-blog-raw-blog-detectron-2-untitled-11.png)\n\n### Inference and Visualization\n\n```\ncfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model\ncfg.DATASETS.TEST = ('microcontroller/test', )\npredictor = DefaultPredictor(cfg)\n\ndf_test = pd.read_csv('Microcontroller Detection/test_labels.csv')\n\ndataset_dicts = DatasetCatalog.get('microcontroller/test')\nfor d in random.sample(dataset_dicts, 3):    \n    im = cv2.imread(d[\"file_name\"])\n    outputs = predictor(im)\n    v = Visualizer(im[:, :, ::-1], \n                   metadata=microcontroller_metadata, \n                   scale=0.8\n                   )\n    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n    cv2_imshow(v.get_image()[:, :, ::-1])\n```\n\n### Real-time Webcam inference\n\n```\nfrom IPython.display import display, Javascript\nfrom google.colab.output import eval_js\nfrom base64 import b64decode\n\ndef take_photo(filename='photo.jpg', quality=0.8):\n  js = Javascript('''\n    async function takePhoto(quality) {\n      const div = document.createElement('div');\n      const capture = document.createElement('button');\n      capture.textContent = 'Capture';\n      div.appendChild(capture);\n\n      const video = document.createElement('video');\n      video.style.display = 'block';\n      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n\n      document.body.appendChild(div);\n      div.appendChild(video);\n      video.srcObject = stream;\n      await video.play();\n\n      // Resize the output to fit the video element.\n      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n\n      // Wait for Capture to be clicked.\n      await new Promise((resolve) => capture.onclick = resolve);\n\n      const canvas = document.createElement('canvas');\n      canvas.width = video.videoWidth;\n      canvas.height = video.videoHeight;\n      canvas.getContext('2d').drawImage(video, 0, 0);\n      stream.getVideoTracks()[0].stop();\n      div.remove();\n      return canvas.toDataURL('image/jpeg', quality);\n    }\n    ''')\n  display(js)\n  data = eval_js('takePhoto({})'.format(quality))\n  binary = b64decode(data.split(',')[1])\n  with open(filename, 'wb') as f:\n    f.write(binary)\n  return filename\n\nfrom IPython.display import Image\ntry:\n  filename = take_photo()\n  print('Saved to {}'.format(filename))\n  \n  # Show the image which was just taken.\n  display(Image(filename))\nexcept Exception as err:\n  # Errors will be thrown if the user does not have a webcam or if they do not\n  # grant the page permission to access it.\n  print(str(err))\n```\n\n```\nmodel_path = '/content/output/model_final.pth'\nconfig_path= model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n\n# Create config\ncfg = get_cfg()\ncfg.merge_from_file(config_path)\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1\ncfg.MODEL.WEIGHTS = model_path\n\npredictor = DefaultPredictor(cfg)\n\nim = cv2.imread('photo.jpg')\noutputs = predictor(im)\n\nv = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\nv = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\ncv2_imshow(v.get_image()[:, :, ::-1])\n```\n\n# Fine-tuning on Face dataset\n\nThe process is same. Here is the output.\n\n![/img/content-blog-raw-blog-detectron-2-untitled-12.png](/img/content-blog-raw-blog-detectron-2-untitled-12.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-13.png](/img/content-blog-raw-blog-detectron-2-untitled-13.png)\n\n![/img/content-blog-raw-blog-detectron-2-untitled-14.png](/img/content-blog-raw-blog-detectron-2-untitled-14.png)\n\n### Behind the scenes\n\n![/img/content-blog-raw-blog-detectron-2-untitled-15.png](/img/content-blog-raw-blog-detectron-2-untitled-15.png)\n\n### References\n\n- [How to embed Detectron2 in your computer vision project - blogpost](https://medium.com/deepvisionguru/how-to-embed-detectron2-in-your-computer-vision-project-817f29149461)\n- [Detectron2 Train a Instance Segmentation Model by Gilbert Tanner](https://gilberttanner.com/blog/detectron2-train-a-instance-segmentation-model)\n- [How to train Detectron2 with Custom COCO Datasets - DLology](https://www.dlology.com/blog/how-to-train-detectron2-with-custom-coco-datasets/)\n- [Character Recognition and Segmentation For Custom Data Using Detectron2 - blogpost](https://towardsdatascience.com/character-recognition-and-segmentation-for-custom-data-using-detectron2-599de82b393c)\n- [Training models with Panoptic Segmentation in Detectron2](https://www.celantur.com/blog/panoptic-segmentation-in-detectron2/)\n- [Image segmentation using Detectron2 - Kaggle](https://www.kaggle.com/lewisgmorris/image-segmentation-using-detectron2)\n- [A Beginner’s Guide To Object Detection And Computer Vision With Facebook’s Detectron2](https://towardsdatascience.com/a-beginners-guide-to-object-detection-and-computer-vision-with-facebook-s-detectron2-700b6273390e)\n- [Face Detection on Custom Dataset with Detectron2 and PyTorch using Python](https://www.curiousily.com/posts/face-detection-on-custom-dataset-with-detectron2-in-python/)\n- [My Experiment Notion](https://www.notion.so/Detectron-2-d31ac9c14a8d4d9888882df14a4e0eee)\n- [Official Colab](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)\n- [Official Slide](https://research.fb.com/wp-content/uploads/2019/12/4.-detectron2.pdf)\n- [Official Git](https://github.com/facebookresearch/detectron2)"
        },
        {
          "id": "/2021/10/01/distributed-training-of-recommender-systems",
          "metadata": {
            "permalink": "/blog/2021/10/01/distributed-training-of-recommender-systems",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-distributed-training-of-recommender-systems.mdx",
            "source": "@site/blog/2021-10-01-distributed-training-of-recommender-systems.mdx",
            "title": "Distributed Training of Recommender Systems",
            "description": "The usage and importance of recommender systems are increasing at a fast pace. And deep learning is gaining traction as the preferred choice for model architecture. Giants like Google and Facebook are already using recommenders to earn billions of dollars.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "distributed",
                "permalink": "/blog/tags/distributed"
              },
              {
                "label": "recsys",
                "permalink": "/blog/tags/recsys"
              }
            ],
            "readingTime": 5.85,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Detectron 2",
              "permalink": "/blog/2021/10/01/detectron-2"
            },
            "nextItem": {
              "title": "Document Recommendation",
              "permalink": "/blog/2021/10/01/document-recommendation"
            }
          },
          "content": "The usage and importance of recommender systems are increasing at a fast pace. And deep learning is gaining traction as the preferred choice for model architecture. Giants like Google and Facebook are already using recommenders to earn billions of dollars.\n\nRecently, Facebook shared its approach to maintain its 12 trillion parameter recommender. Building these large systems is challenging because it requires huge computation and memory resources. And we will soon enter into 100 trillion range. And SMEs will not be left behind due to open-source environment of software architectures and the decreasing cost of hardware, especially on the cloud infrastructure.\n\nAs per one estimate, a model with 100 trillion parameters would require at least 200TB just to store the model, even at 16-bit floating-point accuracy. So we need architectures that can support efficient and distributed training of recommendation models.\n\n***Memory-intensive vs Computation-intensive***: The increasing parameter comes mostly from the embedding layer which maps each entrance of an ID type feature (such as an user ID and a session ID) into a fixed length low-dimensional embedding vector. Consider the billion scale of entrances for the ID type features in a production recommender system and the wide utilization of feature crosses, the embedding layer usually domains the parameter space, which makes this component extremely **memory-intensive**. On the other hand, these low-dimensional embedding vectors are concatenated with diversified Non-ID type features (e.g., image, audio, video, social network, etc.) to feed a group of increasingly sophisticated neural networks (e.g., convolution, LSTM, multi-head attention) for prediction(s). Furthermore, in practice, multiple objectives can also be combined and optimized simultaneously for multiple tasks. These mechanisms make the rest neural network increasingly **computation-intensive**.\n\n![An example of a recommender models with 100+ trillions of parameter in the embedding layer and 50+ TFLOP computation in the neural network.](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled.png)\n\nAn example of a recommender models with 100+ trillions of parameter in the embedding layer and 50+ TFLOP computation in the neural network.\n\n[Alibaba's XDL](https://github.com/alibaba/x-deeplearning), [Baidu's PaddleRec](https://github.com/PaddlePaddle/PaddleRec), and [Kwai's Persia](https://github.com/persiaml/persia) are some open-source frameworks for this large-scale distributed training of recommender systems.\n\n<aside>\n📌 ***Synchronous vs Asynchronous Algorithms***: Synchronous algorithms always use the up-to-date gradient to update the model to ensure the model accuracy. However, the overhead of communications for synchronous algorithms starts to become too expensive to scale out the training procedure, causing inefficiency in running time. While asynchronous algorithm have better hardware efficiency, it often leads to a “significant” loss in model accuracy at this scale—for production recommender systems (e.g., Baidu’s search engine). Recall that even 0.1% drop of accuracy would lead to a noticeable loss in revenue.\n\n</aside>\n\n### Parameter Server Framework\n\nExisting distributed systems for deep learning based recommender models are usually built on top of the parameter server (PS) framework, where one can add elastic distributed storage to hold the increasingly large amount of parameters of the embedding layer. On the other hand, the computation workload does not scale linearly with the increasing parameter scale of the embedding layer—in fact, with an efficient implementation, a lookup operation over a larger embedding table would introduce almost no additional computations.\n\n![Left: deep learning based recommender model training workflow over a heterogeneous cluster. Right: Gantt charts to compare fully synchronous, fully asynchronous, raw hybrid and optimized hybrid modes of distributed training of the deep learning recommender model. [Source](https://arxiv.org/pdf/2111.05897v1.pdf).](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-1.png)\n\nLeft: deep learning based recommender model training workflow over a heterogeneous cluster. Right: Gantt charts to compare fully synchronous, fully asynchronous, raw hybrid and optimized hybrid modes of distributed training of the deep learning recommender model. [Source](https://arxiv.org/pdf/2111.05897v1.pdf).\n\n### PERSIA\n\n**PERSIA** (**P**arallel r**E**commendation t**R**aining **S**ystem with hybr**I**d **A**cceleration) is a PyTorch-based system for training deep learning recommendation models on commodity hardware. It supports models containing more than 100 trillion parameters.\n\nIt uses a hybrid training algorithm to tackle the embedding layer and dense neural network modules differently—the embedding layer is trained in an asynchronous fashion to improve the throughput of training samples, while the rest neural network is trained in a synchronous fashion to preserve the statistical efficiency.\n\nIt also uses a distributed system to manage the hybrid computation resources (CPUs and GPUs) to optimize the co-existence of asynchronicity and synchronicity in the training algorithm.\n\n![Untitled](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-2.png)\n\n![Untitled](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-3.png)\n\nPersia includes a data loader module, a embedding PS (Parameter Server) module, a group of embedding workers over CPU nodes, and a group of NN workers over GPU instances. Each module can be dynamically scaled for different model scales and desired training throughput:\n\n- A data loader that fetches training data from distributed storages such as Hadoop, Kafka, etc;\n- A embedding parameter server (embedding PS for short) manages the storage and update of the parameters in the embedding layer $\\mathrm{w}^{emb}$;\n- A group of embedding workers that runs Algorithm 1 for getting the embedding parameters from the embedding PS; aggregating embedding vectors (potentially) and putting embedding gradients back to embedding PS;\n- A group of NN workers that runs the forward-/backward- propagation of the neural network $\\mathrm{NN_{w^{nn}}(·)}$.\n\n![The architecture of Persia.](/img/content-blog-raw-blog-distributed-training-of-recommender-systems-untitled-4.png)\n\nThe architecture of Persia.\n\nLogically, the training procedure is conducted by Persia in a data dispatching based paradigm as below:\n\n1. The data loader will dispatch the ID type feature $\\mathrm{x^{ID}}$ to an embedding worker—the embedding worker will generate an unique sample ID 𝜉 for this sample, buffer this sample ID with the ID type feature $\\mathrm{x_\\xi^{ID}}$ locally, and returns this ID 𝜉 back the data loader; the data loader will associate this sample’s Non-ID type features and labels with this unique ID.\n2. Next, the data loader will dispatch the Non-ID type feature and label(s) $\\mathrm{(x_\\xi^{NID},y_\\xi)}$ to a NN worker.\n3. Once a NN worker receives this incomplete training sample, it will issue a request to pull the ID type features’ $\\mathrm{(x_\\xi^{ID})}$ embedding $\\mathrm{w_\\xi^{emb}}$ from some embedding worker according to the sample ID 𝜉—this would trigger the forward propagation in Algorithm 1, where the embedding worker will use the buffered ID type feature $\\mathrm{x_\\xi^{ID}}$ to get the corresponding $\\mathrm{w_\\xi^{emb}}$ from the embedding PS.\n4. Then the embedding worker performs some potential aggregation of original embedding vectors. When this computation finishes, the aggregated embedding vector $\\mathrm{w_\\xi^{emb}}$ will be transmitted to the NN worker that issues the pull request.\n5. Once the NN worker gets a group of complete inputs for the dense module, it will create a mini-batch and conduct the training computation of the NN according to Algorithm 2. Note that the parameter of the NN always locates in the device RAM of the NN worker, where the NN workers synchronize the gradients by the AllReduce Paradigm.\n6. When the iteration of Algorithm 2 is finished, the NN worker will send the gradients of the embedding ($\\mathrm{F_\\xi^{emb'}}$) back to the embedding worker (also along with the sample ID 𝜉).\n7. The embedding worker will query the buffered ID type feature $\\mathrm{x_\\xi^{ID}}$ according to the sample ID 𝜉; compute gradients $\\mathrm{F_\\xi^{emb'}}$ of the embedding parameters and send the gradients to the embedding PS, so that the embedding PS can finally compute the updates according the embedding parameter’s gradients by its SGD optimizer and update the embedding parameters."
        },
        {
          "id": "/2021/10/01/document-recommendation",
          "metadata": {
            "permalink": "/blog/2021/10/01/document-recommendation",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-document-recommendation.mdx",
            "source": "@site/blog/2021-10-01-document-recommendation.mdx",
            "title": "Document Recommendation",
            "description": "/img/content-blog-raw-blog-document-recommendation-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              }
            ],
            "readingTime": 1.285,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Distributed Training of Recommender Systems",
              "permalink": "/blog/2021/10/01/distributed-training-of-recommender-systems"
            },
            "nextItem": {
              "title": "Fake Voice Detection",
              "permalink": "/blog/2021/10/01/fake-voice-detection"
            }
          },
          "content": "![/img/content-blog-raw-blog-document-recommendation-untitled.png](/img/content-blog-raw-blog-document-recommendation-untitled.png)\n\n## **Introduction**\n\n### Business objective\n\nFor the given user query, recommend relevant documents (BRM_ifam)\n\n### Technical objective\n\n1-to-N mapping of given input text\n\n## **Proposed Framework 1 — Hybrid Recommender System**\n\n- Text → Vector (Universal Sentence Embedding with TF Hub)\n- Vector → Content-based Filtering Recommendation\n- Index → Interaction Matrix\n- Interaction Matrix → Collaborative Filtering Recommendation\n- Collaborative + Content-based → Hybrid Recommendation\n- Evaluation: Area-under-curve\n\n## **Proposed Framework 2 — Content-based Recommender System**\n\n1. Find A most similar user → Cosine similarity\n2. For each user in A, find TopK Most Similar Items → Map Argsort\n3. For each item Find TopL Most Similar Items → Cosine similarity\n4. Display\n5. Implement an evaluation metric\n6. Evaluate\n\n## **Results and Discussion**\n\n- build.py → this script will take the training data as input and save all the required files in the same working directory\n- recommend.py → this script will take the user query as input and predict top-K BRM recommendations\n\nVariables (during recommendation, you will be asked 2–3 choices, the meaning of those choices are as following)\n\n- top-K — how many top items you want to get in recommendation\n- secondary items: this will determine how many similar items you would like to add in consideration, for each primary matching item\n- sorted by frequency: since multiple input queries might point to same output, therefore this option allows to take that frequence count of outputs in consideration and will move the more frequent items at the top.\n\n### **Code**\n\n[https://gist.github.com/sparsh-ai/4e5f06ba3c55192b33a276ee67dbd42c#file-text-recommendations-ipynb](https://gist.github.com/sparsh-ai/4e5f06ba3c55192b33a276ee67dbd42c#file-text-recommendations-ipynb)"
        },
        {
          "id": "/2021/10/01/fake-voice-detection",
          "metadata": {
            "permalink": "/blog/2021/10/01/fake-voice-detection",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-fake-voice-detection.mdx",
            "source": "@site/blog/2021-10-01-fake-voice-detection.mdx",
            "title": "Fake Voice Detection",
            "description": "/img/content-blog-raw-blog-fake-voice-detection-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "audio",
                "permalink": "/blog/tags/audio"
              },
              {
                "label": "deepfake",
                "permalink": "/blog/tags/deepfake"
              }
            ],
            "readingTime": 2.88,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Document Recommendation",
              "permalink": "/blog/2021/10/01/document-recommendation"
            },
            "nextItem": {
              "title": "Finding Hardware Parts in Warehouse",
              "permalink": "/blog/2021/10/01/finding-hardware-parts-in-warehouse"
            }
          },
          "content": "![/img/content-blog-raw-blog-fake-voice-detection-untitled.png](/img/content-blog-raw-blog-fake-voice-detection-untitled.png)\n\n# Introduction\n\nFake audio can be used for malicious purposes which affect directly or indirectly human life. The objective is to differentiate between fake and real voice. Python and deep learning has been used and implemented to achieve the objective. Audio files or video file are being used as an input of this work then model has been trained for uniquely identify features for voice creation and voice detection. Deep learning technique is used to find accuracy between real and fake.\n\nSpeaker recognition usually refers to both speaker identification and speaker verification. A speaker identification system identifies who the speaker is, while an automatic speaker verification (ASV) system decides if an identity claim is true or false.\nA general ASV system is robust to zero-effort impostors, they are vulnerable to more sophisticated attacks. Such vulnerability represents one of the security concerns of ASV systems. Spoofing involves an adversary (attacker) who masquerades as the target speaker to gain the access to a system. Such spoofing attacks can happen to various biometric traits, such as fingerprints, iris, face, and voice patterns. We are focusing only on the voice-based spoofing and anti-spoofing techniques for ASV system. The spoofed speech samples can be obtained through speech synthesis, voice conversion, or replay of recorded speech. **Imagine the following scenario…**\nYour phone rings, you pick up. It’s your spouse asking you for details about your savings account — they don’t have the account information on hand, but want to deposit money there this afternoon. Later, you realize a bunch of money has went missing! After investigating, you find out that the person masquerading as them on the other line was a voice 100% generated with AI. You’ve just been scammed, and on top of that, can’t believe the voice you thought belonged to your spouse was actually a fake.\n\nTo discern between real and fake audio, the detector uses visual representations of audio clips called spectrograms, which are also used to train speech synthesis models.\nGoogle’s 2019 [AVSSpoof dataset](https://www.blog.google/outreach-initiatives/google-news-initiative/advancing-research-fake-audio-detection/) contains over 25,000 clips of audio, featuring both real and fake clips of a variety of male and female speakers.**Temporal Convolution Model**\n\n# Modeling Approach\n\nFirst, raw audio is preprocessed and converted into a mel-frequency spectrogram — this is the input for the model. The model performs convolutions over the time dimension of the spectrogram, then uses masked pooling to prevent overfitting. Finally, the output is passed into a dense layer and a sigmoid activation function, which ultimately outputs a predicted probability between 0 (fake) and 1 (real).\nThe baseline model achieved 99%, 95%, and 85% accuracy on the train, validation, and test sets respectively. The differing performance is caused by differences between the three datasets. While all three datasets feature distinct and different speakers, the test set uses a different set of fake audio generating algorithms that were not present in the train or validation set.\n\n# Proposed Framework\n\n# Process Flow\n\n- Voice detection\n    - Temporal Convolution model\n        - Install packages\n        - Download pretrained models\n        - Initialize the model\n        - Load data\n        - Detect DeepFakes\n    - GMM-UBG model\n        - Install packages\n        - Train the model\n        - Load data\n        - Detect DeepFakes\n    - Convolutional VAE model\n        - Install packages\n        - Train the model\n        - Load data\n        - Detect DeepFakes\n    - Voice Similarity\n        - Install packages\n        - Load data\n        - Voice similarity match\n        - Embedding visualization\n\n# Models Algorithms\n\n1. Temporal Convolution\n2. ResNet\n3. GMM\n4. Light CNN\n5. Fusion\n6. SincNet\n7. ASSERT\n8. HOSA\n9. CVAE"
        },
        {
          "id": "/2021/10/01/finding-hardware-parts-in-warehouse",
          "metadata": {
            "permalink": "/blog/2021/10/01/finding-hardware-parts-in-warehouse",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-finding-hardware-parts-in-warehouse.mdx",
            "source": "@site/blog/2021-10-01-finding-hardware-parts-in-warehouse.mdx",
            "title": "Finding Hardware Parts in Warehouse",
            "description": "Imagine a customer visits a store to buy hardware parts (e.g. a PVC  pipe or a concrete block) and describe the requirements in a natural language like 'I need 2\" x 5\" concrete block' but the exact description of this part might be different in the seller's database e.g. 'concrete block solid of width 2 inch and height 5 inches'. So the objective is to build a system that will help the store owner to find and offer the right item from the database for the description given by the customer.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              }
            ],
            "readingTime": 1.35,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Fake Voice Detection",
              "permalink": "/blog/2021/10/01/fake-voice-detection"
            },
            "nextItem": {
              "title": "Image Similarity System",
              "permalink": "/blog/2021/10/01/image-similarity-system"
            }
          },
          "content": "Imagine a customer visits a store to buy hardware parts (e.g. a PVC  pipe or a concrete block) and describe the requirements in a natural language like `'I need 2\" x 5\" concrete block'` but the exact description of this part might be different in the seller's database e.g. `'concrete block solid of width 2 inch and height 5 inches'`. So the objective is to build a system that will help the store owner to find and offer the right item from the database for the description given by the customer. \n\n# Proposed Solution\n\nSemantic text similarity to map the queries. Bag-of-words based Count vectorizer model with different types of tokenization process and n-gram range. \n\n# Modeling Approach\n\n### Data Description\n\nData 1 - Core training data with 2 columns - Part ID and Description, to find top similar queries\n\nData 2 - Lookup data to find the top most similar query\n\nData 3 - Lookup data to fetch the exact description if description is exactly matching in the database\n\nData 4 - List of keywords for a tokenizer\n\nData 5 - List of substitutions for more accurate similarity\n\nData 6 - Test data with 2 columns - Description and part ID (optional)\n\n### Modeling\n\nCount vectorizer models\n\n- Unigram, Bigram and Trigram tokens\n- Non-alphabet tokens\n- Keyword tokens\n- M1 - Text similarity model trained on small file\n- M2 - Text similarity model trained on large file\n- M3 - Text similarity model trained on mixed file\n\n### Algorithm\n\n- 1-gram and 2-gram tokenization\n- Count vectorization\n- Cosine or Euclidean distance\n\n# Final Repository Structure\n\n![/img/content-blog-raw-blog-finding-hardware-parts-in-warehouse-untitled.png](/img/content-blog-raw-blog-finding-hardware-parts-in-warehouse-untitled.png)"
        },
        {
          "id": "/2021/10/01/image-similarity-system",
          "metadata": {
            "permalink": "/blog/2021/10/01/image-similarity-system",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-image-similarity-system.mdx",
            "source": "@site/blog/2021-10-01-image-similarity-system.mdx",
            "title": "Image Similarity System",
            "description": "/img/content-blog-raw-blog-image-similarity-system-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "aws beanstalk",
                "permalink": "/blog/tags/aws-beanstalk"
              },
              {
                "label": "flask",
                "permalink": "/blog/tags/flask"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 3.045,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Finding Hardware Parts in Warehouse",
              "permalink": "/blog/2021/10/01/finding-hardware-parts-in-warehouse"
            },
            "nextItem": {
              "title": "Insurance Personalization",
              "permalink": "/blog/2021/10/01/insurance-personalization"
            }
          },
          "content": "![/img/content-blog-raw-blog-image-similarity-system-untitled.png](/img/content-blog-raw-blog-image-similarity-system-untitled.png)\n\n# Choice of variables\n\n### Image Encoder\n\nWe can select any pre-trained image classification model. These models are commonly known as encoders because their job is to encode an image into a feature vector. I analyzed four encoders named 1) MobileNet, 2) EfficientNet, 3) ResNet and 4) [BiT](https://tfhub.dev/google/bit/m-r152x4/1). After basic research, I decided to select BiT model because of its performance and state-of-the-art nature. I selected the BiT-M-50x3 variant of model which is of size 748 MB. More details about this architecture can be found on the official page [here](https://tfhub.dev/google/bit/m-r50x3/1). \n\n### Vector Similarity System\n\nImages are represented in a fixed-length feature vector format. For the given input vector, we need to find the TopK most similar vectors, keeping the memory efficiency and real-time retrival objective in mind. I explored the most popular techniques and listed down five of them: Annoy, Cosine distance, L1 distance, Locally Sensitive Hashing (LSH) and Image Deep Ranking. I selected Annoy because of its fast and efficient nature. More details about Annoy can be found on the official page [here](https://github.com/spotify/annoy).\n\n### Dataset\n\nI listed down 3 datasets from Kaggle that were best fitting the criteria of this use case: 1) [Fashion Product Images (Small)](https://www.kaggle.com/bhaskar2443053/fashion-small?), 2) [Food-11 image dataset](https://www.kaggle.com/trolukovich/food11-image-dataset?) and 3) [Caltech 256 Image Dataset](https://www.kaggle.com/jessicali9530/caltech256?). I selected Fashion dataset and Foods dataset.\n\n# Literature review\n\n- Determining Image similarity with Quasi-Euclidean Metric [arxiv](https://arxiv.org/abs/2006.14644v1)\n- CatSIM: A Categorical Image Similarity Metric [arxiv](https://arxiv.org/abs/2004.09073v1)\n- Central Similarity Quantization for Efficient Image and Video Retrieval [arxiv](https://arxiv.org/abs/1908.00347v5)\n- Improved Deep Hashing with Soft Pairwise Similarity for Multi-label Image Retrieval [arxiv](https://arxiv.org/abs/1803.02987v3)\n- Model-based Behavioral Cloning with Future Image Similarity Learning [arxiv](https://arxiv.org/abs/1910.03157v1)\n- Why do These Match? Explaining the Behavior of Image Similarity Models [arxiv](https://arxiv.org/abs/1905.10797v1)\n- Learning Non-Metric Visual Similarity for Image Retrieval [arxiv](https://arxiv.org/abs/1709.01353v2)\n\n# Process Flow\n\n### Step 1: Data Acquisition\n\nDownload the raw image dataset into a directory. Categorize these images into their respective category directories. Make sure that images are of the same type, JPEG recommended. We will also process the metadata and store it in a serialized file, CSV recommended. \n\n### Step 2: Encoder Fine-tuning\n\nDownload the pre-trained image model and add two additional layers on top of that: the first layer is a feature vector layer and the second layer is the classification layer. We will only train these 2 layers on our data and after training, we will select the feature vector layer as the output of our fine-tuned encoder. After fine-tuning the model, we will save the feature extractor for later use.\n\n![Fig: a screenshot of encoder fine-tuning process](/img/content-blog-raw-blog-image-similarity-system-untitled-1.png)\n\nFig: a screenshot of encoder fine-tuning process\n\n### Step 3: Image Vectorization\n\nNow, we will use the encoder (prepared in step 2) to encode the images (prepared in step 1). We will save feature vector of each image as an array in a directory. After processing, we will save these embeddings for later use.\n\n### Step 4: Metadata and Indexing\n\nWe will assign a unique id to each image and create dictionaries to locate information of this image: 1) Image id to Image name dictionary, 2) Image id to image feature vector dictionary, and 3) (optional) Image id to metadata product id dictionary. We will also create an image id to image feature vector indexing. Then we will save these dictionaries and index object for later use.\n\n### Step 5: API Call\n\nWe will receive an image from user, encode it with our image encoder, find TopK similar vectors using Indexing object, and retrieve the image (and metadata) using dictionaries. We send these images (and metadata) back to the user.\n\n# Deployment\n\nThe API was deployed on AWS cloud infrastructure using AWS Elastic Beanstalk service.\n\n![/img/content-blog-raw-blog-image-similarity-system-untitled-2.png](/img/content-blog-raw-blog-image-similarity-system-untitled-2.png)"
        },
        {
          "id": "/2021/10/01/insurance-personalization",
          "metadata": {
            "permalink": "/blog/2021/10/01/insurance-personalization",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-insurance-personalization.mdx",
            "source": "@site/blog/2021-10-01-insurance-personalization.mdx",
            "title": "Insurance Personalization",
            "description": "Author: Alexsoft",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "insurance",
                "permalink": "/blog/tags/insurance"
              },
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              }
            ],
            "readingTime": 9.355,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Image Similarity System",
              "permalink": "/blog/2021/10/01/image-similarity-system"
            },
            "nextItem": {
              "title": "Name & Address Parsing",
              "permalink": "/blog/2021/10/01/name-&-address-parsing"
            }
          },
          "content": "Author: [Alexsoft](https://www.altexsoft.com/blog/personalized-insurance/)\n\nIn a hyper-connected world, where advanced analytics and smart devices constantly re-assess and monitor risks, the traditional once-a-year insurance policy looks increasingly irrelevant and static. Insurance will become a breathing and living thing that shrinks and scales with time to accommodate the changing risks in the clients’ daily lives. As technology continues to expand, real-time data from connected devices and predictive analysis from AIs and machine learning will enhance personalized insurance to benefit the client and insurer.\n\nTo satisfy the expectations of clients, insurers may need to go beyond the personalization of marketing communication and start personalizing product bundles for individuals.\n\n## What is personalized insurance?\n\n**Personalized insurance** is the process of reaching insurance customers with targeted pricing, offers, and messages at the right time. Personalization spans across various types of insurance services, from health to property insurance.\n\nSome insurers are already defining themselves as trusted advisors aiding people in navigating, anticipating, and eliminating risks rather than just paying the compensation when things go wrong.\n\nFor example, these companies use customer data from wearable and smart devices to monitor the user’s lifestyle. If the user’s data indicate the emergence of a serious medical condition, they can send the customer content designed to change their detrimental lifestyle or recommend immediate treatment. When the customer stays fit, healthy and does not carry out risky activities, their insurance cost will be decreased.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled.png](/img/content-blog-raw-blog-insurance-personalization-untitled.png)\n\nInsurers can provide personalization to customers at different levels:\n\n- **Personalized product bundles.** The insurer offers a wide range of products such as health, car, life, and property insurance. So, clients can choose the specific products they want and group them in a bundle.\n- **Personalized communications.** Insurers use data collected from smart devices to notify customers about harmful activities and lifestyles. They also send recommendations on lifestyle changes. Some insurers take a step further to provide clients with incentives for a healthy lifestyle.\n- **Personalized insurance quote.** Customers are able to adjust the price of their insurance premiums by turning off the ones they don’t need at any time. Some insurers enable automatic quote adjustments depending on customer’s behavior (e.g., driving habits) or lifestyle choices (e.g., exercising).\n\n### Why is it important?\n\nCollecting and analyzing user data is vital in personalizing products based on individual behavior and preferences. In addition, insurers should use this data to enhance external relationships with their customers and guide their internal processes. This will eventually lead to delightful customer experiences and efficient operations.\n\nPersonalized insurance is important for many reasons:\n\n**Customers expect personalized treatment.** Every customer wants to feel special, and the personalization of your services and products will do just that. It will make them stay loyal to you. Moreover, customers are open for personalization. According to the [Accenture study](https://www.accenture.com/_acnmedia/PDF-95/Accenture-2019-Global-Financial-Services-Consumer-Study.pdf#zoom=50), 95 percent of new customers are ready to share their data in exchange for personalized insurance services. And about 58 percent of conservative users would be willing to do so.\n\n**Driving more effective sales and increasing revenue.** Personalization benefits your sales and income in two ways. First, lots of people are ready to share their data with you in exchange for incentives and reduced premiums. Secondly, having access to clients’ data gives you the ability to target people who are already interested in your product, thereby increasing sales and revenue at a lower cost. You will be able to reach your customers at the right time and with the product they need.\n\n**Streamlining operations and working with customers more accurately.** Having an insight into customer preferences and behavior is crucial if you want to provide personalized services. Data obtained from social media activity, fitness trackers, GPS, and other tech can help you serve customers better.\n\n## Success stories\n\n### Lemonade\n\nUse of AI and chatbots to personalize communications. \n\nLemonade is a US insurance company that uses Maya – an AI-powered bot, to collect and analyze customer data. Maya acts as a virtual assistant that gets information, provides quotes, and handles payments. It also has the ability to provide customized answers to user’s questions and even help them make changes to existing policies. Lemonade uses Natural Action Synthesis and Natural Language Processing to ensure that Maya gets smarter the more it chats. This is possible because their machine learning model is retrained almost daily.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-1.png](/img/content-blog-raw-blog-insurance-personalization-untitled-1.png)\n\nOn top of that, the company uses big data analytics to quantify losses and predict risks by placing the client into a risk group and quoting a relevant premium. Customers are grouped according to their risk behaviors. The groups are created using algorithms that collect extensive customer data, such as health conditions.\n\n### Cover\n\n**[Cover](https://cover.com/)** is a US-based insurance metasearch company that notifies its clients of price drops for their premiums. Their technology works by scanning the market, looking for discounted and lowered prices of insurance premiums for their clients. Cover blends automation, mobile technology, and expert advice to provide customers with high-quality insurance protection at the best prices.\n\nCover compares with policy data and prices from over 30 different insurers. From the start, the customers need to provide answers to some questions, which will be used to match the client with a policy that suits their needs.\n\n### Oscar\n\n**[Oscar](https://www.hioscar.com/)** is a health insurer that provides its clients with a concierge team of medical professionals who give health advice and help them know if they see the best specialist for their specific health condition. They also help with finding the best doctors that accept Oscar insurance and manage and treat chronic conditions. Also, they set aside a separate concierge team in cases of emergencies that helps with the patient’s discharge and follow-up care.\n\nOscar’s mobile app acts as an intermediary between the user and the health system. The platform facilitates the customer’s interaction with their healthcare professionals. Clients can receive their lab reports, medical records, physician recommendations, and virtual care from the app. Oscar has also improved its high-touch services, including telemedicine and an “Ask your concierge” feature that connects users with a health insurance advice team.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-2.png](/img/content-blog-raw-blog-insurance-personalization-untitled-2.png)\n\n### Alllstate\n\nAllstate is an auto insurance company that offers personalized car insurance to its customers using telematics programs called Drivewise and Milewise. Drivewise is offered through a mobile app that monitors the customers driving behavior and provides feedback after each drive. Customers also receive incentives for safe driving. From the app interface, clients can check their rewards and driving behavior for the last 100 trips. The customer’s premium is then calculated based on factors like speeding, abrupt braking, and time of the trip. One of the nice things about Drivewise is that even those who do not have an Allstate care insurance policy can participate in this program. Their Milewise program, as the name suggests, lets customers pay insurance based on the miles covered. So, the app monitors the distance covered by the car, and low-mileage drivers can save on insurance.\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-3.png](/img/content-blog-raw-blog-insurance-personalization-untitled-3.png)\n\n## How to approach personalization?\n\n![/img/content-blog-raw-blog-insurance-personalization-untitled-4.png](/img/content-blog-raw-blog-insurance-personalization-untitled-4.png)\n\nBefore fully investing in personalization, you need to carefully plan your approach. This will ensure you have all the pieces for success, and it will help you follow through with your plan.\n\n### Explore existing data\n\nHaving customer data is the minimum requirement to provide personalized services. First, you need to envision the type of personalization you want to offer. Then, make sure you have data collection channels that provide you with relevant data needed for your tasks. For instance, some of your documents may contain the required information, and you have to digitize, structure those, or extract specific details for that. So, you should audit your current information and data collection mechanisms to estimate whether you’ll need any additional effort to gather this data. For instance, you may want to use [intelligent document processing](https://www.altexsoft.com/blog/intelligent-document-processing/).\n\n### Engage data scientists to make the proof of concept and carry out A/B tests\n\nYour vision on personalization may not work for every business model. Or your data quality may be low to reach project feasibility. We’ve talked about that while explaining how to approach [ROI calculations with machine learning projects](https://www.altexsoft.com/blog/business/how-to-estimate-roi-and-costs-for-machine-learning-and-data-science-projects/). So, you need to present the data you have to a data science team to run several experiments and build prototypes. Once they are ready, you can roll out your new algorithms for a subset of customers to run A/B tests. Their results may show that the conventional approaches work better for you or help iterate on your assumptions.\n\n### Invest in data infrastructure\n\nIf the A/B tests show that personalization will work for your business model, that is where automation comes into play. You can start investing in data infrastructure and [analytical pipelines](https://www.altexsoft.com/blog/data-pipeline-components-and-types/) to automate data collection and analysis mechanisms.\n\nYou’ll need a [data engineering team](https://www.altexsoft.com/blog/datascience/what-is-data-engineering-explaining-data-pipeline-data-warehouse-and-data-engineer-role/) for that. These specialists set up connections with data sources, such as mobile, IoT, and telematics devices, enable automatic data preparation, configure storages, and integrate your infrastructure with business intelligence software that helps explore and visualize data.\n\n### Continuously learn your customers’ preferences and needs\n\nThe data you collect is only as good as the insights gained from it. That is why it is vital to have a [comprehensive analytic solution](https://www.altexsoft.com/blog/business/complete-guide-to-business-intelligence-and-analytics-strategy-steps-processes-and-tools/). A high-quality analytic software will transform the data into your most valuable asset. This data will be used to improve product development, make more accurate decisions, and provide personalized services to your customers.\n\n### Iterate on your infrastructure and algorithms\n\nPersonalization isn’t a one-time project. Whether you apply machine learning or build personalization based on rule-based systems, you still have to revisit your technology, continuously gather new data, and adapt your workflows.\n\n### Ensure a personalized cross-channel experience\n\nSince the data collected from IoT devices and other tech is vital for personalization, it is important to make the customer experience seamless across different communication channels. Therefore, the customer should always be provided with the same level of personalization regardless of the touchpoint.\n\n## Challenges\n\n**Personalization is financially intensive.** The ability of insurers to personalize insurance differs only marginally between marketing communications and products. Most of them, especially startups, do not have the funds to implement advanced technologies like machine learning needed for personalized insurance. However, insurers do not need to start with all the levels of personalization. They can often start by customizing their customer service, gathering data and insights, and then gradually developing towards more complex systems.\n\n**Complex process involving multiple parties.** Also, it is difficult to balance personalization with financial targets, especially when establishing a price for risk. In-depth personalization of insurance must use data analytics from different sources to ensure that personalized offers reflect the client’s needs as well as the profitability and risks implications for the company.\n\n**Customer data is heavily regulated.** Customer data from different sources are subject to industry regulations and privacy concerns. It is often a difficult task to obtain approval from regulators to use this data. Also, customers are becoming more aware of how companies are using their data and approve strict regulations. That is why laws such as General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA) have been passed, which gives customers more control over their data. Insurers can address this barrier by explaining to people how their systems work and how personal data is used. Read more on [explainable machine learning](https://www.altexsoft.com/blog/interpretability-machine-learning/) in our dedicated article. Besides being open, insurers can provide clients with incentives and other services for free in exchange for access to personal data."
        },
        {
          "id": "/2021/10/01/name-&-address-parsing",
          "metadata": {
            "permalink": "/blog/2021/10/01/name-&-address-parsing",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-name-&-address-parsing.mdx",
            "source": "@site/blog/2021-10-01-name-&-address-parsing.mdx",
            "title": "Name & Address Parsing",
            "description": "/img/content-blog-raw-blog-name-&-address-parsing-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "flask",
                "permalink": "/blog/tags/flask"
              },
              {
                "label": "ner",
                "permalink": "/blog/tags/ner"
              },
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              }
            ],
            "readingTime": 3.8,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Insurance Personalization",
              "permalink": "/blog/2021/10/01/insurance-personalization"
            },
            "nextItem": {
              "title": "Object Detection Hands-on Exercises",
              "permalink": "/blog/2021/10/01/object-detection-hands-on-exercises"
            }
          },
          "content": "![/img/content-blog-raw-blog-name-&-address-parsing-untitled.png](/img/content-blog-raw-blog-name-&-address-parsing-untitled.png)\n\n# Introduction\n\nCreate an API that can parse and classify names and addresses given a string. We tried [probablepeople](https://github.com/datamade/probablepeople) and [usaddress](https://github.com/datamade/usaddress). These work well separately but need the functionality of these packages combined, and better accuracy than what probablepeople provides.\nFor the API, I'd like to mimic [this](https://parserator.datamade.us/api-docs/) with some minor modifications.\nA few examples: \n\n- \"KING JOHN A 5643 ROUTH CREEK PKWY #1314 RICHARDSON TEXAS 750820146 UNITED STATES OF AMERICA\" would return type: person; first_name: JOHN; last_name: KING; middle: A; street_address: 5643 ROUTH CREEK PKWY #1314; city: RICHARDSON; state: TEXAS; zip: 75082-0146; country: UNITED STATES OF AMERICA.\n- \"THRM NGUYEN LIVING TRUST 2720 SUMMERTREE CARROLLTON HOUSTON TEXAS 750062646 UNITED STATES OF AMERICA\" would return type: entity; name: THRM NGUYEN LIVING TRUST; street_address: 2720 SUMMERTREE CARROLLTON; state: TEXAS; city: HOUSTON; zip: 75006-2646; country: UNITED STATES OF AMERICA.\n\n# Modeling Approach\n\n### List of Entities\n\nList of Entities A - Person, Household, Corporation\n\nList of Entities B - Person First name, Person Middle name, Person Last name, Street address, City, State, Pincode, Country, Company name\n\n### Endpoint Configuration\n\n**OOR Endpoint**\n\nInput Instance: ANDERSON, EARLINE 1423 NEW YORK AVE FORT WORTH, TX 76104 7522\n\n```\nOutput Tags:-\n<Type> - Person/Household/Corporation\n<GivenName>, <MiddleName>, <Surname> - if Type Person/Household\n<Name> - Full Name - if Type Person \n<Name> - Household - if Type Household\n<Name> - Corporation - If Type Corporation\n<Address> - Full Address\n<StreetAddress>, <City>, <State>, <Zipcode>, <Country>\n~~NameConfidence, AddrConfidence~~\n```\n\n**Name Endpoint**\n\nInput Instance: ANDERSON, EARLINE\n\n```\nOutput Tags:-\n\n- <Type> - Person/Household/Corporation\n- <GivenName>, <MiddleName>, <Surname> - if Type Person/Household\n- <Name> - Full Name - if Type Person\n- <Name> - Household - if Type Household\n- <Name> - Corporation - If Type Corporation\n- ~~NameConfidence~~\n```\n\n**Address Endpoint**\n\nInput Instance: 1423 NEW YORK AVE FORT WORTH, TX 76104 7522\n\n```\nOutput Tags:-\n\n- <Address> - Full Address\n- <StreetAddress>, <City>, <State>, <Zipcode>, <Country>\n- ~~AddrConfidence~~\n```\n\n### Process Flow\n\n- Pytorch Flair NER model\n- Pre trained word embeddings\n- Additional parsing models on top of name tags\n- Tagging of 1000+ records to create training data\n- Deployment as REST api with 3 endpoints - name parse, address parse and whole string parse\n\n# Framework\n\n![/img/content-blog-raw-blog-name-&-address-parsing-untitled-1.png](/img/content-blog-raw-blog-name-&-address-parsing-untitled-1.png)\n\n![/img/content-blog-raw-blog-name-&-address-parsing-untitled-2.png](/img/content-blog-raw-blog-name-&-address-parsing-untitled-2.png)\n\n# Tagging process\n\nI used Doccano ([https://github.com/doccano/doccano](https://github.com/doccano/doccano)) for labeling the dataset. This tool is open-source and free to use. I deployed it with a one-click Heroku service (fig 1). After launching the app, log in with the provided credentials, and create a project (fig 2). Create the labels and upload the dataset (fig 3). Start the annotation process (fig 4). Now after enough annotations (you do not need complete all annotations in one go), go back to projects > edit section and export the data (fig 5). Bring the exported JSON file in python and run the model training code. The whole model will automatically get trained on the new annotations. To make the training faster, you can use Nvidia GPU support.\n\n![fig 1: screenshot taken from Doccano's github page](/img/content-blog-raw-blog-name-&-address-parsing-untitled-3.png)\n\nfig 1: screenshot taken from Doccano's github page\n\n![fig 2: Doccano's deployed app homepage](/img/content-blog-raw-blog-name-&-address-parsing-untitled-4.png)\n\nfig 2: Doccano's deployed app homepage\n\n![fig 3: create the labels. I defined these labels for my project](/img/content-blog-raw-blog-name-&-address-parsing-untitled-5.png)\n\nfig 3: create the labels. I defined these labels for my project\n\n![fig 5: export the annotations](/img/content-blog-raw-blog-name-&-address-parsing-untitled-6.png)\n\nfig 5: export the annotations\n\n# Model\n\nI first tried the Spacy NER blank model but it was not giving high-quality results. So I moved to the PyTorch Flair NER model. This model was a way faster (5 min training because of GPU compatibility comparing to 1-hour Spacy training time) and also much more accurate. F1 results for all tags were near perfect (score of 1).  This score will increase further with more labeled data. This model is production-ready.\n\n# Inference\n\nFor OOR, I directly used the model's output for core tagging and created the aggregated tags like recipient (aggregation of name tags) and address (aggregation of address tags like city and state) using simple conditional concatenation. For only Name and only Address inference, I added the dummy address in name text and dummy name in address text. This way, I passed the text in same model and later on filtered the required tags as output. \n\n### API\n\nI used Flask REST framework in Python to build the API with 3 endpoints. This API is production-ready.\n\n# Results and Discussion\n\n- 0.99 F1 score on 6 out of 8 tags & 0.95+ F1 score on other 2 tags\n- API inference time of less than 1 second on single CPU"
        },
        {
          "id": "/2021/10/01/object-detection-hands-on-exercises",
          "metadata": {
            "permalink": "/blog/2021/10/01/object-detection-hands-on-exercises",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-object-detection-hands-on-exercises.mdx",
            "source": "@site/blog/2021-10-01-object-detection-hands-on-exercises.mdx",
            "title": "Object Detection Hands-on Exercises",
            "description": "We are going to discuss the following 4 use cases:",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "object detection",
                "permalink": "/blog/tags/object-detection"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 3.165,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Name & Address Parsing",
              "permalink": "/blog/2021/10/01/name-&-address-parsing"
            },
            "nextItem": {
              "title": "Object detection with OpenCV",
              "permalink": "/blog/2021/10/01/object-detection-with-opencv"
            }
          },
          "content": "We are going to discuss the following 4 use cases:\n\n1. Detect faces, eyes, pedestrians, cars, and number plates using OpenCV haar cascade classifiers\n2. Streamlit app for MobileNet SSD Caffe Pre-trained model\n3. Streamlit app for various object detection models and use cases\n4. Detect COCO-80 class objects in videos using TFHub MobileNet SSD model\n\n### Use Case 1 -  **Object detection with OpenCV**\n\n**Face detection** - We will use the frontal face Haar cascade classifier model to detect faces in the given image. The following function first passes the given image into the classifier model to detect a list of face bounding boxes and then runs a loop to draw a red rectangle box around each detected face in the image:\n\n```python\ndef detect_faces(fix_img):\n    face_rects = face_classifier.detectMultiScale(fix_img)\n    for (x, y, w, h) in face_rects:\n        cv2.rectangle(fix_img,\n                     (x,y),\n                     (x+w, y+h),\n                     (255,0,0),\n                     10)\n    return fix_img\n```\n\n**Eyes detection** - The process is almost similar to the face detection process. Instead of frontal face Haar cascade, we will use the eye detection Haar cascade model.\n\n![Input image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled.png)\n\nInput image\n\n![detected faces and eyes in the image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled-1.png)\n\ndetected faces and eyes in the image\n\n**Pedestrian detection** - We will use the full-body Haar cascade classifier model for pedestrian detection. We will apply this model to a video this time. The following function will run the model on each frame of the video to detect the pedestrians:\n\n```python\n# While Loop\nwhile cap.isOpened():\n    # Read the capture\n\t\tret, frame = cap.read()\n    # Pass the Frame to the Classifier\n\t\tbodies = body_classifier.detectMultiScale(frame, 1.2, 3)\n    # if Statement\n\t\tif ret == True:\n        # Bound Boxes to Identified Bodies\n\t\t\t\tfor (x,y,w,h) in bodies:\n            cv2.rectangle(frame,\n                         (x,y),\n                         (x+w, y+h),\n                         (25,125,225),\n                         5)\n            cv2.imshow('Pedestrians', frame) \n        # Exit with Esc button\n\t\t\t\tif cv2.waitKey(1) == 27:\n            break  \n    # else Statement\n\t\telse:\n        break\n    \n# Release the Capture & Destroy All Windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n**Car detection** - The process is almost similar to the pedestrian detection process. Again, we will use this model on a video. Instead of people Haar cascade, we will use the car cascade model.\n\n**Car number plate detection** - The process is almost similar to the face and eye detection process. We will use the car number plate cascade model.\n\n*You can find the code [here](https://github.com/sparsh-ai/0D7ACA15) on Github.*\n\n### Use Case 2 - MobileNet SSD Caffe Pre-trained model\n\n*You can play with the live app [here](https://share.streamlit.io/sparsh-ai/streamlit-5a407279/app.py). Souce code is available* [here](https://github.com/sparsh-ai/streamlit-489fbbb7) *on Github.*\n\n### Use Case 3 - YOLO Object Detection App\n\n*You can play with the live app* [*here](https://share.streamlit.io/sparsh-ai/streamlit-489fbbb7/app.py). Source code is available [here](https://github.com/sparsh-ai/streamlit-5a407279/tree/master) on Github.*\n\nThis app can detect COCO 80-classes using three different models - Caffe MobileNet SSD, Yolo3-tiny, and Yolo3. It can also detect faces using two different models - SSD Res10 and OpenCV face detector.  Yolo3-tiny can also detect fires.\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png)\n\n### Use Case 4 - TFHub MobileNet SSD on Videos\n\nIn this section, we will use the MobileNet SSD object detection model from TFHub. We will apply it to videos. We can load the model using the following command:\n\n```python\nmodule_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\"\ndetector = hub.load(module_handle).signatures['default']\n```\n\nAfter loading the model, we will capture frames using OpenCV video capture method, and pass each frame through the detection model:\n\n```python\ncap = cv2.VideoCapture('/content/Spectre_opening_highest_for_a_James_Bond_film_in_India.mp4')\nfor i in range(1,total_frames,200):\n    cap.set(cv2.CAP_PROP_POS_FRAMES,i)\n    ret,frame = cap.read()\n    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    run_detector(detector,frame)\n```\n\nHere are some detected objects in frames: \n\n![/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled.png](/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-1.png](/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-1.png)\n\n![/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-2.png](/img/content-blog-raw-blog-object-detection-hands-on-exercises-untitled-2.png)\n\n*You can find the code [here](https://gist.github.com/sparsh-ai/32ff6fe8c073f6be5d893029e4dc2960) on Github.*\n\n---\n\n*Congrats! In the next post of this series, we will cover 5 exciting use cases - 1) detectron 2 object detection fine-tuning on custom class, 2) Tensorflow Object detection API inference, fine-tuning, and few-shot learning, 3) Inference with 6 pre-trained models, 4) Mask R-CNN object detection app, and 5) Logo detection app deployment as a Rest API using AWS elastic Beanstalk.*"
        },
        {
          "id": "/2021/10/01/object-detection-with-opencv",
          "metadata": {
            "permalink": "/blog/2021/10/01/object-detection-with-opencv",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-object-detection-with-opencv.mdx",
            "source": "@site/blog/2021-10-01-object-detection-with-opencv.mdx",
            "title": "Object detection with OpenCV",
            "description": "Face detection",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "object detection",
                "permalink": "/blog/tags/object-detection"
              },
              {
                "label": "opencv",
                "permalink": "/blog/tags/opencv"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 1.565,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Object Detection Hands-on Exercises",
              "permalink": "/blog/2021/10/01/object-detection-hands-on-exercises"
            },
            "nextItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/10/01/object-detection-with-yolo3"
            }
          },
          "content": "## **Face detection**\n\nWe will use the frontal face Haar cascade classifier model to detect faces in the given image. The following function first passes the given image into the classifier model to detect a list of face bounding boxes and then runs a loop to draw a red rectangle box around each detected face in the image:\n\n```python\ndef detect_faces(fix_img):\n    face_rects = face_classifier.detectMultiScale(fix_img)\n    for (x, y, w, h) in face_rects:\n        cv2.rectangle(fix_img,\n                     (x,y),\n                     (x+w, y+h),\n                     (255,0,0),\n                     10)\n    return fix_img\n```\n\n## **Eyes detection**\n\nThe process is almost similar to the face detection process. Instead of frontal face Haar cascade, we will use the eye detection Haar cascade model.\n\n![Input image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled.png)\n\nInput image\n\n![detected faces and eyes in the image](/img/content-blog-raw-blog-object-detection-with-opencv-untitled-1.png)\n\ndetected faces and eyes in the image\n\n## **Pedestrian detection**\n\nWe will use the full-body Haar cascade classifier model for pedestrian detection. We will apply this model to a video this time. The following function will run the model on each frame of the video to detect the pedestrians:\n\n```python\n# While Loop\nwhile cap.isOpened():\n    # Read the capture\n\t\tret, frame = cap.read()\n    # Pass the Frame to the Classifier\n\t\tbodies = body_classifier.detectMultiScale(frame, 1.2, 3)\n    # if Statement\n\t\tif ret == True:\n        # Bound Boxes to Identified Bodies\n\t\t\t\tfor (x,y,w,h) in bodies:\n            cv2.rectangle(frame,\n                         (x,y),\n                         (x+w, y+h),\n                         (25,125,225),\n                         5)\n            cv2.imshow('Pedestrians', frame) \n        # Exit with Esc button\n\t\t\t\tif cv2.waitKey(1) == 27:\n            break  \n    # else Statement\n\t\telse:\n        break\n    \n# Release the Capture & Destroy All Windows\ncap.release()\ncv2.destroyAllWindows()\n```\n\n## **Car detection**\n\nThe process is almost similar to the pedestrian detection process. Again, we will use this model on a video. Instead of people Haar cascade, we will use the car cascade model.\n\n## **Car number plate detection**\n\nThe process is almost similar to the face and eye detection process. We will use the car number plate cascade model.\n\n*You can find the code [here](https://github.com/sparsh-ai/0D7ACA15) on Github.*"
        },
        {
          "id": "/2021/10/01/object-detection-with-yolo3",
          "metadata": {
            "permalink": "/blog/2021/10/01/object-detection-with-yolo3",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-object-detection-with-yolo3.mdx",
            "source": "@site/blog/2021-10-01-object-detection-with-yolo3.mdx",
            "title": "Object detection with YOLO3",
            "description": "Live app",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "streamlit",
                "permalink": "/blog/tags/streamlit"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 1.975,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Object detection with OpenCV",
              "permalink": "/blog/2021/10/01/object-detection-with-opencv"
            },
            "nextItem": {
              "title": "OCR experiments",
              "permalink": "/blog/2021/10/01/ocr-experiments"
            }
          },
          "content": "## Live app\n\nThis app can detect COCO 80-classes using three different models - Caffe MobileNet SSD, Yolo3-tiny, and Yolo3. It can also detect faces using two different models - SSD Res10 and OpenCV face detector.  Yolo3-tiny can also detect fires.\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png)\n\n## Code\n\n```python\nimport streamlit as st\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport os\n\nfrom tempfile import NamedTemporaryFile\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\ntemp_file = NamedTemporaryFile(delete=False)\n\nDEFAULT_CONFIDENCE_THRESHOLD = 0.5\nDEMO_IMAGE = \"test_images/demo.jpg\"\nMODEL = \"model/MobileNetSSD_deploy.caffemodel\"\nPROTOTXT = \"model/MobileNetSSD_deploy.prototxt.txt\"\n\nCLASSES = [\n    \"background\",\n    \"aeroplane\",\n    \"bicycle\",\n    \"bird\",\n    \"boat\",\n    \"bottle\",\n    \"bus\",\n    \"car\",\n    \"cat\",\n    \"chair\",\n    \"cow\",\n    \"diningtable\",\n    \"dog\",\n    \"horse\",\n    \"motorbike\",\n    \"person\",\n    \"pottedplant\",\n    \"sheep\",\n    \"sofa\",\n    \"train\",\n    \"tvmonitor\",\n]\nCOLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n\n@st.cache\ndef process_image(image):\n    blob = cv2.dnn.blobFromImage(\n        cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5\n    )\n    net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n    net.setInput(blob)\n    detections = net.forward()\n    return detections\n\n@st.cache\ndef annotate_image(\n    image, detections, confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD\n):\n    # loop over the detections\n    (h, w) = image.shape[:2]\n    labels = []\n    for i in np.arange(0, detections.shape[2]):\n        confidence = detections[0, 0, i, 2]\n\n        if confidence > confidence_threshold:\n            # extract the index of the class label from the `detections`,\n            # then compute the (x, y)-coordinates of the bounding box for\n            # the object\n            idx = int(detections[0, 0, i, 1])\n            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n            (startX, startY, endX, endY) = box.astype(\"int\")\n\n            # display the prediction\n            label = f\"{CLASSES[idx]}: {round(confidence * 100, 2)}%\"\n            labels.append(label)\n            cv2.rectangle(image, (startX, startY), (endX, endY), COLORS[idx], 2)\n            y = startY - 15 if startY - 15 > 15 else startY + 15\n            cv2.putText(\n                image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2\n            )\n    return image, labels\n\ndef main():\n  selected_box = st.sidebar.selectbox(\n    'Choose one of the following',\n    ('Welcome', 'Object Detection')\n    )\n    \n  if selected_box == 'Welcome':\n      welcome()\n  if selected_box == 'Object Detection':\n      object_detection() \n\ndef welcome():\n  st.title('Object Detection using Streamlit')\n  st.subheader('A simple app for object detection')\n  st.image('test_images/demo.jpg',use_column_width=True)\n\ndef object_detection():\n  \n  st.title(\"Object detection with MobileNet SSD\")\n\n  confidence_threshold = st.sidebar.slider(\n    \"Confidence threshold\", 0.0, 1.0, DEFAULT_CONFIDENCE_THRESHOLD, 0.05)\n\n  st.sidebar.multiselect(\"Select object classes to include\",\n  options=CLASSES,\n  default=CLASSES\n  )\n\n  img_file_buffer = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n\n  if img_file_buffer is not None:\n      temp_file.write(img_file_buffer.getvalue())\n      image = load_img(temp_file.name)\n      image = img_to_array(image)\n      image = image/255.0\n\n  else:\n      demo_image = DEMO_IMAGE\n      image = np.array(Image.open(demo_image))\n\n  detections = process_image(image)\n  image, labels = annotate_image(image, detections, confidence_threshold)\n\n  st.image(\n      image, caption=f\"Processed image\", use_column_width=True,\n  )\n\n  st.write(labels)\n\nmain()\n```\n\n*You can play with the live app* [*here](https://share.streamlit.io/sparsh-ai/streamlit-489fbbb7/app.py). Source code is available [here](https://github.com/sparsh-ai/streamlit-5a407279/tree/master) on Github.*"
        },
        {
          "id": "/2021/10/01/ocr-experiments",
          "metadata": {
            "permalink": "/blog/2021/10/01/ocr-experiments",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-ocr-experiments.mdx",
            "source": "@site/blog/2021-10-01-ocr-experiments.mdx",
            "title": "OCR experiments",
            "description": "/img/content-blog-raw-blog-ocr-experiments-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "ocr",
                "permalink": "/blog/tags/ocr"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 1.155,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/10/01/object-detection-with-yolo3"
            },
            "nextItem": {
              "title": "PDF to Wordcloud via Mail",
              "permalink": "/blog/2021/10/01/pdf-to-wordcloud-via-mail"
            }
          },
          "content": "![/img/content-blog-raw-blog-ocr-experiments-untitled.png](/img/content-blog-raw-blog-ocr-experiments-untitled.png)\n\n## 1. Tesseract\n\nTesseract is an open-source text recognition engine that is available under the Apache 2.0 license and its development has been sponsored by Google since 2006.\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/2d1f533048a3655de625298c3dd32d47)\n\n## 2. EasyOCR\n\nReady-to-use OCR with 70+ languages supported including Chinese, Japanese, Korean and Thai. EasyOCR is built with Python and Pytorch deep learning library, having a GPU could speed up the whole process of detection. The detection part is using the CRAFT algorithm and the Recognition model is CRNN. It is composed of 3 main components, feature extraction (we are currently using Resnet), sequence labelling (LSTM) and decoding (CTC). EasyOCR doesn’t have much software dependencies, it can directly be used with its API.\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/12359606ee4127513c66fc3b4ff18e5b)\n\n## 3. KerasOCR\n\nThis is a slightly polished and packaged version of the Keras CRNN implementation and the published CRAFT text detection model. It provides a high-level API for training a text detection and OCR pipeline and out-of-the-box OCR models, and an end-to-end training pipeline to build new OCR models.\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/2fcb764619baf5f56cf7122b1b2c527c)\n\n## 4. ArabicOCR\n\nIt is an OCR system for the Arabic language that converts images of typed text to machine-encoded text. It currently supports only letters (29 letters).  ArabicOCR aims to solve a simpler problem of OCR with images that contain only Arabic characters (check the dataset link below to see a sample of the images).\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/26df76b78f8cd2018a068b284b7cfe56)"
        },
        {
          "id": "/2021/10/01/pdf-to-wordcloud-via-mail",
          "metadata": {
            "permalink": "/blog/2021/10/01/pdf-to-wordcloud-via-mail",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-pdf-to-wordcloud-via-mail.mdx",
            "source": "@site/blog/2021-10-01-pdf-to-wordcloud-via-mail.mdx",
            "title": "PDF to Wordcloud via Mail",
            "description": "/img/content-blog-raw-blog-pdf-to-wordcloud-via-mail-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [],
            "readingTime": 1.015,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "OCR experiments",
              "permalink": "/blog/2021/10/01/ocr-experiments"
            },
            "nextItem": {
              "title": "Personalized Unexpectedness in  Recommender Systems",
              "permalink": "/blog/2021/10/01/personalized-unexpectedness-in-recommender-systems"
            }
          },
          "content": "![/img/content-blog-raw-blog-pdf-to-wordcloud-via-mail-untitled.png](/img/content-blog-raw-blog-pdf-to-wordcloud-via-mail-untitled.png)\n\n## Objective\n\nIntegrating PDF, Text, Wordcloud and Email functionalities in Python\n\n## Process Flow\n\n- Step 1 - I use PyPDF2 library to read PDF text in Python\n- Step 2 - Import the supporting libraries\n- Step 3 - Count No. of Pages for this pdf and extract text for each page using loop\n- Step 4 - Build Text corpus by simply attaching text of next page to all the previous ones\n- Step 5 - Creating word frequency dataframe by first splitting text into words and counting the frequency of each word\n- Step 6.1 - Pre-process text i.e. removing stopwords (using nltk library), grouping common words.\n- Step 6.2 - used regex to extract alphabets only, lower all chracters, and sorting as per decreasing order of frequency.\n- Step 7 - Creating Wordcloud using matplotlib and wordcloud libraries\n- Step 8 - Importing required libraries like smtplib, MIME, win32 for sending the mail\n- Step 9 - Create outlook mail object with supporting data like filepath attachment, recepient address, mail body etc.\n- Step 10 - Sending the mail with required wordcloud image file attached and checking if mail is received or not!\n\n## Code\n\n[Notebook on nbviewer](https://nbviewer.jupyter.org/gist/sparsh-ai/f1de48fd4fac199bcc95e1d136fbdfd0)"
        },
        {
          "id": "/2021/10/01/personalized-unexpectedness-in-recommender-systems",
          "metadata": {
            "permalink": "/blog/2021/10/01/personalized-unexpectedness-in-recommender-systems",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-personalized-unexpectedness-in-recommender-systems.mdx",
            "source": "@site/blog/2021-10-01-personalized-unexpectedness-in-recommender-systems.mdx",
            "title": "Personalized Unexpectedness in  Recommender Systems",
            "description": "Classical recommender systems typically provides familier items, which not only bores customer after some time, but create a critical bias problem also, generally known as filter bubble or echo chamber problem.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              }
            ],
            "readingTime": 2.96,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "PDF to Wordcloud via Mail",
              "permalink": "/blog/2021/10/01/pdf-to-wordcloud-via-mail"
            },
            "nextItem": {
              "title": "Predicting Electronics Resale Price",
              "permalink": "/blog/2021/10/01/predicting-electronics-resale-price"
            }
          },
          "content": "Classical recommender systems typically provides familier items, which not only bores customer after some time, but create a critical bias problem also, generally known as *filter bubble* or *echo chamber problem*. \n\nTo address this issue, instead of recommending best matching product all the time, we intentionally recommend a random product. For example, if a user subscribed to Netflix one month ago and watching action movies all the time. If we recommend another action movie, there is a high probability that user will click but keeping in mind the long-term user satisfaction and to address the filter bubble bias, we would recommend a comedy movie. Surprisingly, this strategy works!!\n\nThe most common metric is ***diversity*** factor but diversity only measures dispersion among recommended items. The better alternative is ***unexpectedness*** factor. It measures deviations of recommended items from user expectations and thus captures the concept of user surprise and allows recommender systems to break from the filter bubble. The goal is to provide novel, surprising and satisfying recommendations. \n\nIncluding session-based information into the design of an unexpected recommender system is beneficial. For example, it is more reasonable to recommend the next episode of a TV series to the user who has just finished the first episode, instead of recommending new types of videos to that person. On the other hand, if the user has been binge-watching the same TV series in one night, it is better to recommend something different to him or her.\n\n### Model\n\n![/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled.png](/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled.png)\n\n*Overview of the proposed PURS model. The base model estimates the click-through rate of certain user-item pairs, while the unexpected model captures the unexpectedness of the new recommendation as well as user perception towards unexpectedness.*\n\n### Offline Experiment Results\n\n![/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled-1.png](/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled-1.png)\n\n### Online A/B Test Results\n\nAuthors conducted the online A/B test at Alibaba-Youku, a major video recommendation platform from 2019-11 to 2019-12. During the testing period, they compared the proposed PURS model with the latest production model in the company. They measured the performance using standard business metrics: **VV** (Video View, average video viewed by each user), **TS** (Time Spent, average time that each user spends on the platform), **ID** (Impression Depth, average impression through one session) and **CTR** (Click-Through-Rate, the percentage of user clicking on the recommended video). They also measure the novelty of the recommended videos using the unexpectedness and coverage measures.\n\n![Represents statistical significance at the 0.95 level.](/img/content-blog-raw-blog-personalized-unexpectedness-in-recommender-systems-untitled-2.png)\n\nRepresents statistical significance at the 0.95 level.\n\n### Code Walkthrough\n\n> Note: PURS is *implemented in Tensorflow 1.x*\n\n**Unexpected attention ([model.py](https://github.com/lpworld/PURS/blob/master/model.py))**\n\n```python\ndef unexp_attention(self, querys, keys, keys_id):\n        \"\"\"\n        Same Attention as in the DIN model\n        queries:     [Batchsize, 1, embedding_size]\n        keys:        [Batchsize, max_seq_len, embedding_size]  max_seq_len is the number of keys(e.g. number of clicked creativeid for each sample)\n        keys_id:     [Batchsize, max_seq_len]\n        \"\"\"\n        querys = tf.expand_dims(querys, 1)\n        keys_length = tf.shape(keys)[1] # padded_dim\n        embedding_size = querys.get_shape().as_list()[-1]\n        keys = tf.reshape(keys, shape=[-1, keys_length, embedding_size])\n        querys = tf.reshape(tf.tile(querys, [1, keys_length, 1]), shape=[-1, keys_length, embedding_size])\n\n        net = tf.concat([keys, keys - querys, querys, keys*querys], axis=-1)\n        for units in [32,16]:\n            net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n        att_wgt = tf.layers.dense(net, units=1, activation=tf.sigmoid)        # shape(batch_size, max_seq_len, 1)\n        outputs = tf.reshape(att_wgt, shape=[-1, 1, keys_length], name=\"weight\")  #shape(batch_size, 1, max_seq_len)\n        scores = outputs\n        scores = scores / (embedding_size ** 0.5)       # scale\n        scores = tf.nn.softmax(scores)\n        outputs = tf.matmul(scores, keys)    #(batch_size, 1, embedding_size)\n        outputs = tf.reduce_sum(outputs, 1, name=\"unexp_embedding\")   #(batch_size, embedding_size)\n        return outputs\n```\n\n**Unexpected metric calculation ([train.py](https://github.com/lpworld/PURS/blob/master/train.py))**\n\n```python\ndef unexpectedness(sess, model, test_set):\n    unexp_list = []\n    for _, uij in DataInput(test_set, batch_size):\n        score, label, user, item, unexp = model.test(sess, uij)\n        for index in range(len(score)):\n            unexp_list.append(unexp[index])\n    return np.mean(unexp_list)\n```\n\n### References\n\n1. [https://arxiv.org/pdf/2106.02771v1.pdf](https://arxiv.org/pdf/2106.02771v1.pdf)\n2. [https://github.com/lpworld/PURS](https://github.com/lpworld/PURS)"
        },
        {
          "id": "/2021/10/01/predicting-electronics-resale-price",
          "metadata": {
            "permalink": "/blog/2021/10/01/predicting-electronics-resale-price",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-predicting-electronics-resale-price.mdx",
            "source": "@site/blog/2021-10-01-predicting-electronics-resale-price.mdx",
            "title": "Predicting Electronics Resale Price",
            "description": "/img/content-blog-raw-blog-predicting-electronics-resale-price-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "regression",
                "permalink": "/blog/tags/regression"
              }
            ],
            "readingTime": 1.875,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Personalized Unexpectedness in  Recommender Systems",
              "permalink": "/blog/2021/10/01/personalized-unexpectedness-in-recommender-systems"
            },
            "nextItem": {
              "title": "Real-time news personalization with Flink",
              "permalink": "/blog/2021/10/01/real-time-news-personalization-with-flink"
            }
          },
          "content": "![/img/content-blog-raw-blog-predicting-electronics-resale-price-untitled.png](/img/content-blog-raw-blog-predicting-electronics-resale-price-untitled.png)\n\n# Objective\n\nPredict the resale price based on brand, part id and purchase quantity\n\n# Milestones\n\n- Data analysis and discovery - What is the acceptable variance the model needs to meet in terms of similar part number and quantity?\n- Model research and validation - Does the model meet the variance requirement? (Variance of the model should meet or be below the variance of the sales history)\n- Model deployment - Traffic will increase 10 fold. So, model needs to be containerized or dockerized\n- Training - Model needs to be trainable on new sales data. Methodology to accept or reject the variance of the newly trained model documented.\n\n# Deliverables\n\n1. Data Analysis and Discovery (identify target variance for pricing model in terms of similar part numbers and quantities). Analysis should be done on the 12 following quantity ranges: 1-4, 5-9, 10-24, 25-49, 50-99, 100-249, 250-499, 500-999, 1000-2499, 2500-4999, 5000-9999, 10000+.\n\n2. ModelA Training (Resale Value Estimation [$] (Brand+PartNo.+Quantity)\n\n3. ModelA Validation (variance analysis and comparison with sales history variance in terms of similar part numbers and quantities)\n\n4. ModelA Containerization\n\n5. ModelA re-training based on new sales data\n\n6. ScriptA to calculate variance for new sales data (feedback for training results)\n\n7. Documentation for re-training\n\n8. ModelA deployment and API\n\n# Modeling Approach\n\n### Framework\n\n- Fully connected regression neural network\n- NLP feature extraction from part id\n- Batch generator to feed large data in batches\n- Hyperparameter tuning to find the best model fit\n\n### List of Variables\n\n- 2 years of sales history\n- PRC\n- PARTNO\n- ORDER_NUMBER\n- ORIG_ORDER_QTY\n- UNIT_COST\n- UNIT_REASLE\n- UOM (UNIT OF MEASUREMENT)\n\n# Bucket of Ideas\n\n1. Increase n-gram range; e.g. in part_id ABC-123-23, these are 4-grams: ABC-, BC-1, C-12, -123, 123-, 23-2, 3-23; Idea is to see if increasing this range further will increase the model's performance\n2. Employ Char-level LSTM to capture sequence information; e.g. in same part_id ABC-123-23, currently we are not maintaining sequence of grams, we don't know if 3-23 is coming at first or last; here, the idea is to see if lstm model can be employed to capture this sequence information to improve model's performance\n3. New Loss function - including cost based loss"
        },
        {
          "id": "/2021/10/01/real-time-news-personalization-with-flink",
          "metadata": {
            "permalink": "/blog/2021/10/01/real-time-news-personalization-with-flink",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-real-time-news-personalization-with-flink.mdx",
            "source": "@site/blog/2021-10-01-real-time-news-personalization-with-flink.mdx",
            "title": "Real-time news personalization with Flink",
            "description": "Overview",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              },
              {
                "label": "realtime",
                "permalink": "/blog/tags/realtime"
              }
            ],
            "readingTime": 9.82,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Predicting Electronics Resale Price",
              "permalink": "/blog/2021/10/01/predicting-electronics-resale-price"
            },
            "nextItem": {
              "title": "Semantic Similarity",
              "permalink": "/blog/2021/10/01/semantic-similarity"
            }
          },
          "content": "## Overview\n\nNews recommendation system has a high degree of real-time because there will be a large number of news and hot spots at any time. Incremental updating, online learning, local updating and even reinforcement learning can make the recommender system quickly respond to the user‘s new behavior, and the premise of these updating strategies is that the sample itself has enough real-time information. In news recommendation system, the typical training sample is the user’s click behavior data.\n\n### Why is the real-time nature of the recommendation system important?\n\nIntuitively, when users use personalized news applications, users expect to find articles that match their interests faster; when using short video services, they expect to \"flash\" content that they are interested in faster; when doing online shopping, I also hope to find the products that I like, faster. All recommendations highlight the word \"fast\", which is an intuitive manifestation of the \"real-time\" role of the recommendation system.\n\nFrom a professional point of view, the real-time performance of the recommendation system is also crucial, which is mainly reflected in the following two aspects:\n\n1. **The faster the update speed of the recommendation system is, the more it can reflect the user's recent user habits, and the more time-sensitive it can make recommendations to the user.**\n2. **The faster the recommendation system is updated, the easier it is for the model to find the latest popular data patterns, and the more it can make the model react to find the latest fashion trends.**\n\n### The real-time nature of the \"feature\" of the recommendation system\n\nSuppose a user has watched a 10-minute \"badminton teaching\" video in its entirety. Then there is no doubt that the user is interested in the subject of \"badminton\". The system hopes to continue to recommend \"badminton\" related videos when the user turns the page next time. However, due to the lack of real-time features of the system, the user’s viewing history cannot be fed back to the recommendation system in real time. As a result, the recommendation system learned that the user had watched the video \"Badminton Teaching\". It was already half an hour later. Has left the app. This is an example of recommendation failure caused by poor real-time performance of the recommendation system.\n\nIt is true that the next time the user opens the application, the recommendation system can use the last user behavior history to recommend \"badminton\" related videos, but the recommendation system undoubtedly loses what is most likely to increase user viscosity and increase user retention. opportunity.\n\n### The real-time nature of the \"model\" of the recommender system\n\nNo matter how strong the real-time feature is, the scope of influence is limited to the current user. Compared with the real-time nature of \"features\", the real-time nature of the recommendation system model is often considered from a more global perspective . The real-time nature of the feature attempts to describe a person with more accurate features, so that the recommendation system can give a recommendation result that is more in line with the person. The real-time nature of the model hopes to capture new data patterns at the global level faster and discover new trends and relevance.\n\nTake, for example, a large number of promotional activities on Double Eleven on an e-commerce website. The real-time nature of the feature will quickly discover the products that the user may be interested in based on the user's recent behavior, but will never find the latest preferences of similar users, the latest correlation information between the products, and the trend information of new activities.\n\nTo discover such global data changes, the model needs to be updated faster. The most important factor affecting the real-time performance of the model is the training method of the model.\n\n1. **Full update -** The most common way of model training is full update. The model will use all training samples in a certain period of time for retraining, and then replace the \"outdated\" model with the new trained model. However, the full update requires a large amount of training samples, so the training time required is longer; and the full update is often performed on offline big data platforms, such as spark+tensorflow, so the data delay is also longer, which leads to the full update It is the worst \"real-time\" model update method. In fact, for a model that has been trained, it is enough to learn only the newly added incremental samples, which is called incremental update.\n2. **Incremental update (Incremental Learning)** - Incremental update only feeds newly added samples to the model for incremental learning . Technically, deep learning models often use stochastic gradient descent (SGD) and its variants for learning. The model's learning of incremental samples is equivalent to continuing to input incremental samples for gradient descent on the basis of the original samples. Therefore, based on the deep learning model, it is not difficult to change from full update to incremental update. But everything in engineering is a tradeoff, there is never a perfect solution, and incremental updates are no exception. Since only incremental samples are used for learning, the model also converges to the best point of the new sample after multiple epochs, and it is difficult to converge to the global best point of all the original samples + incremental samples. Therefore, in the actual recommendation system, the incremental update and the global update are often combined . After several rounds of incremental update, the global update is performed in a time window with a small business volume, and the model is corrected after the incremental update process. Accumulated errors in. Make trade-offs and trade-offs between \"real-time performance\" and \"global optimization\".\n3. **Online learning** - \"Online learning\" is a further improvement of \"incremental update\", \"incremental update\" is to perform incremental update when a batch of new samples is obtained, and online learning is to update the model in real time every time a new sample is obtained. Online learning can also be implemented technically through SGD. But if you use the general SGD method, online learning will cause a very serious problem, that is, the sparsity of the model is very poor, opening too many \"fragmented\" unimportant features. We pay attention to the \"sparseness\" of the model in a sense that is also an engineering consideration. For example, in a model with an input vector of several million dimensions, if the sparsity of the model is good, the effect of the model can be maintained without affecting the model. , Only make the corresponding weight of the input vector of a very small part of the dimension non-zero, that is to say, when the model is online, the volume of the model is very small, which is undoubtedly beneficial to the entire model serving process. Both the memory space required to store the model and the speed of online inference will benefit from the sparsity of the model. If the SGD method is used to update the model, it is easier to generate a large number of features with small weights than the batch method, which increases the difficulty of model deployment and update. So in order to take into account the training effect and model sparsity in the online learning process, there are a lot of related researches. The most famous ones include Microsoft's RDA, Google's FOBOS and the most famous FTRL, etc.\n4. **Partial model update** - Another improvement direction to improve the real-time performance of the model is to perform a partial update of the model. The general idea is to reduce the update frequency of the part with low training efficiency and increase the update frequency of the part with high training efficiency . This approach is representative of the GBDT+LR model of Facebook.\n\n![/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled.png](/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled.png)\n\n## Data pipeline of a typical news recommendation system\n\nWhen a user is exposed with a list of news articles, a page view events are sent to the backend server and when that user clicks on the news of interest, the action events are also sent to the backend server. After receiving these 2 event streams (page view and clicks), the backend server will send these user behaviour events to the message queue. And message queue finally stores these messages into the distributed file system, such as HDFS.\n\nFor model training, we need a training sample. The most common sampling technique is negative sampling. In this, we generate 'n' negative samples for each positive event that we receive. Users will only generate behavior for some exposed news samples, which are positive samples, and the remaining exposure samples without behavior are negative samples. After generating positive and negative samples, the model can be trained.\n\nThe recommendation system with low real-time requirements can use batch processing technology (APACHE spark is a typical tool) to generate samples, as shown in the left figure. Set a timing task, and read the user behavior log and exposure log in the time window from HDFS every other period of time, such as one hour, to perform join operation, generate training samples, and then write the training samples back to HDFS, Then start the training update of the model.\n\n![/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-1.png](/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-1.png)\n\n### Problems\n\nOne obvious problem with batch processing is **latency**. The typical cycle of running batch tasks regularly is one hour, which means that there is a delay of at least one hour from sample generation to model training. Sometimes, if the batch platform is overloaded and the tasks need to be queued, the delay will be greater.\n\nAnother problem is the **boundary** problem. If page view (PV) data is generated at the end of the log time window selected by the batch task, the corresponding action data may fall into the next time window of the batch task, resulting in join failure and false negative samples.\n\nA related problem to this is the time synchronization problem. When a news item is exposed to the user, the user may click immediately after the PV data stream is generated, or the user may act after a few minutes, more than ten minutes, or even several hours. This means that after the PV data stream arrives, it needs to wait for a period of time to join with the action data stream. If the waiting time is too long, some samples (positive samples) that should have user behavior will be wrongly marked as negative samples because the user behavior has no time to return. Too long waiting time will damage and increase the system delay. Offline analysis of the delay distribution between the actual action data stream and PV data stream is a very typical exponential distribution.\n\n![/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-2.png](/img/content-blog-raw-blog-real-time-news-personalization-with-flink-untitled-2.png)\n\n## Apache Flink to the rescue\n\n### How Apache Flink solves the latency problem?\n\nIn order to enhance the real-time performance, we use Apache Flink framework to rewrite the sample generation logic with stream processing technology. As shown in the right figure above, after the user exposure and behavior logs generated by online services are written into the message queue, instead of waiting for them to drop to HDFS, we directly consume these message flows with Flink. At the same time, Flink reads the necessary feature information from the redis cache and generates the sample message stream directly. The sample message flow is written back to the Kafka queue, and downstream tensorflow can directly consume the message flow for model training.\n\n### How Apache Flink solved the boundary and synchronization problem?\n\nAs per the exponential distribution (analyzed on a private dataset of a news recommender app), most of the user behavior has reflow within a few minutes. And if few minutes is an acceptable delay, a simple solution is to set a time window with a compromise size. Flink provides window join to implement this logic.\n\n## References\n\n1. [https://developpaper.com/flink-streaming-processing-and-real-time-sample-generation-in-recommender-system/](https://developpaper.com/flink-streaming-processing-and-real-time-sample-generation-in-recommender-system/)\n2. [https://zhuanlan.zhihu.com/p/74813776](https://zhuanlan.zhihu.com/p/74813776)\n3. [https://zhuanlan.zhihu.com/p/75597761](https://zhuanlan.zhihu.com/p/75597761)"
        },
        {
          "id": "/2021/10/01/semantic-similarity",
          "metadata": {
            "permalink": "/blog/2021/10/01/semantic-similarity",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-semantic-similarity.mdx",
            "source": "@site/blog/2021-10-01-semantic-similarity.mdx",
            "title": "Semantic Similarity",
            "description": "/img/content-blog-raw-blog-semantic-similarity-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              }
            ],
            "readingTime": 1.67,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Real-time news personalization with Flink",
              "permalink": "/blog/2021/10/01/real-time-news-personalization-with-flink"
            },
            "nextItem": {
              "title": "Short-video Background Music Recommender",
              "permalink": "/blog/2021/10/01/short-video-background-music-recommender"
            }
          },
          "content": "![/img/content-blog-raw-blog-semantic-similarity-untitled.png](/img/content-blog-raw-blog-semantic-similarity-untitled.png)\n\n# Introduction\n\nDeliverable - Two paragraph-level distance outputs for L and Q, each has 35 columns. \n\nFor each paragraph, we need to calculate the L1 distance of consecutive sentences in this paragraph, and then generate the mean and standard deviation of all these distances for this paragraph. For example, say the paragraph 1 starts from sentence1 and ends with sentence 5. First, calculate the L1 distances for L1(1,2), L1(2,3), L1(3,4) and L1(4,5) and then calculate the mean and standard deviation of the 4 distances. In the end we got two measures for this paragraph: L1_m and L1_std. Similarly, we need to calculate the mean and standard deviation using L2 distance, plus a simple mean and deviation of the distances. We use 6 different embeddings: all dimensions of BERT embeddings, 100,200 and 300 dimensions of PCA Bert embeddings (PCA is a dimension reduction technique \n\nIn the end, we will have 35 columns for each paragraph : Paragraph ID +#sentences in the paragraph +(cosine_m, cosine_std,cossimillarity_m, cosimmilarity_std, L1_m, L1_std, L2_m, L2_std ) – by- ( all, 100, 200, 300)= 3+8*4. \n\nNote: for paragraph that only has 1 sentence, the std measures are empty.\n\n# Modeling Approach\n\n### Process Flow for Use Case 1\n\n1. Splitting paragraphs into sentences using 1) NLTK Sentence Tokenizer, 2) Spacy Sentence Tokenizer and, on two additional symbols `:` and `...`\n2. Text Preprocessing: Lowercasing, Removing Non-alphanumeric characters, Removing Null records, Removing sentence records (rows) having less than 3 words.\n3. TF-IDF vectorization\n4. LSA over document-term matrix\n5. Cosine distance calculation of adjacent sentences (rows)\n\n### Process Flow for Use Case 2\n\n- Split paragraphs into sentences\n- Text cleaning\n- BERT Sentence Encoding\n- BERT PCA 100\n- BERT PCA 200\n- BERT PCA 300\n- Calculate distance between consecutive sentences in the paragraph\n- Distances: L1, L2 and Cosine and Cosine similarity\n- Statistics: Mean, SD\n\n# Experimental Setup\n\n1. #IncrementalPCA\n2. GPU to speed up\n3. Data chunking\n4. Calculate BERT for a chunk and store in disk"
        },
        {
          "id": "/2021/10/01/short-video-background-music-recommender",
          "metadata": {
            "permalink": "/blog/2021/10/01/short-video-background-music-recommender",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-short-video-background-music-recommender.mdx",
            "source": "@site/blog/2021-10-01-short-video-background-music-recommender.mdx",
            "title": "Short-video Background Music Recommender",
            "description": "Matching micro-videos with suitable background music can help uploaders better convey their contents and emotions, and increase the click-through rate of their uploaded videos. However, manually selecting the background music becomes a painstaking task due to the voluminous and ever-growing pool of candidate music. Therefore, automatically recommending background music to videos becomes an important task.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "recsys",
                "permalink": "/blog/tags/recsys"
              }
            ],
            "readingTime": 2.17,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Semantic Similarity",
              "permalink": "/blog/2021/10/01/semantic-similarity"
            },
            "nextItem": {
              "title": "The progression of analytics in enterprises",
              "permalink": "/blog/2021/10/01/the-progression-of-analytics-in-enterprises"
            }
          },
          "content": "Matching micro-videos with suitable background music can help uploaders better convey their contents and emotions, and increase the click-through rate of their uploaded videos. However, manually selecting the background music becomes a painstaking task due to the voluminous and ever-growing pool of candidate music. Therefore, automatically recommending background music to videos becomes an important task.\n\nIn [this](https://arxiv.org/pdf/2107.07268.pdf) paper, Zhu et. al. shared their approach to solve this task. They first collected ~3,000 background music from popular TikTok videos and also ~150,000 video clips that used some kind of background music. They named this dataset `TT-150K`.\n\n![An exemplar subset of videos and their matched background music in the established TT-150k dataset](/img/content-blog-raw-blog-short-video-background-music-recommender-untitled.png)\n\nAn exemplar subset of videos and their matched background music in the established TT-150k dataset\n\nAfter building the dataset, they worked on modeling and proposed the following architecture:\n\n![Proposed CMVAE (Cross-modal Variational Auto-encoder) framework](/img/content-blog-raw-blog-short-video-background-music-recommender-untitled-1.png)\n\nProposed CMVAE (Cross-modal Variational Auto-encoder) framework\n\nThe goal is to represent videos (`users` in recsys terminology) and music (`items`) in a shared latent space. To achieve this, CMVAE use pre-trained models to extract features from unstructured data - `vggish` model for audio2vec, `resnet` for video2vec and `bert-multilingual` for text2vec.  Text and video vectors are then fused using product-of-expert approach. \n\nIt uses the reconstruction power of variational autoencoders to 1) reconstruct video from music latent vector and, 2) reconstruct music from video latent vector. In layman terms, we are training a neural network that will try to guess the video activity just by listening background music, and also try to guess the background music just by seeing the video activities. \n\nThe joint training objective is $\\mathcal{L}_{(z_m,z_v)} = \\beta \\cdot\\mathcal{L}_{cross\\_recon} - \\mathcal{L}_{KL} + \\gamma \\cdot \\mathcal{L}_{matching}$, where $\\beta$ and $\\gamma$ control the weight of the cross reconstruction loss and the matching loss, respectively.\n\nAfter training the model, they compared the model's performance with existing baselines and the results are as follows:\n\n![/img/content-blog-raw-blog-short-video-background-music-recommender-untitled-2.png](/img/content-blog-raw-blog-short-video-background-music-recommender-untitled-2.png)\n\n**Conclusion**: I don't make short videos myself but can easily imagine the difficulty in finding the right background music. If I have to do this task manually, I will try out 5-6 videos and select one that I like. But here, I will be assuming that my audience would also like this music. Moreover, feedback is not actionable because it will create kind of an implicit sub-conscious effect (because when I see a video, I mostly judge it at overall level and rarely notice that background music is the problem). So, this kind of recommender system will definitely help me in selecting a better background music. Excited to see this feature soon in TikTok, Youtube Shorts and other similar services."
        },
        {
          "id": "/2021/10/01/the-progression-of-analytics-in-enterprises",
          "metadata": {
            "permalink": "/blog/2021/10/01/the-progression-of-analytics-in-enterprises",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-the-progression-of-analytics-in-enterprises.mdx",
            "source": "@site/blog/2021-10-01-the-progression-of-analytics-in-enterprises.mdx",
            "title": "The progression of analytics in enterprises",
            "description": "An organization’s analytics strategy is how its people, processes, tools, and data work together to collect, store, and analyze data. Processes refers to how analytics are produced, consumed, and maintained. A more modern approach to analytics is intended to support greater business agility at scale. This requires faster data preparation from a wider variety of sources, rapid prototyping and analytics model building, and cross-team collaboration processes. Tools, or technologies, are the raw programs and applications used to prepare for and perform analyses, such as the provisioning, flow, and automation of tasks and resources. As an analytics strategy matures, the technologies used to implement it tend to move from monolithic structures to composable microservices. The last element is data. A modern analytics architecture supports a growing volume and variety of data sources, which may include data from data warehouses and data lakes—streaming data, relational databases, graph databases, unstructured or semi-structured data, text data, and images.",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "insight",
                "permalink": "/blog/tags/insight"
              }
            ],
            "readingTime": 12.09,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Short-video Background Music Recommender",
              "permalink": "/blog/2021/10/01/short-video-background-music-recommender"
            },
            "nextItem": {
              "title": "Tools for building recommender systems",
              "permalink": "/blog/2021/10/01/tools-for-building-recommender-systems"
            }
          },
          "content": "An organization’s analytics strategy is how its *people, processes, tools, and data* work together to collect, store, and analyze data. *Processes* refers to *how* analytics are produced, consumed, and maintained. A more modern approach to analytics is intended to support greater business agility at scale. This requires faster data preparation from a wider variety of sources, rapid prototyping and analytics model building, and cross-team collaboration processes. *Tools*, or technologies, are the raw programs and applications used to prepare for and perform analyses, such as the provisioning, flow, and automation of tasks and resources. As an analytics strategy matures, the technologies used to implement it tend to move from monolithic structures to composable microservices. The last element is *data.* A modern analytics architecture supports a growing volume and variety of data sources, which may include data from data warehouses and data lakes—streaming data, relational databases, graph databases, unstructured or semi-structured data, text data, and images.\n\n### Analytics Past, Present, and Future\n\n|  | Past | Present | Future |\n| --- | --- | --- | --- |\n|  | This refers to an era of analytics starting in the 1990s and running through the mid-2000s. During this phase, organizations were able to consolidate mostly transactional data into a unified system, often a data warehouse, which limited end users’ ability to interact directly with the data due to technical and governance requirements. | Starting in the late 2000s, organizations were forced to rethink how they used analytics, in no small part due to the explosion of data during this time. This was the era of “Big Data” and its infamous “ V’s”: volume, velocity, and variety.4 As organizations shifted their approach during this period, they unlocked diagnostic analytics, or the capability to answer “Why did it happen?” | The Future of Analytics Is Converged. Converged analytics unifies advances in AI, streaming data, and related technologies into a seamless analytics experience for all users. This arrangement unlocks prescriptive analytics across an organization, allowing anyone to make data-driven decisions that answer important questions. |\n| People | IT professionals were needed to kick off any data-based work by extracting data from a centralized, difficult-to-use source. This process could take multiple days, and the number of query requests could easy exceed the IT team’s ability to fulfill those requests—and the opportune time for new insights.If some change was needed to data collection or storage methods, it could easily take IT months to perform. The data analysis and modeling work could take nearly as long. Rank-and-file domain experts did have some access to data, through so-called self-service business intelligence (BI) features. However, due to the same speed and accessibility issues that technical professionals faced, it was often difficult for domain experts like line of business leaders to truly lead with data for decision making. | It’s no coincidence that around the same time as Big Data emerged, so did the role of the data scientist. Compared with earlier roles like researcher or statistician, the data scientist blends quantitative and domain expertise with a greater degree of computational thinking. These skills became necessary both to handle the greater variety and volume of data sources and to update and deploy data and analytics models without the assistance of IT professionals.Whereas IT in the past sought to meticulously catalog and structure data to enter into a data warehouse, they no longer needed to always clean the data before collecting it; these analytics teams could focus on ease of use and speed to governed access.With these new workflows and organization structures in place, domain leaders are better able to lead with data: both via self-service BI tools and from frequent collaboration with data analysts, data scientists, and other data specialists. | Statisticians and IT served information to business users at the inception of a wider analytics adoption; further into maturity, data analysts and scientists built systems where business users could self-serve insights. In a converged architecture, not only is the business user at the center, but their decision making is augmented by automation. Given this arrangement, there is more collaboration, more automation, and greater scale for data-driven insights as a result of the convergence of teams and workstreams. Teams can work cross-functionally and in parallel across different domains iterating the system to their needs with the raw time and human resources needed to create and maintain analytics products such as dashboards and models. |\n| Processes | IT professionals spent long periods of time gathering requirements for analytics projects before they could build or deploy solutions. The team meticulously catalogued sources of data used across the organization, from financial or point-of-sale systems to frequently used external datasets. As part of the warehousing process, it was decided which of these data sources to store and how to store them.Once deployed, data passed into the warehouse through an extract-transform-load process (ETL), where the data was copied from these various sources, cleaned and reshaped into the defined structure of the data warehouse, then inserted into production. In other words, data went through rigorous cleaning and preprocessing before use.To reach this data, users needed to write time-consuming ad hoc queries. Alternatively, particular data segments or summaries that were frequently requested by business users could be delivered via scheduled automation to reports, dashboards, and scorecards. | As opposed to earlier analytics strategies, IT professionals now seek to collect data as is from any possible source of value. This data can be in a variety of formats, so few predefined rules or relationships are established for ingestion. Depending on the data size, data is processed in batch over discrete time periods, or in streams and events near real time. Because data cleaning is the last step, this process is sometimes referred to as extract-load-transform (ELT), as opposed to the ETL of earlier architectures. For data scientists and other technical professionals, faster access to more and more dynamic data better enables the rapid development of training sets of data for machine learning models. The ELT process allows for the construction of machine learning models, where computers are able to improve performance as more data is passed to them.As more data is collected and put into production, the importance of a data governance process typically grows, describing who has authority over data and how that data should be used. Similar approaches are necessary to audit how models are put into production and how they work. | While perhaps using different means, the ends of older analytics approaches were the same: insights, whether historic or in support of future decisions, using governed data and processes. In the methods for doing so, however, infrastructure tended to bloat, either from fragile data storage jobs or increasingly complex data pipelines.Given the volume, velocity, and variety of data needed for prescriptive analytics, such monolithic, centralized approaches are less than optimal. Using the tools discussed in the next section, a converged architecture offers a more nimble approach for providing the right insights at the right time to users of all technical levels.Such democratization relies on quick deployment and adjustment of data products; optimizing production, for example, requires bringing more machine learning models to production faster and at scale. The practice of ModelOps is used to institute and govern such rapid production. These processes have become a necessity in rapidly changing business conditions; for example, as the COVID-19 pandemic made structural changes to the economy, many models lost their predictive edge in the face of fundamentally different data. |\n| Tools | Data warehouses implemented some new technologies relative to the traditional relational database model. Importantly, the data warehouse separated data into fact tables, where measurements were stored, and dimension tables, which contained descriptive attributes. Business users interacted with the data via reporting software to view static data summaries. These tended to rely on overnight batch jobs to update.In a more sophisticated architecture, analysts could take advantage of online analytical processing (OLAP) cubes. Usually relying on a star schema, OLAP let users query the data across dimensions during interactive sessions. For example, they could “slice and dice” or “roll up and drill down” on the data.By this point, end users had some autonomy in how they looked at and acted upon the data. Automated processes to inform business activities through data were also put into place, such as alerts when inventory or sales dropped below some threshold. Basic what-if analyses also helped business users evaluate decisions and plan for the future.That said, given the limited sources of data from the data warehouse, there were limited ways to customize and work with the data. While reporting and basic analytics were automated, end users operated largely without the assistance of models developed by statisticians. Although business intelligence and operations research seek to create value from data, too often these complementary tools were siloed. | In 2011, James Dixon, then chief technology officer of Pentaho, coined the term data lake as the architecture needed to support the next level of analytics maturity. Dixon argued that because of the inherently rigid structures of data warehouses, getting value from the increasing volume and variety of data associated with Big Data was difficult. A data lake, “a repository of data stored in its natural/raw format,” was a better approach. In particular, this arrangement wasn’t suited to operate or capitalize on the expanding volume and variety of Big Data.The data lake is often powered by cloud computing for the benefits of reliability, redundancy, and scalability. Dominant cloud service providers include Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP). Open source technologies like Hadoop and Spark are used to process and store massive datasets using parallel computing and distributed storage. Because this data is often unstructured, it may be stored in graph, document, or other non-relational databases.With the increasing volume and velocity of data, and the use of data lakes along with data warehouses to enable data-driven decisions, businesses needed better ways to scale and share business intelligence. One such path was through interactive, immersive exploration and visualization of the data, as pioneered with Spotfire. Other paths were through visual reports and dashboards, as used by not just Spotfire, but by Jaspersoft, Power BI, WebFOCUS, and many others. As BI tools matured, self-service capabilities and automation for end users also matured. | If maintaining legacy analytics is like raising a thoroughbred, then developing converged analytics is like cultivating a school of goldfish. That is, the backend provisioning is no longer served by monolithic systems but rather by composable groups of microservices. This arrangement supports elastic and scalable analytics; composability makes it easier to adapt to changes driven in part by a growing volume and variety of data sources. In previous analytics approaches, the distinction between backward-facing BI and prediction-focused data science was clear. Under convergence, analytics at the edge is possible—automating analytic computations so they can be performed on non-centralized data generated by sensors, switches, and similar. With converged analytics, individuals no longer need to wait for data science teams to provide ad hoc deeper insights. They have all the data-driven insights at their fingertips, assisted by AI to quickly explore and make decisions. This isn’t just the case for back-office analysts: frontline workers can, for example, adjust how they interact with a customer given data retrieved about that customer at the time of that interaction. |\n| Data | During this period, data tended to be transactional, or related to sales and purchases. Take a point-of-sales (POS) system, for example. Each time a sale is made, information about what was sold, possibly to whom, is recorded in the POS system. Those records can be compiled into tables and ultimately processed into a data warehouse.Under this process, data is gathered from prespecified sources at prespecified times, such as a nightly POS extract. Not all data made its way to the data warehouse, especially in the earlier days of analytics—either because it was judged unimportant, or because it was not prioritized. | Contemporary analytics expands the variety of data available and used: both structured tables and unstructured sources like natural language and images are available. On account of stream processing, refreshes of this data are available in minutes or even less. In particular, the data lake can accommodate real-time events such as IoT sensor readings, GPS signals, and online transactions as they happen. | A primary feature of converged analytics is the blending of historical and real-time data. According to a study by Seagate and International Data Corporation (IDC), 30% of all data will be real time by 2025. In particular, IoT sensor readings, GPS signals, and online transactions as they happen are available for immediate analysis and modeling. |\n| Agility | The relatively rigid nature of the data warehouse made changes to the collection and dissemination of data difficult. Subsequently, business agility was limited. Business users could get historic data about the business through static reports (descriptive analytics). Through OLAP cubes, they could possibly even dig into the data to parse out cause and effect (diagnostic analytics). But without more immediate access to broader data, it was difficult to advance to predictive analytics, or the ability to ask: “What is going to happen?” | This next phase in the evolution of analytics gets data-driven insights into the hands of end users quickly, with technology allowing them to interact with it on a deeper level. Data scientists are able to build machine learning systems that improve with more data. Using drag-and-drop tools, business users can process and analyze data without technical assistance. With cloud, automation, and streaming technologies, organizations have been better able to adapt to and plan for changing circumstances. That said, machine learning works only so long in production before the algorithm struggles to account for changes to the business and needs intervention. While data scientists undertake these predictive challenges, BI professionals and domain experts tend to operate solely in analyzing current or past data. The next generation of analytics architecture will further reflect organizational needs for greater collaboration among data scientists, BI and analytics teams, and business users and consumers of analytics insights. | Earlier analytics tended to isolate skills and processes: technical versus highly technical roles, data collection versus deployment versus modeling, and so forth. Converged analytics promotes close collaboration between teams to rapidly model, deploy, and act on data. As data operations become decentralized, teams and individuals can rapidly mine and act on the analytics.In particular, the marriage of real-time data with machine learning and AI-infused BI allows any user to magnify their own domain knowledge with data-driven insights. These features square precisely with the definition of business agility as “innovation via collaboration to be able to anticipate challenges and opportunities before they occur.” With the support of converged analytics, any professional can detect and act on both challenges and opportunities at the moment of impact, rather than months later. |\n\n---\n\n©️2021, RecoHut."
        },
        {
          "id": "/2021/10/01/tools-for-building-recommender-systems",
          "metadata": {
            "permalink": "/blog/2021/10/01/tools-for-building-recommender-systems",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-tools-for-building-recommender-systems.mdx",
            "source": "@site/blog/2021-10-01-tools-for-building-recommender-systems.mdx",
            "title": "Tools for building recommender systems",
            "description": "/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "recsys",
                "permalink": "/blog/tags/recsys"
              },
              {
                "label": "tool",
                "permalink": "/blog/tags/tool"
              }
            ],
            "readingTime": 11.025,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "The progression of analytics in enterprises",
              "permalink": "/blog/2021/10/01/the-progression-of-analytics-in-enterprises"
            },
            "nextItem": {
              "title": "Vehicle Suggestions",
              "permalink": "/blog/2021/10/01/vehicle-suggestions"
            }
          },
          "content": "![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled.png)\n\n## Recombee - Recommendation as a service API\n\nRecombee is a Recommender as a Service with easy integration and Admin UI. It can be used in many domains, for example in media (VoD, news …), e-commerce, job boards, aggregators or classifieds. Basically, it can be used in any domain with a catalog of **items** that can be interacted by **users**. The users can interact with the items in many ways: for example view them, rate them, bookmark them, purchase them, etc. Both items and users can have various properties (metadata) that are also used by the recommendation models.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-1.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-1.png)\n\n[Here](https://docs.recombee.com/tutorial.html) is the official tutorial series to get started. \n\n## Amazon Personalize - Self-service Platform to build and serve recommenders\n\nAmazon Personalize is a fully managed machine learning service that goes beyond rigid static rule based recommendation systems and trains, tunes, and deploys custom ML models to deliver highly customized recommendations to customers across industries such as retail and media and entertainment.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-2.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-2.png)\n\nIt covers 6 use-cases:\n\n![Popular Use-cases](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-3.png)\n\nPopular Use-cases\n\nFollowing are the hands-on tutorials:\n\n1. [Data Science on AWS Workshop - Personalize Recommendations**p**](https://github.com/data-science-on-aws/workshop/tree/937f6e4fed53fcc6c22bfac42c2c18a687317995/oreilly_book/02_usecases/personalize_recommendations)\n2. [https://aws.amazon.com/blogs/machine-learning/creating-a-recommendation-engine-using-amazon-personalize/](https://aws.amazon.com/blogs/machine-learning/creating-a-recommendation-engine-using-amazon-personalize/)\n3. [https://aws.amazon.com/blogs/machine-learning/omnichannel-personalization-with-amazon-personalize/](https://aws.amazon.com/blogs/machine-learning/omnichannel-personalization-with-amazon-personalize/)\n4. [https://aws.amazon.com/blogs/machine-learning/using-a-b-testing-to-measure-the-efficacy-of-recommendations-generated-by-amazon-personalize/](https://aws.amazon.com/blogs/machine-learning/using-a-b-testing-to-measure-the-efficacy-of-recommendations-generated-by-amazon-personalize/)\n\nAlso checkout these resources:\n\n1. [https://www.youtube.com/playlist?list=PLN7ADELDRRhiQB9QkFiZolioeJZb3wqPE](https://www.youtube.com/playlist?list=PLN7ADELDRRhiQB9QkFiZolioeJZb3wqPE)\n\n## Azure Personalizer - An API based service with Reinforcement learning capability\n\nAzure Personalizer is a cloud-based API service that helps developers create rich, personalized experiences for each user of your app. It learns from customer's real-time behavior, and uses reinforcement learning to select the best item (action) based on collective behavior and reward scores across all users. Actions are the content items, such as news articles, specific movies, or products. It takes a list of items (e.g. list of drop-down choices) and their context (e.g. Report Name, User Name, Time Zone) as input and returns the ranked list of items for the given context. While doing that, it also allows feedback submission regarding the relevance and efficiency of the ranking results returned by the service. The feedback (reward score) can be automatically calculated and submitted to the service based on the given personalization use case.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-4.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-4.png)\n\nYou can use the Personalizer service to determine what product to suggest to shoppers or to figure out the optimal position for an advertisement. After the content is shown to the user, your application monitors the user's reaction and reports a reward score back to the Personalizer service. This ensures continuous improvement of the machine learning model, and Personalizer's ability to select the best content item based on the contextual information it receives. \n\nFollowing are some of the interesting use cases of Azure Personalizer:\n\n1. Blog Recommender [[Video tutorial](https://youtu.be/fsn7hTOKXsY?list=PLN7ADELDRRhhHRu1tS3gmdeUfeQkG82k_&t=1145), [GitHub](https://github.com/georgiakalyva/azure-personalizer-service)]\n2. Food Personalizer [[Video tutorial](https://youtu.be/A-8OfoWySHQ?list=PLN7ADELDRRhhHRu1tS3gmdeUfeQkG82k_&t=1758), [Slideshare](https://www.slideshare.net/SetuChokshi/introduction-to-reinforcement-learning-with-azure-personalizer-233272693), [Code Blog](https://pipinstall.me/introduction_to_azure_personalizer/)]\n3. Coffee Personalizer [[GitHub](https://github.com/Azure-Samples/cognitive-services-personalizer-samples/tree/master/samples/azurenotebook), [Video tutorial](https://youtu.be/vkbIhX7xhcE?list=PLN7ADELDRRhhHRu1tS3gmdeUfeQkG82k_)]\n4. News Recommendation\n5. Movie Recommendation\n6. Product Recommendation\n7. **Intent clarification & disambiguation**: help your users have a better experience when their intent is not clear by providing an option that is personalized.\n8. **Default suggestions** for menus & options: have the bot suggest the most likely item in a personalized way as a first step, instead of presenting an impersonal menu or list of alternatives.\n9. **Bot traits & tone**: for bots that can vary tone, verbosity, and writing style, consider varying these traits.\n10. **Notification & alert content**: decide what text to use for alerts in order to engage users more.\n11. **Notification & alert timing**: have personalized learning of when to send notifications to users to engage them more.\n12. Dropdown Options - Different users of an application with manager privileges would see a list of reports that they can run. Before Personalizer was implemented, the list of dozens of reports was displayed in alphabetical order, requiring most of the managers to scroll through the lengthy list to find the report they needed. This created a poor user experience for daily users of the reporting system, making for a good use case for Personalizer. The tooling learned from the user behavior and began to rank frequently run reports on the top of the dropdown list. Frequently run reports would be different for different users, and would change over time for each manager as they get assigned to different projects. This is exactly the situation where Personalizer’s reward score-based learning models come into play.\n13. Projects in Timesheet - Every employee in the company logs a daily timesheet listing all of the projects the user is assigned to. It also lists other projects, such as overhead. Depending upon the employee project allocations, his or her timesheet table could have few to a couple of dozen active projects listed. Even though the employee is assigned to several projects, particularly at lead and manager levels, they don’t log time in more than 2 to 3 projects for a few weeks to months.\n    1. Reward Score Calculation\n\n## Google Recommendation - Recommender Service from Google\n\n![https://cloudx-bricks-prod-bucket.storage.googleapis.com/6a0d4afb1778e55d54cb7d66382a4b25f8748a50a93f3c3403d2a835aa166f3d.svg](https://cloudx-bricks-prod-bucket.storage.googleapis.com/6a0d4afb1778e55d54cb7d66382a4b25f8748a50a93f3c3403d2a835aa166f3d.svg)\n\n## [Abacus.ai](http://abacus.ai) - Self-service Platform at cheaper price\n\nIt uses multi-objective, real-time recommendations models and provides 4 use-cases for fasttrack train-&-deploy process - Personalized recommendations, personalized search, related items and real-time feed recommendations.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-5.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-5.png)\n\nHere is the hands-on video tutorial:\n\n[https://youtu.be/7hTKL73f2yA](https://youtu.be/7hTKL73f2yA)\n\n## Nvidia Merlin - Toolkit with GPU capabilities\n\nMerlin empowers data scientists, machine learning engineers, and researchers to build high-performing recommenders at scale. Merlin includes tools that democratize building deep learning recommenders by addressing common ETL, training, and inference challenges. Each stage of the Merlin pipeline is optimized to support hundreds of terabytes of data, all accessible through easy-to-use APIs. With Merlin, better predictions than traditional methods and increased click-through rates are within reach.\n\n![End-to-end recommender system architecture. FE: feature engineering; PP: preprocessing; ETL: extract-transform-load.](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-6.png)\n\nEnd-to-end recommender system architecture. FE: feature engineering; PP: preprocessing; ETL: extract-transform-load.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-7.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-7.png)\n\n## TFRS - Open-source Recommender library built on top of Tensorflow\n\nBuilt with TensorFlow 2.x, TFRS makes it possible to:\n\n- Build and evaluate flexible **[candidate nomination models](https://research.google/pubs/pub48840/)**;\n- Freely incorporate item, user, and context **[information](https://tensorflow.org/recommenders/examples/featurization)** into recommendation models;\n- Train **[multi-task models](https://tensorflow.org/recommenders/examples/multitask)** that jointly optimize multiple recommendation objectives;\n- Efficiently serve the resulting models using **[TensorFlow Serving](https://www.tensorflow.org/tfx/guide/serving)**.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-8.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-8.png)\n\nFollowing is a series of official tutorial notebooks:-\n\n[TensorFlow Recommenders: Quickstart](https://www.tensorflow.org/recommenders/examples/quickstart)\n\n## Elliot - An end-to-end framework good for recommender system experiments\n\n[Elliot](https://elliot.readthedocs.io/en/latest/) is a comprehensive recommendation framework that aims to run and reproduce an entire experimental pipeline by processing a simple configuration file. The framework loads, filters, and splits the data considering a vast set of strategies (13 splitting methods and 8 filtering approaches, from temporal training-test splitting to nested K-folds Cross-Validation). Elliot optimizes hyperparameters (51 strategies) for several recommendation algorithms (50), selects the best models, compares them with the baselines providing intra-model statistics, computes metrics (36) spanning from accuracy to beyond-accuracy, bias, and fairness, and conducts statistical analysis (Wilcoxon and Paired t-test). The aim is to provide the researchers with a tool to ease (and make them reproducible) all the experimental evaluation phases, from data reading to results collection.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-9.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-9.png)\n\n## RecBole - Another framework good for recommender system model experiments\n\nRecBole is developed based on Python and PyTorch for reproducing and developing recommendation algorithms in a unified, comprehensive and efficient framework for research purpose. It can be installed from pip, Conda and source, and easy to use. It includes 65 recommendation algorithms, covering four major categories: General Recommendation, Sequential Recommendation, Context-aware Recommendation, and Knowledge-based Recommendation, which can support the basic research in recommender systems.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-10.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-10.png)\n\nFeatures:\n\n- **General and extensible data structure**We deign general and extensible data structures to unify the formatting and usage of various recommendation datasets.\n- **Comprehensive benchmark models and datasets**We implement 65 commonly used recommendation algorithms, and provide the formatted copies of 28 recommendation datasets.\n- **Efficient GPU-accelerated execution**We design many tailored strategies in the GPU environment to enhance the efficiency of our library.\n- **Extensive and standard evaluation protocols**We support a series of commonly used evaluation protocols or settings for testing and comparing recommendation algorithms.\n\n## Microsoft Recommenders - A powerful set of tools for building high-quality recommender system at low-cost *(highly recommended)*\n\nThe Microsoft Recommenders repository is an open source collection of python utilities and Jupyter notebooks to help accelerate the process of designing, evaluating, and deploying recommender systems. The repository was initially formed by data scientists at Microsoft to consolidate common tools and best practices developed from working on recommender systems in various industry settings. The goal of the tools and notebooks is to show examples of how to effectively build, compare, and then deploy the best recommender solution for a given scenario. Contributions from the community have brought in new algorithm implementations and code examples covering multiple aspects of working with recommendation algorithms.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-11.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-11.png)\n\n## Surprise - An open-source library with easy api and powerful models\n\n[Surprise](http://surpriselib.com/) is a Python [scikit](https://www.scipy.org/scikits.html) for building and analyzing recommender systems that deal with explicit rating data.\n\n[Surprise](http://surpriselib.com/) **was designed with the following purposes in mind**:\n\n- Give users perfect control over their experiments. To this end, a strong emphasis is laid on [documentation](http://surprise.readthedocs.io/en/stable/index.html), which we have tried to make as clear and precise as possible by pointing out every detail of the algorithms.\n- Alleviate the pain of [Dataset handling](http://surprise.readthedocs.io/en/stable/getting_started.html#load-a-custom-dataset). Users can use both *built-in* datasets ([Movielens](http://grouplens.org/datasets/movielens/), [Jester](http://eigentaste.berkeley.edu/dataset/)), and their own *custom* datasets.\n- Provide various ready-to-use [prediction algorithms](http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html) such as [baseline algorithms](http://surprise.readthedocs.io/en/stable/basic_algorithms.html), [neighborhood methods](http://surprise.readthedocs.io/en/stable/knn_inspired.html), matrix factorization-based ( [SVD](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD), [PMF](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#unbiased-note), [SVD++](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVDpp), [NMF](http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF)), and [many others](http://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html). Also, various [similarity measures](http://surprise.readthedocs.io/en/stable/similarities.html) (cosine, MSD, pearson…) are built-in.\n- Make it easy to implement [new algorithm ideas](http://surprise.readthedocs.io/en/stable/building_custom_algo.html).\n- Provide tools to [evaluate](http://surprise.readthedocs.io/en/stable/model_selection.html), [analyse](http://nbviewer.jupyter.org/github/NicolasHug/Surprise/tree/master/examples/notebooks/KNNBasic_analysis.ipynb/) and [compare](http://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/Compare.ipynb) the algorithms’ performance. Cross-validation procedures can be run very easily using powerful CV iterators (inspired by [scikit-learn](http://scikit-learn.org/) excellent tools), as well as [exhaustive search over a set of parameters](http://surprise.readthedocs.io/en/stable/getting_started.html#tune-algorithm-parameters-with-gridsearchcv).\n\n## Spotlight - Another open-source library\n\nSpotlight uses PyTorch to build both deep and shallow recommender models. By providing both a slew of building blocks for loss functions (various pointwise and pairwise ranking losses), representations (shallow factorization representations, deep sequence models), and utilities for fetching (or generating) recommendation datasets, it aims to be a tool for rapid exploration and prototyping of new recommender models.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-12.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-12.png)\n\n[Here](https://github.com/maciejkula/spotlight/tree/master/examples) is a series of hands-on tutorials to get started.\n\n## Vowpal Wabbit - library with reinforcement learning features\n\nVowpal Wabbit is an open source machine learning library, extensively used by industry, and is the first public terascale learning system. It provides fast, scalable machine learning and has unique capabilities such as learning to search, active learning, contextual memory, and extreme multiclass learning. It has a focus on reinforcement learning and provides production ready implementations of Contextual Bandit algorithms. It was developed originally at Yahoo! Research, and currently at Microsoft Research. Vowpal Wabbit sees significant innovation as a research to production vehicle for Microsoft Research.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-13.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-13.png)\n\nFor most applications, collaborative filtering yields satisfactory results for item recommendations; there are however several issues that arise that might make it difficult to scale up a recommender system.\n\n- The number of features can grow quite large, and given the usual sparsity of consumption datasets, collaborative filtering needs every single feature and datapoint available.\n- For new data points, the whole model has to be re-trained\n\nVowpal Wabbit’s matrix factorization capabilities can be used to build a recommender that is similar in spirit to collaborative filtering but that avoids the pitfalls that we mentioned before.\n\nFollowing are the three introductory hands-on tutorials on building recommender systems with vowpal wabbit:\n\n1. [Vowpal Wabbit Deep Dive - A Content-based Recommender System using Microsoft Recommender Library](https://github.com/microsoft/recommenders/blob/main/examples/02_model_content_based_filtering/vowpal_wabbit_deep_dive.ipynb)\n2. [Simulating Content Personalization with Contextual Bandits](https://vowpalwabbit.org/tutorials/cb_simulation.html)\n3. [Vowpal Wabbit, The Magic Recommender System!](https://samuel-guedj.medium.com/vowpal-wabbit-the-magic-58b7f1d8e39c)\n\n## DLRM - An open-source scalable model from Facebook's AI team, build on top of PyTorch\n\nDLRM advances on other models by combining principles from both collaborative filtering and predictive analytics-based approaches, which enables it to work efficiently with production-scale data and provide state-of-art results.\n\nIn the DLRM model, categorical features are processed using embeddings, while continuous features are processed with a bottom multilayer perceptron (MLP). Then, second-order interactions of different features are computed explicitly. Finally, the results are processed with a top MLP and fed into a sigmoid function in order to give a probability of a click.\n\n![/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-14.png](/img/content-blog-raw-blog-tools-for-building-recommender-systems-untitled-14.png)\n\nFollowing are the hands-on tutorials:\n\n1. [https://nbviewer.jupyter.org/github/gotorehanahmad/Recommendation-Systems/blob/master/dlrm/dlrm_main.ipynb](https://nbviewer.jupyter.org/github/gotorehanahmad/Recommendation-Systems/blob/master/dlrm/dlrm_main.ipynb)\n2. [Training Facebook's DLRM on the digix dataset](https://nbviewer.jupyter.org/github/mabeckers/dlrm/blob/new_dataset/Train_DLRM_Digix.ipynb)\n\n## References\n\n1. [https://elliot.readthedocs.io/en/latest/](https://elliot.readthedocs.io/en/latest/)\n2. [https://vowpalwabbit.org/index.html](https://vowpalwabbit.org/index.html)\n3. [https://abacus.ai/user_eng](https://abacus.ai/user_eng)\n4. [https://azure.microsoft.com/en-in/services/cognitive-services/personalizer/](https://azure.microsoft.com/en-in/services/cognitive-services/personalizer/)\n5. [https://aws.amazon.com/personalize/](https://aws.amazon.com/personalize/)\n6. [https://github.com/facebookresearch/dlrm](https://github.com/facebookresearch/dlrm)\n7. [https://www.tensorflow.org/recommenders](https://www.tensorflow.org/recommenders)\n8. [https://magento.com/products/product-recommendations](https://magento.com/products/product-recommendations)\n9. [https://cloud.google.com/recommendations](https://cloud.google.com/recommendations)\n10. [https://www.recombee.com/](https://www.recombee.com/)\n11. [https://recbole.io/](https://recbole.io/)\n12. [https://github.com/microsoft/recommenders](https://github.com/microsoft/recommenders)\n13. [http://surpriselib.com/](http://surpriselib.com/)\n14. [https://github.com/maciejkula/spotlight](https://github.com/maciejkula/spotlight)\n15. https://vowpalwabbit.org/tutorials/contextual_bandits.html\n16. https://github.com/VowpalWabbit/vowpal_wabbit/wiki\n17. https://vowpalwabbit.org/tutorials/cb_simulation.html\n18. https://vowpalwabbit.org/rlos/2021/projects.html\n19. https://vowpalwabbit.org/rlos/2020/projects.html\n20. https://getstream.io/blog/recommendations-activity-streams-vowpal-wabbit/\n21. https://samuel-guedj.medium.com/vowpal-wabbit-the-magic-58b7f1d8e39c\n22. https://vowpalwabbit.org/neurips2019/\n23. https://github.com/VowpalWabbit/neurips2019\n24. https://getstream.io/blog/introduction-contextual-bandits/\n25. https://www.youtube.com/watch?v=CeOcNK1xSSA&t=72s\n26. https://vowpalwabbit.org/blog/rlos-fest-2021.html\n27. https://github.com/VowpalWabbit/workshop\n28. https://github.com/VowpalWabbit/workshop/tree/master/aiNextCon2019\n29. [Blog post by Nasir Mirza. Azure Cognitive Services Personalizer: Part One. Oct, 2019.](https://www.ais.com/azure-cognitive-services-personalizer-part-one/)\n30. [Blog post by Nasir Mirza. Azure Cognitive Services Personalizer: Part Two. Oct, 2019.](https://www.ais.com/azure-cognitive-services-personalizer-part-two/)\n31. [Blog post by Nasir Mirza. Azure Cognitive Services Personalizer: Part Three. Dec, 2019.](https://www.ais.com/azure-cognitive-services-personalizer-part-three/)\n32. [Microsoft Azure Personalizer Official Documentation. Oct, 2020.](https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/what-is-personalizer)\n33. [Personalizer demo.](https://personalizationdemo.azurewebsites.net/)\n34. [Official Page.](https://azure.microsoft.com/en-in/services/cognitive-services/personalizer/#faqs)\n35. [Blog Post by Jake Wong. Get hands on with the Azure Personalizer API. Aug, 2019.](https://www.linkedin.com/pulse/get-hands-azure-personalizer-api-jake-wang/)\n36. [Medium Post.](https://enefitit.medium.com/we-tested-azure-personalizer-heres-what-you-can-expect-8c5ec074a28e)\n37. [Blog Post.](https://www.valoremreply.com/post/azure-personalizer/)\n38. [Git Repo.](https://github.com/Azure-Samples/cognitive-services-personalizer-samples)\n39. [https://youtu.be/7hTKL73f2yA](https://youtu.be/7hTKL73f2yA)\n40. [Deep-Learning Based Recommendation Systems — Learning AI](https://abacus.ai/blog/2020/03/31/deep-learning-based-recommendation-systems/#:~:text=Deep%2DLearning%20Based%20Recommendation%20Systems%20%E2%80%94%20Learning%20AI,-By%20Abacus.AI&text=Deep%20Learning%20(DL)%20has%20had,of%20Recommender%20Systems%20(RS).)\n41. [Evaluating Deep Learning Models with Abacus.AI – Recommendation Systems](https://abacus.ai/blog/2020/12/11/evaluating-deep-learning-models-recommender-systems/)\n42. https://aws.amazon.com/blogs/machine-learning/pioneering-personalized-user-experiences-at-stockx-with-amazon-personalize/\n43. https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/amazon-personalize/\n44. https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_Build_a_content-recommendation_engine_with_Amazon_Personalize_AIM304-R1.pdf\n45. https://aws.amazon.com/blogs/aws/amazon-personalize-real-time-personalization-and-recommendation-for-everyone/\n46. https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_Accelerate_experimentation_with_personalization_models_AIM424-R1.pdf\n47. https://d1.awsstatic.com/events/reinvent/2019/REPEAT_1_Personalized_user_engagement_with_machine_learning_AIM346-R1.pdf\n48. https://github.com/aws-samples/amazon-personalize-samples\n49. https://github.com/aws-samples/amazon-personalize-automated-retraining\n50. https://github.com/aws-samples/amazon-personalize-ingestion-pipeline\n51. https://github.com/aws-samples/amazon-personalize-monitor\n52. https://github.com/aws-samples/amazon-personalize-data-conversion-pipeline\n53. https://github.com/james-jory/segment-personalize-workshop\n54. https://github.com/aws-samples/amazon-personalize-samples/tree/master/next_steps/workshops/POC_in_a_box\n55. https://github.com/Imagination-Media/aws-personalize-magento2\n56. https://github.com/awslabs/amazon-personalize-optimizer-using-amazon-pinpoint-events\n57. https://github.com/aws-samples/amazon-personalize-with-aws-glue-sample-dataset\n58. https://github.com/awsdocs/amazon-personalize-developer-guide\n59. https://github.com/chrisking/NetflixPersonalize\n60. https://github.com/aws-samples/retail-demo-store\n61. https://github.com/aws-samples/personalize-data-science-sdk-workflow\n62. https://github.com/apac-ml-tfc/personalize-poc\n63. https://github.com/dalacan/personalize-batch-recommendations\n64. https://github.com/harunobukameda/Amazon-Personalize-Handson\n65. https://www.sagemakerworkshop.com/personalize/\n66. https://github.com/lmorri/vodpocinabox\n67. https://github.com/awslabs/unicornflix\n68. https://www.youtube.com/watch?v=r9J3UZmddC4&t=966s\n69. https://www.youtube.com/watch?v=kTufCK76Yus&t=1436s\n70. https://www.youtube.com/watch?v=hY_XzglTkak&t=66s\n71. [https://business.adobe.com/lv/summit/2020/adobe-sensei-powers-magento-product-recommendations.html](https://business.adobe.com/lv/summit/2020/adobe-sensei-powers-magento-product-recommendations.html)\n72. https://magento.com/products/product-recommendations\n73. https://docs.magento.com/user-guide/marketing/product-recommendations.html\n74. https://vod.webqem.com/detail/videos/magento-commerce/video/6195503645001/magento-commerce---product-recommendations?autoStart=true&page=1\n75. https://blog.adobe.com/en/publish/2020/11/23/new-ai-capabilities-for-magento-commerce-improve-retail.html#gs.yw6mtq\n76. https://developers.google.com/recommender/docs/reference/rest\n77. https://www.youtube.com/watch?v=nY5U0uQZRyU&t=6s"
        },
        {
          "id": "/2021/10/01/vehicle-suggestions",
          "metadata": {
            "permalink": "/blog/2021/10/01/vehicle-suggestions",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-vehicle-suggestions.mdx",
            "source": "@site/blog/2021-10-01-vehicle-suggestions.mdx",
            "title": "Vehicle Suggestions",
            "description": "/img/content-blog-raw-blog-vehicle-suggestions-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              },
              {
                "label": "similarity",
                "permalink": "/blog/tags/similarity"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              }
            ],
            "readingTime": 13.92,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Tools for building recommender systems",
              "permalink": "/blog/2021/10/01/tools-for-building-recommender-systems"
            },
            "nextItem": {
              "title": "Web Scraping using Scrapy, BS4, and Selenium",
              "permalink": "/blog/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium"
            }
          },
          "content": "![/img/content-blog-raw-blog-vehicle-suggestions-untitled.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled.png)\n\n# Introduction\n\nThe customer owns a franchise store for selling Tesla Automobiles. The objective is to predict user preferences using social media data.\n\nTask 1 - Suggest the best vehicle for the given description\n\nTask 2 - Suggest the best vehicle for the given social media id of the user\n\n## Customer queries\n\n```json\n// car or truck or no mention of vehicle type means Cyber Truck\n// SUV mention means Model X\nconst one = \"I'm looking for a fast suv that I can go camping without worrying about recharging\".;\nconst two = \"cheap red car that is able to go long distances\";\nconst three = \"i am looking for a daily driver that i can charge everyday, do not need any extras\";\nconst four = \"i like to go offroading a lot on my jeep and i want to do the same with the truck\";\nconst five = \"i want the most basic suv possible\";\nconst six = \"I want all of the addons\";\n// mentions of large family or many people means model x\nconst seven = \"I have a big family and want to be able to take them around town and run errands without worrying about charging\";\n```\n\n- Expected output\n    \n    ```json\n    const oneJson = {\n    vehicle: 'Model X',\n    trim : 'adventure',\n    exteriorColor: 'whiteExterior',\n    wheels: \"22Performance\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"\",\n    }\n    \n    const twoJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"21AllSeason\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"\",\n    }\n    \n    const threeJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"21AllSeason\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"standardRange\",\n    software: \"\",\n    }\n    \n    const fourJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'adventure',\n    exteriorColor: 'whiteExterior',\n    wheels: \"20AllTerrain\",\n    tonneau: \"powerTonneau\",\n    packages: \"offroadPackage,matchingSpareTire\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"\",\n    }\n    \n    const fiveJSON = {\n    vehicle: 'Model X',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"20AllTerrain\",\n    tonneau: \"manualTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"standardRange\",\n    software: \"\",\n    }\n    \n    const sixJSON = {\n    vehicle: 'Cyber Truck',\n    trim : 'adventure',\n    exteriorColor: 'whiteExterior',\n    wheels: \"20AllTerrain\",\n    tonneau: \"powerTonneau\",\n    packages: \"offroadPackage,matchingSpareTire\",\n    interiorAddons: \"wirelessCharger\",\n    interiorColor: \"blackInterior\",\n    range: \"extendedRange\",\n    software: \"selfDrivingPackage\",\n    }\n    \n    const sevenJSON = {\n    vehicle: 'Model X',\n    trim : 'base',\n    exteriorColor: 'whiteExterior',\n    wheels: \"21AllSeason\",\n    tonneau: \"powerTonneau\",\n    packages: \"\",\n    interiorAddons: \"\",\n    interiorColor: \"blackInterior\",\n    range: \"mediumRange\",\n    software: \"\",\n    }\n    ```\n    \n- Vehicle model configurations\n    \n    ```json\n    const configuration = {\n    meta: {\n    configurationId: '???',\n    storeId: 'US_SALES',\n    country: 'US',\n    version: '1.0',\n    effectiveDate: '???',\n    currency: 'USD',\n    locale: 'en-US',\n    availableLocales: ['en-US'],\n    },\n    \n    defaults: {\n    basePrice: 50000,\n    deposit: 1000,\n    initialSelection: [\n    'adventure',\n    'whiteExterior',\n    '21AllSeason',\n    'powerTonneau',\n    'blackInterior',\n    'mediumRange',\n    ],\n    },\n    \n    groups: {\n    trim: {\n    name: { 'en-US': 'Choose trim' },\n    multiselect: false,\n    required: true,\n    options: ['base', 'adventure'],\n    },\n    exteriorColor: {\n    name: { 'en-US': 'Choose paint' },\n    multiselect: false,\n    required: true,\n    options: [\n    'whiteExterior',\n    'blueExterior',\n    'silverExterior',\n    'greyExterior',\n    'blackExterior',\n    'redExterior',\n    'greenExterior',\n    ],\n    },\n    wheels: {\n    name: { 'en-US': 'Choose wheels' },\n    multiselect: false,\n    required: true,\n    options: ['21AllSeason', '20AllTerrain', '22Performance'],\n    },\n    tonneau: {\n    name: { 'en-US': 'Choose tonneau cover' },\n    multiselect: false,\n    required: true,\n    options: ['manualTonneau', 'powerTonneau'],\n    },\n    packages: {\n    name: { 'en-US': 'Choose upgrades' },\n    multiselect: true,\n    required: false,\n    options: ['offroadPackage', 'matchingSpareTire'],\n    },\n    interiorColor: {\n    name: { 'en-US': 'Choose interior' },\n    multiselect: false,\n    required: true,\n    options: ['greyInterior', 'blackInterior', 'greenInterior'],\n    },\n    interiorAddons: {\n    name: { 'en-US': 'Choose upgrade' },\n    multiselect: true,\n    required: false,\n    options: ['wirelessCharger'],\n    },\n    range: {\n    name: { 'en-US': 'Choose range' },\n    multiselect: false,\n    required: true,\n    options: ['standardRange', 'mediumRange', 'extendedRange'],\n    },\n    software: {\n    name: { 'en-US': 'Choose upgrade' },\n    multiselect: true,\n    required: false,\n    options: ['selfDrivingPackage'],\n    },\n    specs: {\n    name: { 'en-US': 'Specs overview *' },\n    attrs: {\n    description: {\n    'en-US':\n    \"* Options, specs and pricing may change as we approach production. We'll contact you to review any updates to your preferred build.\",\n    },\n    },\n    multiselect: false,\n    required: false,\n    options: ['acceleration', 'power', 'towing', 'range'],\n    },\n    },\n    \n    options: {\n    base: {\n    name: { 'en-US': 'Base' },\n    attrs: {\n    description: { 'en-US': 'Production begins 2022' },\n    },\n    visual: true,\n    price: 0,\n    },\n    adventure: {\n    name: { 'en-US': 'Adventure' },\n    attrs: {\n    description: { 'en-US': 'Production begins 2021' },\n    },\n    visual: true,\n    price: 10000,\n    },\n    \n    standardRange: {\n    name: { 'en-US': 'Standard' },\n    attrs: {\n    description: { 'en-US': '230+ miles' },\n    },\n    price: 0,\n    },\n    mediumRange: {\n    name: { 'en-US': 'Medium' },\n    attrs: {\n    description: { 'en-US': '300+ miles' },\n    },\n    price: 3000,\n    },\n    extendedRange: {\n    name: { 'en-US': 'Extended' },\n    attrs: {\n    description: { 'en-US': '400+ miles' },\n    },\n    price: 8000,\n    },\n    \n    greenExterior: {\n    name: { 'en-US': 'Adirondack Green' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/green.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    blueExterior: {\n    name: { 'en-US': 'Trestles Blue' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/blue.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    whiteExterior: {\n    name: { 'en-US': 'Arctic White' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/white.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    silverExterior: {\n    name: { 'en-US': 'Silver Gracier' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/silver.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    blackExterior: {\n    name: { 'en-US': 'Cosmic Black' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/black.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    redExterior: {\n    name: { 'en-US': 'Red Rocks' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/red.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    greyExterior: {\n    name: { 'en-US': 'Antracite Grey' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/exteriorcolors/grey.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    \n    '21AllSeason': {\n    name: { 'en-US': '21\" Cast Wheel - All Season' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/wheels/twentyone.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    '20AllTerrain': {\n    name: { 'en-US': '20\" Forged Wheel - All Terrain' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/wheels/twenty.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    '22Performance': {\n    name: { 'en-US': '22\" Cast Wheel - Performance' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/wheels/twentytwo.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    \n    manualTonneau: {\n    name: { 'en-US': 'Manual' },\n    attrs: {\n    description: { 'en-US': 'Description here' },\n    },\n    price: 0,\n    },\n    powerTonneau: {\n    name: { 'en-US': 'Powered' },\n    attrs: {\n    description: { 'en-US': 'Description here' },\n    },\n    price: 0,\n    },\n    \n    blackInterior: {\n    name: { 'en-US': 'Black' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/interiorcolors/black.svg',\n    },\n    visual: true,\n    price: 0,\n    },\n    greyInterior: {\n    name: { 'en-US': 'Grey' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/interiorcolors/grey.svg',\n    },\n    visual: true,\n    price: 1000,\n    },\n    greenInterior: {\n    name: { 'en-US': 'Green' },\n    attrs: {\n    imageUrl: '/public/images/configurationOptions/interiorcolors/green.svg',\n    },\n    visual: true,\n    price: 2000,\n    },\n    \n    offroadPackage: {\n    name: { 'en-US': 'Off-Road' },\n    attrs: {\n    description: { 'en-US': 'Lorem ipsum dolor sit amet.' },\n    imageUrl: '/public/images/configurationOptions/packages/offroad.png',\n    },\n    visual: true,\n    price: 5000,\n    },\n    matchingSpareTire: {\n    name: { 'en-US': 'Matching Spare Tire' },\n    attrs: {\n    description: { 'en-US': 'Full sized tire' },\n    imageUrl: '/public/images/configurationOptions/packages/spare.png',\n    },\n    price: 500,\n    },\n    \n    wirelessCharger: {\n    name: { 'en-US': 'Wireless charger' },\n    attrs: {\n    description: { 'en-US': 'Lorem ipsum dolor sit amet.' },\n    imageUrl: '/public/images/configurationOptions/packages/wireless.png',\n    },\n    price: 100,\n    },\n    selfDrivingPackage: {\n    name: { 'en-US': 'Autonomy' },\n    attrs: {\n    description: { 'en-US': 'Lorem ipsum dolor sit amet.' },\n    imageUrl: '/public/images/configurationOptions/packages/autonomy.png',\n    },\n    price: 7000,\n    },\n    \n    acceleration: {\n    name: { 'en-US': '0 - 60 mph' },\n    attrs: {\n    units: { 'en-US': 'sec' },\n    decimals: 1,\n    },\n    value: 3.4,\n    },\n    power: {\n    name: { 'en-US': 'Horsepower' },\n    attrs: {\n    units: { 'en-US': 'hp' },\n    },\n    value: 750,\n    },\n    towing: {\n    name: { 'en-US': 'Towing' },\n    attrs: {\n    units: { 'en-US': 'lbs' },\n    },\n    value: 10000,\n    },\n    range: {\n    name: { 'en-US': 'Range' },\n    attrs: {\n    units: { 'en-US': 'mi' },\n    },\n    value: 400,\n    },\n    }\n    };\n    ```\n    \n\n## Public datasets\n\n- Instagram: 16539 images from 972 Instagram influencers ([link](https://github.com/gvsi/instagram-like-predictor))\n- TechCrunchPosts: ([link](https://www.kaggle.com/thibalbo/techcrunch-posts-compilation))\n- Tweets: ([link](https://data.world/data-society/twitter-user-data))\n\nPrimary (available for academic use only, need university affiliation for access)\n\n- [A Dataset and Benchmarks for Multimedia Social Analysis](https://arxiv.org/abs/2006.08335)\n\nSecondary (low quality data, not sure if can be used at all)\n\n- [Hacker News Posts](https://www.kaggle.com/hacker-news/hacker-news-posts)\n- [TechCrunch Posts Compilation](https://www.kaggle.com/thibalbo/techcrunch-posts-compilation)\n- Instagram image data [HowTo](https://towardsdatascience.com/predict-the-number-of-likes-on-instagram-a7ec5c020203)\n- Flikr Large with likes and comments\n- [The Images of Groups Dataset](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)\n- [http://www.multimediaeval.org/datasets/](http://www.multimediaeval.org/datasets/)\n- [The InstaCities1M Dataset](https://gombru.github.io/2018/08/01/InstaCities1M/)\n- [Multimodal Meme Classification: Identifying Offensive Content in Image and Text](https://www.insight-centre.org/sites/default/files/publications/memes_classification_lrec_1.pdf)\n- [Understanding Police Social Media Usage Through Posts and Tweets](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NRPHLC)\n- Topic clusters text\n    - Model X\n        - I like model X\n        - I want to buy model X\n        - Model X is my favorite car\n        - Tesla Modelx is my dream\n        - modelx tesla love\n    - Cyber Truck\n        - I like Cyber Truck\n        - I want to buy Cyber Truck\n        - Cyber Truck is my favorite car\n        - Tesla Cyber Truck is my dream\n        - CyberTruck tesla love\n    - Adventure\n        - I like adventure\n        - sports i play\n        - i went on trip\n        - I travels a lot\n        - car adventure\n        \n    - Exterior Color White\n        - I like white color\n        - White is my fav\n        - white car love\n        - I like white exterior\n    - Exterior Color Black\n        - I like Black color\n        - Black is my fav\n        - Black car love\n        - I like Black exterior\n    - Exterior Color Blue\n        - I like Blue color\n        - Blue is my fav\n        - Blue car love\n        - I like Blue exterior\n    - Exterior Color Green\n        - I like Green color\n        - Green is my fav\n        - Green car love\n        - I like Green exterior\n    - Exterior Color Red\n        - I like Red color\n        - Red is my fav\n        - Red car love\n        - I like Red exterior\n    - Exterior Color Grey\n        - I like Grey color\n        - Grey is my fav\n        - Grey car love\n        - I like Grey exterior\n    - Exterior Color Silver\n        - I like Silver color\n        - Silver is my fav\n        - Silver car love\n        - I like Silver exterior\n    - Self driving\n        - I like self driving technology\n        - selfDrivingPackage\n        - selfDrivingtech love\n        - self drive is my fav\n        - self driving car is amazing\n- Celebs\n    \n    ![/img/content-blog-raw-blog-vehicle-suggestions-untitled-1.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-1.png)\n    \n\n## Logical Reasoning\n\n- If I implicitly rate pictures of blue car, that means I might prefer a blue car.\n- If I like posts of self-driving, that means I might prefer a self-driving option.\n\n# Scope\n\n### Scope 1\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-2.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-2.png)\n\n### Scope 2\n\nmedia content categories: text and images\n\nplatforms: facebook, twitter and instagram\n\nimplicit rating categories: like, comment, share\n\ncolumns: userid, timestamp, platform, type, content, rating\n\n# Model Framework\n\n### Model framework 1\n\n1. Convert user's natural language query into vector using Universal Sentence Embedding model\n2. Create a product specs binary matrix based on different categories\n3. Find TopK similar query vectors using cosine distance\n4. For each TopK vector, Find TopM product specs using interaction table weights\n5. For each TopM specification, find TopN similar specs using binary matrix\n6. Show all the qualified product specifications\n\n### Model framework 2\n\n1. Seed data: 10 users with ground-truth persona, media content and implicit ratings\n2. Inflated data: 10 users with media content and implicit ratings\n3. media content → Implicit rating (A)\n4. media content → feature vector (B) + (A) → weighted pooling → similar users (C)\n5. media content → QA model → slot filling → global pooling → item associations (D)\n6. (C) → content-based filtering → item recommendations → (D) → top-k recommendations\n\n**User selection**\n\n- People who are connected to social media community of electric vehicles\n- Seed users are those who already have an electric vehicle\n- Inflated users are those who doesn't own an EV but inclined to purchase\n- Users having presense on all three sites or at least 2\n- List of common users\n    \n    [https://www.facebook.com/gossman](https://www.facebook.com/gossman)\n    \n    [https://www.facebook.com/ryanm06](https://www.facebook.com/ryanm06)\n    \n    [https://www.facebook.com/chad.turner.7146](https://www.facebook.com/chad.turner.7146)\n    \n    [https://www.facebook.com/cjacobs05](https://www.facebook.com/cjacobs05)\n    \n    [https://www.facebook.com/MafiaAllen](https://www.facebook.com/MafiaAllen)\n    \n    [https://www.facebook.com/rahul.mii.33](https://www.facebook.com/rahul.mii.33)\n    \n    [https://www.facebook.com/francisco.chavira.547](https://www.facebook.com/francisco.chavira.547)\n    \n    [https://www.facebook.com/JayTheillest74](https://www.facebook.com/JayTheillest74)\n    \n    [https://www.facebook.com/michael.creighton20](https://www.facebook.com/michael.creighton20)\n    \n    [https://www.facebook.com/darryl.grigggardening](https://www.facebook.com/darryl.grigggardening)\n    \n    [https://www.facebook.com/4X4Aus/](https://www.facebook.com/4X4Aus/)\n    \n    [https://www.instagram.com/minnyrc/](https://www.instagram.com/minnyrc/)\n    \n    [https://www.instagram.com/warnerbu7lt/](https://www.instagram.com/warnerbu7lt/)\n    \n- List of celebs\n    1. [https://en.wikipedia.org/wiki/List_of_most-followed_Instagram_accounts](https://en.wikipedia.org/wiki/List_of_most-followed_Instagram_accounts)\n    2. [https://en.wikipedia.org/wiki/List_of_most-followed_Twitter_accounts](https://en.wikipedia.org/wiki/List_of_most-followed_Twitter_accounts)\n    3. [https://en.wikipedia.org/wiki/List_of_most-followed_Facebook_pages](https://en.wikipedia.org/wiki/List_of_most-followed_Facebook_pages)\n    \n    ['Jennifer Lopez', 'Virat Kohli', 'Ariana Grande', 'Dwayne Johnson', 'Kylie Jenner', 'Lionel Messi', 'LeBron James', 'Beyoncé', 'Justin Bieber', 'Akshay Kumar', 'Demi Lovato', 'Kendall Jenner', 'Nicki Minaj', 'Khloé Kardashian', 'Kim Kardashian', 'Gigi Hadid', 'Ellen DeGeneres', 'Deepika Padukone', 'Rihanna', 'Shakira', 'Cardi B', 'Eminem', 'Drake', 'Chris Brown', 'Maluma', 'Vin Diesel', 'Ronaldinho', 'Kevin Hart', 'Emma Watson', 'Shawn Mendes', 'Neymar', 'Justin Timberlake', 'Katy Perry', 'Donald Trump', 'Lady Gaga', 'Amitabh Bachchan', 'Selena Gomez', 'Lil Wayne', 'Elon Musk', 'Britney Spears', 'Jimmy Fallon', 'Bill Gates', 'Ariana Grande', 'Miley Cyrus', 'Oprah Winfrey', 'Cristiano Ronaldo', 'Salman Khan', 'Shah Rukh Khan', 'Niall Horan']\n    \n\n### Model framework 3\n\nUser-User Similarity (clustering)\n\n- User → Media content → Embedding → Average pooling\n- Cosine Similarity of user's social vector with other user's social vector\n\nUser-Item Similarity (reranking)\n\n- **User → Implicit Rating on media content M → M's correlation with item features**\n- Item features: familySize\n- Cosine Similarity of user's social vector with item's feature vector\n\nUser-User Similarity (clustering)\n\n- User → Media content → Embedding → Average pooling\n- Cosine Similarity of user's social vector with other user's social vector\n\nUser-Item Similarity (reranking)\n\n- **User → Implicit Rating on media content M → M's correlation with item features**\n- Item features: familySize\n- Cosine Similarity of user's social vector with item's feature vector\n\n### Model framework 4\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-3.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-3.png)\n\nText → Prepare → Vectorize → Average → Similar Users\n\nImage → Prepare → Vectorize → Average → Similar Users\n\nText → Prepare → QA → Slot filling\n\nImage → Prepare → VQA → Slot filling\n\nImage → Similar Image from users → Detailed enquiry\n\n### Model framework 5\n\n1. Topic Clusters Text\n2. Topic Clusters Image\n3. Fetch raw text and images\n4. Combine, Clean and Store text in text dataframe\n5. Vectorize Texts\n6. Cosine similarities of texts with topic clusters\n7. Vectorize Images\n8. Cosine similarities of images with topic clusters\n\n# Experimental Setup\n\n- Experiment 1\n    \n    ```python\n    import numpy as np\n    import pandas as pd\n    import tensorflow_hub as hub\n    from itertools import product\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.metrics.pairwise import cosine_similarity\n    \n    vehicle = ['modelX', 'cyberTruck']\n    trim = ['adventure', 'base']\n    exteriorColor = ['whiteExterior', 'blueExterior', 'silverExterior', 'greyExterior', 'blackExterior', 'redExterior', 'greenExterior']\n    wheels = ['20AllTerrain', '21AllSeason', '22Performance']\n    tonneau = ['powerTonneau', 'manualTonneau']\n    interiorColor = ['blackInterior', 'greyInterior', 'greenInterior']\n    range = ['standardRange', 'mediumRange', 'extendedRange']\n    packages = ['offroadPackage', 'matchingSpareTire', 'offroadPackage,matchingSpareTire', 'None']\n    interiorAddons = ['wirelessCharger', 'None']\n    software = ['selfDrivingPackage', 'None']\n    \n    specs_cols = ['vehicle', 'trim', 'exteriorColor', 'wheels', 'tonneau', 'interiorColor', 'range', 'packages', 'interiorAddons', 'software']\n    specs = pd.DataFrame(list(product(vehicle, trim, exteriorColor, wheels, tonneau, interiorColor, range, packages, interiorAddons, software)),\n                         columns=specs_cols)\n    \n    enc = OneHotEncoder(handle_unknown='error', sparse=False)\n    specs = pd.DataFrame(enc.fit_transform(specs))\n    \n    specs_ids = specs.index.tolist()\n    \n    query_list = [\"I'm looking for a fast suv that I can go camping without worrying about recharging\",\n                  \"cheap red car that is able to go long distances\",\n                  \"i am looking for a daily driver that i can charge everyday, do not need any extras\",\n                  \"i like to go offroading a lot on my jeep and i want to do the same with the truck\",\n                  \"i want the most basic suv possible\",\n                  \"I want all of the addons\", \n                  \"I have a big family and want to be able to take them around town and run errands without worrying about charging\"]\n    \n    queries = pd.DataFrame(query_list, columns=['query'])\n    query_ids = queries.index.tolist()\n    \n    const_oneJSON = {\n    'vehicle': 'modelX',\n    'trim' : 'adventure',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"22Performance\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"None\",\n    }\n    \n    const_twoJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"21AllSeason\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"None\",\n    }\n    \n    const_threeJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"21AllSeason\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"standardRange\",\n    'software': \"None\",\n    }\n    \n    const_fourJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'adventure',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"20AllTerrain\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"offroadPackage,matchingSpareTire\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"None\",\n    }\n    \n    const_fiveJSON = {\n    'vehicle': 'modelX',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"20AllTerrain\",\n    'tonneau': \"manualTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"standardRange\",\n    'software': \"None\",\n    }\n    \n    const_sixJSON = {\n    'vehicle': 'cyberTruck',\n    'trim' : 'adventure',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"20AllTerrain\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"offroadPackage,matchingSpareTire\",\n    'interiorAddons': \"wirelessCharger\",\n    'interiorColor': \"blackInterior\",\n    'range': \"extendedRange\",\n    'software': \"selfDrivingPackage\",\n    }\n    \n    const_sevenJSON = {\n    'vehicle': 'modelX',\n    'trim' : 'base',\n    'exteriorColor': 'whiteExterior',\n    'wheels': \"21AllSeason\",\n    'tonneau': \"powerTonneau\",\n    'packages': \"None\",\n    'interiorAddons': \"None\",\n    'interiorColor': \"blackInterior\",\n    'range': \"mediumRange\",\n    'software': \"None\",\n    }\n    \n    historical_data = pd.DataFrame([const_oneJSON, const_twoJSON, const_threeJSON, const_fourJSON, const_fiveJSON, const_sixJSON, const_sevenJSON])\n    \n    input_vec = enc.transform([specs_frame.append(historical_data.iloc[0], sort=False).iloc[-1]])\n    idx = np.argsort(-cosine_similarity(input_vec, specs.values))[0,:][:1]\n    rslt = enc.inverse_transform([specs.iloc[idx]])\n    \n    interactions = pd.DataFrame(columns=['query_id','specs_id'])\n    interactions['query_id'] = queries.index.tolist()\n    input_vecs = enc.transform(specs_frame.append(historical_data, sort=False).iloc[-len(historical_data):])\n    interactions['specs_id'] = np.argsort(-cosine_similarity(input_vecs, specs.values))[:,0]\n    \n    module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" \n    embed_model = hub.load(module_url)\n    def embed(input):\n      return embed_model(input)\n    query_vecs = embed(queries['query'].tolist()).numpy()\n    \n    _query = input('Please enter query: ') or 'i want the most basic suv possible'\n    _query_vec = embed([_query]).numpy()\n    _match_qid = np.argsort(-cosine_similarity(_query_vec, query_vecs))[0,:][:1]\n    _match_sid = interactions.loc[interactions['query_id']==_match_qid[0], 'specs_id'].values[0]\n    input_vec = enc.transform([specs_frame.append(historical_data.iloc[0], sort=False).iloc[-1]])\n    idx = np.argsort(-cosine_similarity([specs.iloc[_match_sid].values], specs.values))[0,:][:5]\n    results = []\n    for x in idx:\n      results.append(enc.inverse_transform([specs.iloc[x]]))\n    _temp = np.array(results).reshape(5,-1)\n    _temp = pd.DataFrame(_temp, columns=specs_frame.columns)\n    print(_temp)\n    ```\n    \n\n## Experiment 2\n\nCeleb Scraping\n\n### Facebook Scraping\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-4.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-4.png)\n\n### Twitter Scraping\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-5.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-5.png)\n\n### Dataframe\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-6.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-6.png)\n\n### Insta Image Grid\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-7.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-7.png)\n\n### User Text NER\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-8.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-8.png)\n\n## Experiment 3\n\nTopic model\n\n### Topic scores\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-9.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-9.png)\n\n### JSON rules\n\n![/img/content-blog-raw-blog-vehicle-suggestions-untitled-10.png](/img/content-blog-raw-blog-vehicle-suggestions-untitled-10.png)\n\n# Results and Discussion\n\n- API with 3 input fields - Facebook username, Twitter handle & Instagram username\n- The system will automatically scrap the user's publicly available text and images from these 3 social media platforms and provide a list of recommendations from most to least preferred product"
        },
        {
          "id": "/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
          "metadata": {
            "permalink": "/blog/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-web-scraping-using-scrapy-bs4-and-selenium.mdx",
            "source": "@site/blog/2021-10-01-web-scraping-using-scrapy-bs4-and-selenium.mdx",
            "title": "Web Scraping using Scrapy, BS4, and Selenium",
            "description": "1. Handling single request & response by extracting a city’s weather from a weather site using Scrapy",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "scraping",
                "permalink": "/blog/tags/scraping"
              }
            ],
            "readingTime": 3.78,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Vehicle Suggestions",
              "permalink": "/blog/2021/10/01/vehicle-suggestions"
            },
            "nextItem": {
              "title": "Web Scraping with Gazpacho",
              "permalink": "/blog/2021/10/01/web-scraping-with-gazpacho"
            }
          },
          "content": "1. Handling single request & response by extracting a city’s weather from a weather site using Scrapy\n2. Handling multiple request & response by extracting book details from a dummy online book store using Scrapy\n3. Scrape the cover images of all the books from the website [books.toscrape.com](http://books.toscrape.com/) using Scrapy\n4. Logging into Facebook using Selenium\n5. Extract PM2.5 data from [openaq.org](http://openaq.org) using Selenium\n6. Extract PM2.5 data from [openaq.org](http://openaq.org) using Selenium Scrapy\n\n:::note Scrapy vs. Selenium\n\nSelenium is an automation tool for testing web applications. It uses a webdriver as an interface to control webpages through programming languages. So, this gives Selenium the capability to handle dynamic webpages effectively. Selenium is capable of extracting data on its own. It is true, but it has its caveats. Selenium cannot handle large data, but Scrapy can handle large data with ease. Also, Selenium is much slower when compared to Scrapy. So, the smart choice would be to use Selenium with Scrapy to scrape dynamic webpages containing large data, consuming less time. Combining Selenium with Scrapy is a simpler process. All that needs to be done is let Selenium render the webpage and once it is done, pass the webpage’s source to create a Scrapy Selector object. And from here on, Scrapy can crawl the page with ease and effectively extract a large amount of data.\n\n:::\n\n```python\n# SKELETON FOR COMBINING SELENIUM WITH SCRAPY\nfrom scrapy import Selector\n# Other Selenium and Scrapy imports\n...\ndriver = webdriver.Chrome()\n# Selenium tasks and actions to render the webpage with required content\nselenium_response_text = driver.page_source\nnew_selector = Selector(text=selenium_response_text)\n# Scrapy tasks to extract data from Selector\n```\n\n## Project tree\n\n```html\n.\n├── airQuality\n│   ├── countries_list.json\n│   ├── get_countries.py\n│   ├── get_pm_data.py\n│   ├── get_urls.py\n│   ├── openaq_data.json\n│   ├── openaq_scraper.py\n│   ├── README.md\n│   └── urls.json\n├── airQualityScrapy\n│   ├── LICENSE\n│   ├── openaq\n│   │   ├── countries_list.json\n│   │   ├── openaq\n│   │   │   ├── __init__.py\n│   │   │   ├── items.py\n│   │   │   ├── middlewares.py\n│   │   │   ├── pipelines.py\n│   │   │   ├── settings.py\n│   │   │   └── spiders\n│   │   ├── output.json\n│   │   ├── README.md\n│   │   ├── scrapy.cfg\n│   │   └── urls.json\n│   ├── performance_comparison\n│   │   ├── performance_comparison\n│   │   │   ├── __init__.py\n│   │   │   ├── items.py\n│   │   │   ├── middlewares.py\n│   │   │   ├── pipelines.py\n│   │   │   ├── settings.py\n│   │   │   └── spiders\n│   │   ├── README.md\n│   │   ├── scrapy.cfg\n│   │   ├── scrapy_output.json\n│   │   └── selenium_scraper\n│   │       ├── bts_scraper.py\n│   │       ├── selenium_output.json\n│   │       └── urls.json\n│   └── README.md\n├── books\n│   ├── books\n│   │   ├── __init__.py\n│   │   ├── items.py\n│   │   ├── middlewares.py\n│   │   ├── pipelines.py\n│   │   ├── settings.py\n│   │   └── spiders\n│   │       ├── book_spider.py\n│   │       ├── crawl_spider.py\n│   │       └── __init__.py\n│   ├── crawl_spider_output.json\n│   ├── README.md\n│   └── scrapy.cfg\n├── booksCoverImage\n│   ├── booksCoverImage\n│   │   ├── __init__.py\n│   │   ├── items.py\n│   │   ├── middlewares.py\n│   │   ├── pipelines.py\n│   │   ├── settings.py\n│   │   └── spiders\n│   │       ├── image_crawl_spider.py\n│   │       └── __init__.py\n│   ├── output.json\n│   ├── path\n│   │   └── to\n│   │       └── store\n│   ├── README.md\n│   └── scrapy.cfg\n├── etc\n│   └── Selenium\n│       ├── chromedriver.exe\n│       ├── chromedriver_v87.exe\n│       └── install.sh\n├── facebook\n│   └── login.py\n├── gazpacho1\n│   ├── data\n│   │   ├── media.html\n│   │   ├── ocr.html\n│   │   ├── page.html\n│   │   ├── static\n│   │   │   └── stheno.mp4\n│   │   └── table.html\n│   ├── media\n│   │   ├── euryale.png\n│   │   ├── medusa.mp3\n│   │   ├── medusa.png\n│   │   ├── stheno.mp4\n│   │   └── test.png\n│   ├── scrap_login.py\n│   ├── scrap_media.py\n│   ├── scrap_ocr.py\n│   ├── scrap_page.py\n│   └── scrap_table.py\n├── houzzdotcom\n│   ├── houzzdotcom\n│   │   ├── __init__.py\n│   │   ├── items.py\n│   │   ├── middlewares.py\n│   │   ├── pipelines.py\n│   │   ├── settings.py\n│   │   └── spiders\n│   │       ├── crawl_spider.py\n│   │       └── __init__.py\n│   └── scrapy.cfg\n├── media\n│   └── test.png\n├── README.md\n├── scrapyPractice\n│   ├── scrapy.cfg\n│   └── scrapyPractice\n│       ├── __init__.py\n│       ├── items.py\n│       ├── middlewares.py\n│       ├── pipelines.py\n│       ├── settings.py\n│       └── spiders\n│           └── __init__.py\n└── weather\n    ├── output.json\n    ├── README.md\n    ├── scrapy.cfg\n    └── weather\n        ├── __init__.py\n        ├── items.py\n        ├── middlewares.py\n        ├── pipelines.py\n        ├── settings.py\n        └── spiders\n            ├── __init__.py\n            └── weather_spider.py\n\n35 directories, 98 files\n```\n\n![For code, drop me a message on mail or LinkedIn.](/img/content-blog-raw-blog-web-scraping-using-scrapy-bs4-and-selenium-untitled.png)\n\nFor code, drop me a message on mail or LinkedIn."
        },
        {
          "id": "/2021/10/01/web-scraping-with-gazpacho",
          "metadata": {
            "permalink": "/blog/2021/10/01/web-scraping-with-gazpacho",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-web-scraping-with-gazpacho.mdx",
            "source": "@site/blog/2021-10-01-web-scraping-with-gazpacho.mdx",
            "title": "Web Scraping with Gazpacho",
            "description": "Using gazpacho to Download and Parse the Contents of a Website. Scrape the names of the three \"Gorgons\".",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "scraping",
                "permalink": "/blog/tags/scraping"
              }
            ],
            "readingTime": 0.52,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Web Scraping using Scrapy, BS4, and Selenium",
              "permalink": "/blog/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium"
            },
            "nextItem": {
              "title": "Wellness tracker chatbot",
              "permalink": "/blog/2021/10/01/wellness-tracker-chatbot"
            }
          },
          "content": "### Using gazpacho to Download and Parse the Contents of a Website. Scrape the names of the three \"Gorgons\".\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled.png)\n\n### Using gazpacho and pandas to Retrieve the Contents of an HTML Table. Scrape the creature and habitat columns.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-1.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-1.png)\n\n### Using gazpacho and Selenium to Retrieve the Contents of a Password-Protected Web Page. Scrape the quote text behind the login form.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-2.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-2.png)\n\n### Using gazpacho and pytesseract to Parse the Contents of “Non-Text” Text Data. Extract the embedded text.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-3.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-3.png)\n\n### Using gazpacho and urllib to Retrieve and Download Images, Videos, and Audio Clippings. To download the Image, Audio and Video data.\n\n![/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-4.png](/img/content-blog-raw-blog-web-scraping-with-gazpacho-untitled-4.png)"
        },
        {
          "id": "/2021/10/01/wellness-tracker-chatbot",
          "metadata": {
            "permalink": "/blog/2021/10/01/wellness-tracker-chatbot",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-wellness-tracker-chatbot.mdx",
            "source": "@site/blog/2021-10-01-wellness-tracker-chatbot.mdx",
            "title": "Wellness tracker chatbot",
            "description": "/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "chatbot",
                "permalink": "/blog/tags/chatbot"
              },
              {
                "label": "healthcare",
                "permalink": "/blog/tags/healthcare"
              },
              {
                "label": "nlp",
                "permalink": "/blog/tags/nlp"
              }
            ],
            "readingTime": 0.455,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Web Scraping with Gazpacho",
              "permalink": "/blog/2021/10/01/web-scraping-with-gazpacho"
            },
            "nextItem": {
              "title": "What is Livestream Ecommerce",
              "permalink": "/blog/2021/10/01/what-is-livestream-ecommerce"
            }
          },
          "content": "![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled.png)\n\n## Problem Statement\n\nA bot that logs daily wellness data to a spreadsheet (using the Airtable API), to help the user keep track of their health goals. Connect the assistant to a messaging channel—Twilio—so users can talk to the assistant via text message and Whatsapp.\n\n---\n\n## Proposed Solution\n\n- RASA chatbot with Forms and Custom actions\n- Connect with Airtable API to log records in table database\n- Connect with Whatsapp for user interaction\n\n---\n\n## Modeling\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-1.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-1.png)\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-2.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-2.png)\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-3.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-3.png)\n\n![/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-4.png](/img/content-blog-raw-blog-wellness-tracker-chatbot-untitled-4.png)\n\n---\n\n## Delivery\n\n[https://github.com/sparsh-ai/chatbots/tree/master/wellnessTracker](https://github.com/sparsh-ai/chatbots/tree/master/wellnessTracker)\n\n---\n\n## Reference\n\n[https://www.udemy.com/course/rasa-for-beginners/learn/lecture/20746878#overview](https://www.udemy.com/course/rasa-for-beginners/learn/lecture/20746878#overview)"
        },
        {
          "id": "/2021/10/01/what-is-livestream-ecommerce",
          "metadata": {
            "permalink": "/blog/2021/10/01/what-is-livestream-ecommerce",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-10-01-what-is-livestream-ecommerce.mdx",
            "source": "@site/blog/2021-10-01-what-is-livestream-ecommerce.mdx",
            "title": "What is Livestream Ecommerce",
            "description": "/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled.png",
            "date": "2021-10-01T00:00:00.000Z",
            "formattedDate": "October 1, 2021",
            "tags": [
              {
                "label": "personalization",
                "permalink": "/blog/tags/personalization"
              },
              {
                "label": "trend",
                "permalink": "/blog/tags/trend"
              }
            ],
            "readingTime": 3.385,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Wellness tracker chatbot",
              "permalink": "/blog/2021/10/01/wellness-tracker-chatbot"
            },
            "nextItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/01/23/object-detection-with-yolo3"
            }
          },
          "content": "![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled.png)\n\nRecent years witness the prosperity of online live streaming. With the development of mobile phones, cameras, and high-speed internet, more and more users are able to broadcast their experiences in live streams on various social platforms, such as Facebook Live and YouTube Live. There are a variety of live streaming applications, including knowledge share, video-gaming, and outdoor traveling.\n\nOne of the most important scenarios is live streaming commerce, a new form of online shopping becomes more and more popular, which combines live streaming with E-Commerce activity. The streamers introduce products and interact with their audiences, and hence greatly improve the performance of selling products.\n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-1.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-1.png)\n\n> Livestream ecommerce is a business model in which retailers, influencers, or celebrities sell products and services via online video streaming where the presenter demonstrates and discusses the offering and answers audience questions in real-time.\n> \n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-2.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-2.png)\n\n### Examples\n\n[https://media.nngroup.com/media/editor/2021/02/16/tiktok_livestream_compressed.mp4](https://media.nngroup.com/media/editor/2021/02/16/tiktok_livestream_compressed.mp4)\n\n*During a livestream event hosted by Walmart on TikTok, users watched an influencer presenting various products such as a pair of jeans. Those interested in the jeans could tap the product listing shown at the bottom of the screen. They could also browse the list of products promoted during the livestream and purchase them without leaving the TikTok app. Viewers’ real-time comments appeared along the left-hand side of the livestream feed.*\n\n### Advantages\n\n- Livestreams allow users to see products in detail and get their questions answered in real time\n- During livestream sessions, the hosts can show product details in close-up (left), give instructions of use for products like essential oils and cosmetic face masks (middle), or even show how a particular product, like the tea they’re selling, is made (right)\n    \n    ![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-3.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-3.png)\n    \n- Greatly shorten the decision-making time of consumers and provoke the sales volume\n- The expert streamers introduce and promote the products in a live streaming manner, which makes the shopping process more interesting and convincing\n- Rich and real-time interactions between streamers and their audiences, which makes live streaming a new medium and a powerful marketing tool for E-Commerce\n- Viewers not only can watch the showing for product’s looks and functions, but also can ask the streamers to show different or individual perspectives of the products in real-time\n\n### Market\n\nLivestream ecommerce has been surging dramatically in China. According to Forbes, this industry is estimated to earn $60 billion annually. In 2019, about 37 percent of the online shoppers in China (265 million people) made livestream purchases. On Taobao’s 2020 annual Single-Day Global Shopping Festival (November 11th), livestreams accounted for $6 billion in sales (twice the amount from the prior year).\n\nAmazon has also launched its live platform, where influencers promote items and chat with potential customers. And Facebook and Instagram are exploring the integration between ecommerce and social media. For instance, the new Shop feature on Instagram allows users to browse products and place orders directly within Instagram — a form of social commerce.\n\nThe total GMV driven by live streaming achieved $6 Billion USD. Some quantitative research results show that adopting live streaming in sales can achieve a 21.8% increase in online sales volume.\n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-4.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-4.png)\n\n### The Anatomy of a Livestream Session\n\n![/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-5.png](/img/content-blog-raw-blog-what-is-livestream-ecommerce-untitled-5.png)\n\nA typical livestream session has the following basic components:\n\n1. **The video stream,** where the host shows the products, talks about them, and answers questions from the audience. In the Amazon Live case, the stream occupies the most of the screen space.\n2. **The list of products being promoted**, with the product currently being shown highlighted. This list appears at the bottom of the Amazon video stream.\n3. **A chat area,** where viewers can type questions and comments to interact with the host and other viewers. The chat area is at the right of the live stream on Amazon Live.\n4. **A reaction button, that users** can use to send reactions, displayed as animated emojis. The reaction button shows up as a little star icon at the bottom right of the video stream on Amazon.\n\n### References\n\n1. [Features of Livestream ecommerce: What We Can Learn from China](https://www.nngroup.com/articles/livestream-ecommerce-china/)\n2. [Top Live Streaming E-Commerce Startups](https://tracxn.com/d/trending-themes/Startups-in-Live-Streaming-E-Commerce)"
        },
        {
          "id": "/2021/01/23/object-detection-with-yolo3",
          "metadata": {
            "permalink": "/blog/2021/01/23/object-detection-with-yolo3",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2021-01-23-object-detection-with-yolo3.mdx",
            "source": "@site/blog/2021-01-23-object-detection-with-yolo3.mdx",
            "title": "Object detection with YOLO3",
            "description": "Live app",
            "date": "2021-01-23T00:00:00.000Z",
            "formattedDate": "January 23, 2021",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              },
              {
                "label": "streamlit",
                "permalink": "/blog/tags/streamlit"
              }
            ],
            "readingTime": 1.975,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "What is Livestream Ecommerce",
              "permalink": "/blog/2021/10/01/what-is-livestream-ecommerce"
            },
            "nextItem": {
              "title": "MobileNet SSD Caffe Pre-trained model",
              "permalink": "/blog/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
            }
          },
          "content": "## Live app\n\nThis app can detect COCO 80-classes using three different models - Caffe MobileNet SSD, Yolo3-tiny, and Yolo3. It can also detect faces using two different models - SSD Res10 and OpenCV face detector.  Yolo3-tiny can also detect fires.\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled.png)\n\n![/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png](/img/content-blog-raw-blog-object-detection-with-yolo3-untitled-1.png)\n\n## Code\n\n```python\nimport streamlit as st\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport os\n\nfrom tempfile import NamedTemporaryFile\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\ntemp_file = NamedTemporaryFile(delete=False)\n\nDEFAULT_CONFIDENCE_THRESHOLD = 0.5\nDEMO_IMAGE = \"test_images/demo.jpg\"\nMODEL = \"model/MobileNetSSD_deploy.caffemodel\"\nPROTOTXT = \"model/MobileNetSSD_deploy.prototxt.txt\"\n\nCLASSES = [\n    \"background\",\n    \"aeroplane\",\n    \"bicycle\",\n    \"bird\",\n    \"boat\",\n    \"bottle\",\n    \"bus\",\n    \"car\",\n    \"cat\",\n    \"chair\",\n    \"cow\",\n    \"diningtable\",\n    \"dog\",\n    \"horse\",\n    \"motorbike\",\n    \"person\",\n    \"pottedplant\",\n    \"sheep\",\n    \"sofa\",\n    \"train\",\n    \"tvmonitor\",\n]\nCOLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n\n@st.cache\ndef process_image(image):\n    blob = cv2.dnn.blobFromImage(\n        cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5\n    )\n    net = cv2.dnn.readNetFromCaffe(PROTOTXT, MODEL)\n    net.setInput(blob)\n    detections = net.forward()\n    return detections\n\n@st.cache\ndef annotate_image(\n    image, detections, confidence_threshold=DEFAULT_CONFIDENCE_THRESHOLD\n):\n    # loop over the detections\n    (h, w) = image.shape[:2]\n    labels = []\n    for i in np.arange(0, detections.shape[2]):\n        confidence = detections[0, 0, i, 2]\n\n        if confidence > confidence_threshold:\n            # extract the index of the class label from the `detections`,\n            # then compute the (x, y)-coordinates of the bounding box for\n            # the object\n            idx = int(detections[0, 0, i, 1])\n            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n            (startX, startY, endX, endY) = box.astype(\"int\")\n\n            # display the prediction\n            label = f\"{CLASSES[idx]}: {round(confidence * 100, 2)}%\"\n            labels.append(label)\n            cv2.rectangle(image, (startX, startY), (endX, endY), COLORS[idx], 2)\n            y = startY - 15 if startY - 15 > 15 else startY + 15\n            cv2.putText(\n                image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2\n            )\n    return image, labels\n\ndef main():\n  selected_box = st.sidebar.selectbox(\n    'Choose one of the following',\n    ('Welcome', 'Object Detection')\n    )\n    \n  if selected_box == 'Welcome':\n      welcome()\n  if selected_box == 'Object Detection':\n      object_detection() \n\ndef welcome():\n  st.title('Object Detection using Streamlit')\n  st.subheader('A simple app for object detection')\n  st.image('test_images/demo.jpg',use_column_width=True)\n\ndef object_detection():\n  \n  st.title(\"Object detection with MobileNet SSD\")\n\n  confidence_threshold = st.sidebar.slider(\n    \"Confidence threshold\", 0.0, 1.0, DEFAULT_CONFIDENCE_THRESHOLD, 0.05)\n\n  st.sidebar.multiselect(\"Select object classes to include\",\n  options=CLASSES,\n  default=CLASSES\n  )\n\n  img_file_buffer = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n\n  if img_file_buffer is not None:\n      temp_file.write(img_file_buffer.getvalue())\n      image = load_img(temp_file.name)\n      image = img_to_array(image)\n      image = image/255.0\n\n  else:\n      demo_image = DEMO_IMAGE\n      image = np.array(Image.open(demo_image))\n\n  detections = process_image(image)\n  image, labels = annotate_image(image, detections, confidence_threshold)\n\n  st.image(\n      image, caption=f\"Processed image\", use_column_width=True,\n  )\n\n  st.write(labels)\n\nmain()\n```\n\n*You can play with the live app* [*here](https://share.streamlit.io/sparsh-ai/streamlit-489fbbb7/app.py). Source code is available [here](https://github.com/sparsh-ai/streamlit-5a407279/tree/master) on Github.*"
        },
        {
          "id": "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model",
          "metadata": {
            "permalink": "/blog/2020/01/19/mobilenet-ssd-caffe-pre-trained-model",
            "editUrl": "https://github.com/recohut/docs/blog/blog/2020-01-19-mobilenet-ssd-caffe-pre-trained-model.mdx",
            "source": "@site/blog/2020-01-19-mobilenet-ssd-caffe-pre-trained-model.mdx",
            "title": "MobileNet SSD Caffe Pre-trained model",
            "description": "You can play with the live app here. Souce code is available here on Github.",
            "date": "2020-01-19T00:00:00.000Z",
            "formattedDate": "January 19, 2020",
            "tags": [
              {
                "label": "app",
                "permalink": "/blog/tags/app"
              },
              {
                "label": "vision",
                "permalink": "/blog/tags/vision"
              },
              {
                "label": "streamlit",
                "permalink": "/blog/tags/streamlit"
              }
            ],
            "readingTime": 0.74,
            "truncated": false,
            "authors": [
              {
                "name": "Sparsh Agarwal",
                "title": "Principal Developer",
                "url": "https://github.com/sparsh-ai",
                "imageURL": "https://avatars.githubusercontent.com/u/62965911?v=4",
                "key": "sparsh"
              }
            ],
            "prevItem": {
              "title": "Object detection with YOLO3",
              "permalink": "/blog/2021/01/23/object-detection-with-yolo3"
            }
          },
          "content": "*You can play with the live app [here](https://share.streamlit.io/sparsh-ai/streamlit-5a407279/app.py). Souce code is available* [here](https://github.com/sparsh-ai/streamlit-489fbbb7) *on Github.*\n\n## Live app\n\n![/img/content-blog-raw-mobilenet-ssd-caffe-pre-trained-model-untitled.png](/img/content-blog-raw-mobilenet-ssd-caffe-pre-trained-model-untitled.png)\n\n## Code\n\n```python\n#------------------------------------------------------#\n# Import libraries\n#------------------------------------------------------#\n\nimport datetime\nimport urllib\nimport time\nimport cv2 as cv\nimport streamlit as st\n\nfrom plugins import Motion_Detection\nfrom utils import GUI, AppManager, DataManager\n\n#------------------------------------------------------#\n#------------------------------------------------------#\n\ndef imageWebApp(guiParam):\n    \"\"\"\n    \"\"\"\n    # Load the image according to the selected option\n    conf = DataManager(guiParam)\n    image = conf.load_image_or_video()\n    \n    # GUI\n    switchProcessing = st.button('* Start Processing *')\n\n    # Apply the selected plugin on the image\n    bboxed_frame, output = AppManager(guiParam).process(image, True)\n\n    # Display results\n    st.image(bboxed_frame, channels=\"BGR\",  use_column_width=True)\n\ndef main():\n    \"\"\"\n    \"\"\"\n    # Get the parameter entered by the user from the GUI\n    guiParam = GUI().getGuiParameters()\n\n    # Check if the application if it is Empty\n    if guiParam['appType'] == 'Image Applications':\n        if guiParam[\"selectedApp\"] is not 'Empty':\n            imageWebApp(guiParam)\n\n    else:\n        raise st.ScriptRunner.StopException\n\n#------------------------------------------------------#\n#------------------------------------------------------#\n\nif __name__ == \"__main__\":\n    main()\n```"
        }
      ],
      "blogListPaginated": [
        {
          "metadata": {
            "permalink": "/blog",
            "page": 1,
            "postsPerPage": 10,
            "totalPages": 3,
            "totalCount": 29,
            "previousPage": null,
            "nextPage": "/blog/page/2",
            "blogDescription": "Blog",
            "blogTitle": "Blog"
          },
          "items": [
            "/2021/10/01/bytedance's-secret-sauce-of-recommendation",
            "/2021/10/01/clinical-decision-making",
            "/2021/10/01/detectron-2",
            "/2021/10/01/distributed-training-of-recommender-systems",
            "/2021/10/01/document-recommendation",
            "/2021/10/01/fake-voice-detection",
            "/2021/10/01/finding-hardware-parts-in-warehouse",
            "/2021/10/01/image-similarity-system",
            "/2021/10/01/insurance-personalization",
            "/2021/10/01/name-&-address-parsing"
          ]
        },
        {
          "metadata": {
            "permalink": "/blog/page/2",
            "page": 2,
            "postsPerPage": 10,
            "totalPages": 3,
            "totalCount": 29,
            "previousPage": "/blog",
            "nextPage": "/blog/page/3",
            "blogDescription": "Blog",
            "blogTitle": "Blog"
          },
          "items": [
            "/2021/10/01/object-detection-hands-on-exercises",
            "/2021/10/01/object-detection-with-opencv",
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/10/01/ocr-experiments",
            "/2021/10/01/pdf-to-wordcloud-via-mail",
            "/2021/10/01/personalized-unexpectedness-in-recommender-systems",
            "/2021/10/01/predicting-electronics-resale-price",
            "/2021/10/01/real-time-news-personalization-with-flink",
            "/2021/10/01/semantic-similarity",
            "/2021/10/01/short-video-background-music-recommender"
          ]
        },
        {
          "metadata": {
            "permalink": "/blog/page/3",
            "page": 3,
            "postsPerPage": 10,
            "totalPages": 3,
            "totalCount": 29,
            "previousPage": "/blog/page/2",
            "nextPage": null,
            "blogDescription": "Blog",
            "blogTitle": "Blog"
          },
          "items": [
            "/2021/10/01/the-progression-of-analytics-in-enterprises",
            "/2021/10/01/tools-for-building-recommender-systems",
            "/2021/10/01/vehicle-suggestions",
            "/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
            "/2021/10/01/web-scraping-with-gazpacho",
            "/2021/10/01/wellness-tracker-chatbot",
            "/2021/10/01/what-is-livestream-ecommerce",
            "/2021/01/23/object-detection-with-yolo3",
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ]
        }
      ],
      "blogTags": {
        "/blog/tags/recsys": {
          "name": "recsys",
          "items": [
            "/2021/10/01/bytedance's-secret-sauce-of-recommendation",
            "/2021/10/01/distributed-training-of-recommender-systems",
            "/2021/10/01/short-video-background-music-recommender",
            "/2021/10/01/tools-for-building-recommender-systems"
          ],
          "permalink": "/blog/tags/recsys"
        },
        "/blog/tags/tool": {
          "name": "tool",
          "items": [
            "/2021/10/01/bytedance's-secret-sauce-of-recommendation",
            "/2021/10/01/detectron-2",
            "/2021/10/01/tools-for-building-recommender-systems"
          ],
          "permalink": "/blog/tags/tool"
        },
        "/blog/tags/classification": {
          "name": "classification",
          "items": [
            "/2021/10/01/clinical-decision-making"
          ],
          "permalink": "/blog/tags/classification"
        },
        "/blog/tags/healthcare": {
          "name": "healthcare",
          "items": [
            "/2021/10/01/clinical-decision-making",
            "/2021/10/01/wellness-tracker-chatbot"
          ],
          "permalink": "/blog/tags/healthcare"
        },
        "/blog/tags/vision": {
          "name": "vision",
          "items": [
            "/2021/10/01/detectron-2",
            "/2021/10/01/image-similarity-system",
            "/2021/10/01/object-detection-hands-on-exercises",
            "/2021/10/01/object-detection-with-opencv",
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/10/01/ocr-experiments",
            "/2021/10/01/vehicle-suggestions",
            "/2021/01/23/object-detection-with-yolo3",
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ],
          "permalink": "/blog/tags/vision"
        },
        "/blog/tags/distributed": {
          "name": "distributed",
          "items": [
            "/2021/10/01/distributed-training-of-recommender-systems"
          ],
          "permalink": "/blog/tags/distributed"
        },
        "/blog/tags/nlp": {
          "name": "nlp",
          "items": [
            "/2021/10/01/document-recommendation",
            "/2021/10/01/finding-hardware-parts-in-warehouse",
            "/2021/10/01/name-&-address-parsing",
            "/2021/10/01/semantic-similarity",
            "/2021/10/01/vehicle-suggestions",
            "/2021/10/01/wellness-tracker-chatbot"
          ],
          "permalink": "/blog/tags/nlp"
        },
        "/blog/tags/similarity": {
          "name": "similarity",
          "items": [
            "/2021/10/01/document-recommendation",
            "/2021/10/01/finding-hardware-parts-in-warehouse",
            "/2021/10/01/image-similarity-system",
            "/2021/10/01/semantic-similarity",
            "/2021/10/01/vehicle-suggestions"
          ],
          "permalink": "/blog/tags/similarity"
        },
        "/blog/tags/audio": {
          "name": "audio",
          "items": [
            "/2021/10/01/fake-voice-detection"
          ],
          "permalink": "/blog/tags/audio"
        },
        "/blog/tags/deepfake": {
          "name": "deepfake",
          "items": [
            "/2021/10/01/fake-voice-detection"
          ],
          "permalink": "/blog/tags/deepfake"
        },
        "/blog/tags/aws-beanstalk": {
          "name": "aws beanstalk",
          "items": [
            "/2021/10/01/image-similarity-system"
          ],
          "permalink": "/blog/tags/aws-beanstalk"
        },
        "/blog/tags/flask": {
          "name": "flask",
          "items": [
            "/2021/10/01/image-similarity-system",
            "/2021/10/01/name-&-address-parsing"
          ],
          "permalink": "/blog/tags/flask"
        },
        "/blog/tags/insurance": {
          "name": "insurance",
          "items": [
            "/2021/10/01/insurance-personalization"
          ],
          "permalink": "/blog/tags/insurance"
        },
        "/blog/tags/personalization": {
          "name": "personalization",
          "items": [
            "/2021/10/01/insurance-personalization",
            "/2021/10/01/personalized-unexpectedness-in-recommender-systems",
            "/2021/10/01/real-time-news-personalization-with-flink",
            "/2021/10/01/what-is-livestream-ecommerce"
          ],
          "permalink": "/blog/tags/personalization"
        },
        "/blog/tags/app": {
          "name": "app",
          "items": [
            "/2021/10/01/name-&-address-parsing",
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/01/23/object-detection-with-yolo3",
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ],
          "permalink": "/blog/tags/app"
        },
        "/blog/tags/ner": {
          "name": "ner",
          "items": [
            "/2021/10/01/name-&-address-parsing"
          ],
          "permalink": "/blog/tags/ner"
        },
        "/blog/tags/object-detection": {
          "name": "object detection",
          "items": [
            "/2021/10/01/object-detection-hands-on-exercises",
            "/2021/10/01/object-detection-with-opencv"
          ],
          "permalink": "/blog/tags/object-detection"
        },
        "/blog/tags/opencv": {
          "name": "opencv",
          "items": [
            "/2021/10/01/object-detection-with-opencv"
          ],
          "permalink": "/blog/tags/opencv"
        },
        "/blog/tags/streamlit": {
          "name": "streamlit",
          "items": [
            "/2021/10/01/object-detection-with-yolo3",
            "/2021/01/23/object-detection-with-yolo3",
            "/2020/01/19/mobilenet-ssd-caffe-pre-trained-model"
          ],
          "permalink": "/blog/tags/streamlit"
        },
        "/blog/tags/ocr": {
          "name": "ocr",
          "items": [
            "/2021/10/01/ocr-experiments"
          ],
          "permalink": "/blog/tags/ocr"
        },
        "/blog/tags/regression": {
          "name": "regression",
          "items": [
            "/2021/10/01/predicting-electronics-resale-price"
          ],
          "permalink": "/blog/tags/regression"
        },
        "/blog/tags/realtime": {
          "name": "realtime",
          "items": [
            "/2021/10/01/real-time-news-personalization-with-flink"
          ],
          "permalink": "/blog/tags/realtime"
        },
        "/blog/tags/insight": {
          "name": "insight",
          "items": [
            "/2021/10/01/the-progression-of-analytics-in-enterprises"
          ],
          "permalink": "/blog/tags/insight"
        },
        "/blog/tags/scraping": {
          "name": "scraping",
          "items": [
            "/2021/10/01/web-scraping-using-scrapy-bs4-and-selenium",
            "/2021/10/01/web-scraping-with-gazpacho"
          ],
          "permalink": "/blog/tags/scraping"
        },
        "/blog/tags/chatbot": {
          "name": "chatbot",
          "items": [
            "/2021/10/01/wellness-tracker-chatbot"
          ],
          "permalink": "/blog/tags/chatbot"
        },
        "/blog/tags/trend": {
          "name": "trend",
          "items": [
            "/2021/10/01/what-is-livestream-ecommerce"
          ],
          "permalink": "/blog/tags/trend"
        }
      },
      "blogTagsListPath": "/blog/tags"
    }
  },
  "docusaurus-plugin-content-pages": {
    "default": [
      {
        "type": "jsx",
        "permalink": "/",
        "source": "@site/src/pages/index.js"
      },
      {
        "type": "mdx",
        "permalink": "/markdown-page",
        "source": "@site/src/pages/markdown-page.md"
      }
    ]
  },
  "docusaurus-plugin-debug": {
    "default": null
  },
  "docusaurus-theme-classic": {
    "default": null
  }
}